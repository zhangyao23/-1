#!/usr/bin/env python3
"""é‡æ–°è®­ç»ƒåˆ†ç±»å™¨è„šæœ¬"""

import pickle
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import os

print("ğŸ”„ é‡æ–°è®­ç»ƒåˆ†ç±»å™¨")
print("=" * 60)

# 1. åŠ è½½è®­ç»ƒæ•°æ®
print("ğŸ“š åŠ è½½è®­ç»ƒæ•°æ®...")
try:
    df = pd.read_csv('data/improved_training_data_6d.csv')
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {len(df)} ä¸ªæ ·æœ¬")
    
    # è¿‡æ»¤å‡ºå¼‚å¸¸æ ·æœ¬ï¼ˆç”¨äºè®­ç»ƒåˆ†ç±»å™¨ï¼‰
    anomaly_df = df[df['label'] != 0].copy()
    print(f"ğŸ“Š å¼‚å¸¸æ ·æœ¬æ•°é‡: {len(anomaly_df)}")
    
    # æ£€æŸ¥å¼‚å¸¸ç±»å‹åˆ†å¸ƒ
    print("\nå¼‚å¸¸ç±»å‹åˆ†å¸ƒ:")
    type_counts = anomaly_df['anomaly_type'].value_counts().sort_index()
    for anomaly_type, count in type_counts.items():
        print(f"  {anomaly_type}: {count}")
    
except Exception as e:
    print(f"âŒ åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
    exit(1)

# 2. å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
print("\nğŸ¯ å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾...")
try:
    # æå–ç‰¹å¾åˆ—
    feature_columns = ['avg_signal_strength', 'avg_data_rate', 'avg_latency', 'packet_loss_rate', 'system_load', 'network_stability']
    X = anomaly_df[feature_columns].values
    y = anomaly_df['anomaly_type'].values
    
    print(f"ç‰¹å¾ç»´åº¦: {X.shape}")
    print(f"æ ‡ç­¾æ•°é‡: {len(y)}")
    print(f"å”¯ä¸€æ ‡ç­¾: {np.unique(y)}")
    
except Exception as e:
    print(f"âŒ å‡†å¤‡æ•°æ®å¤±è´¥: {e}")
    exit(1)

# 3. ç¼–ç æ ‡ç­¾
print("\nğŸ”¤ ç¼–ç æ ‡ç­¾...")
try:
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    print(f"æ ‡ç­¾æ˜ å°„:")
    for i, class_name in enumerate(label_encoder.classes_):
        print(f"  {i}: {class_name}")
    
except Exception as e:
    print(f"âŒ æ ‡ç­¾ç¼–ç å¤±è´¥: {e}")
    exit(1)

# 4. åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
print("\nâœ‚ï¸ åˆ†å‰²è®­ç»ƒæµ‹è¯•æ•°æ®...")
try:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape}")
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape}")
    
except Exception as e:
    print(f"âŒ æ•°æ®åˆ†å‰²å¤±è´¥: {e}")
    exit(1)

# 5. è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨
print("\nğŸŒ² è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨...")
try:
    rf_classifier = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        class_weight='balanced'
    )
    
    rf_classifier.fit(X_train, y_train)
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
    train_score = rf_classifier.score(X_train, y_train)
    print(f"è®­ç»ƒå‡†ç¡®ç‡: {train_score:.4f}")
    
    # è®¡ç®—æµ‹è¯•å‡†ç¡®ç‡
    test_score = rf_classifier.score(X_test, y_test)
    print(f"æµ‹è¯•å‡†ç¡®ç‡: {test_score:.4f}")
    
except Exception as e:
    print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
    exit(1)

# 6. è¯„ä¼°æ¨¡å‹
print("\nğŸ“Š æ¨¡å‹è¯„ä¼°...")
try:
    y_pred = rf_classifier.predict(X_test)
    
    print("\nåˆ†ç±»æŠ¥å‘Š:")
    target_names = [f"{i}:{name}" for i, name in enumerate(label_encoder.classes_)]
    print(classification_report(y_test, y_pred, target_names=target_names))
    
    print("\næ··æ·†çŸ©é˜µ:")
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
    
except Exception as e:
    print(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")

# 7. ä¿å­˜æ¨¡å‹
print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
try:
    # ç¡®ä¿modelsç›®å½•å­˜åœ¨
    os.makedirs('models', exist_ok=True)
    
    # ä¿å­˜æ¨¡å‹å’Œæ ‡ç­¾ç¼–ç å™¨
    model_data = {
        'model': rf_classifier,
        'label_encoder': label_encoder,
        'feature_columns': feature_columns,
        'classes': label_encoder.classes_,
        'training_info': {
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'train_accuracy': train_score,
            'test_accuracy': test_score,
            'features': feature_columns
        }
    }
    
    # ä¿å­˜ä¸»æ¨¡å‹
    with open('models/rf_classifier_improved.pkl', 'wb') as f:
        pickle.dump(model_data, f)
    
    print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ: models/rf_classifier_improved.pkl")
    
    # åŒæ—¶ä¿å­˜å¤‡ä»½
    with open('models/rf_classifier_backup.pkl', 'wb') as f:
        pickle.dump(model_data, f)
    
    print("âœ… å¤‡ä»½ä¿å­˜æˆåŠŸ: models/rf_classifier_backup.pkl")
    
except Exception as e:
    print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
    exit(1)

# 8. æµ‹è¯•åŠ è½½
print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½...")
try:
    with open('models/rf_classifier_improved.pkl', 'rb') as f:
        loaded_model = pickle.load(f)
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"æ¨¡å‹ç±»å‹: {type(loaded_model)}")
    print(f"åŒ…å«é”®: {list(loaded_model.keys())}")
    
    # æµ‹è¯•é¢„æµ‹
    test_features = np.array([[75.0, 1.5, 11.75, 0.005, 12.0, 35.0]])
    pred = loaded_model['model'].predict(test_features)
    pred_proba = loaded_model['model'].predict_proba(test_features)
    pred_label = loaded_model['label_encoder'].inverse_transform(pred)
    
    print(f"\næµ‹è¯•é¢„æµ‹:")
    print(f"  è¾“å…¥ç‰¹å¾: {test_features[0]}")
    print(f"  é¢„æµ‹ç¼–ç : {pred[0]}")
    print(f"  é¢„æµ‹æ ‡ç­¾: {pred_label[0]}")
    print(f"  é¢„æµ‹æ¦‚ç‡: {pred_proba[0]}")
    
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")

print("\n" + "=" * 60)
print("ğŸ‰ åˆ†ç±»å™¨é‡æ–°è®­ç»ƒå®Œæˆ!") 