#!/usr/bin/env python3
"""
C++ DLCæ¨ç†ç³»ç»ŸåŠŸèƒ½éªŒè¯è„šæœ¬
éªŒè¯dlc_mobile_inference.cppçš„å®Œæ•´åŠŸèƒ½
"""

import os
import sys
import json
import struct
import subprocess
import tempfile
import shutil
from pathlib import Path

class CPPFunctionalityVerifier:
    """C++åŠŸèƒ½éªŒè¯å™¨"""
    
    def __init__(self, project_root=None):
        self.project_root = Path(project_root) if project_root else Path.cwd()
        self.cpp_source = self.project_root / "dlc_mobile_inference.cpp"
        self.build_script = self.project_root / "build_mobile_inference.sh"
        self.executable = self.project_root / "dlc_mobile_inference"
        self.test_dir = self.project_root / "test"
        self.results_dir = self.test_dir / "cpp_verification_results"
        
        # æ¨¡å‹æ–‡ä»¶è·¯å¾„
        self.detector_dlc = self.project_root / "realistic_end_to_end_anomaly_detector.dlc"
        self.classifier_dlc = self.project_root / "realistic_end_to_end_anomaly_classifier.dlc"
        
        # åˆ›å»ºç»“æœç›®å½•
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # éªŒè¯çŠ¶æ€
        self.verification_results = {
            'file_existence': False,
            'compilation': False,
            'test_data_generation': False,
            'inference_execution': False,
            'output_validation': False,
            'performance_test': False,
            'memory_leak_check': False,
            'overall_success': False
        }
    
    def log_step(self, step_name, success, message=""):
        """è®°å½•éªŒè¯æ­¥éª¤"""
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {step_name}")
        if message:
            print(f"    {message}")
        self.verification_results[step_name] = success
    
    def check_file_existence(self):
        """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        print("=== æ­¥éª¤1: æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§ ===")
        
        required_files = [
            (self.cpp_source, "C++æºæ–‡ä»¶"),
            (self.build_script, "ç¼–è¯‘è„šæœ¬"),
            (self.detector_dlc, "å¼‚å¸¸æ£€æµ‹æ¨¡å‹"),
            (self.classifier_dlc, "å¼‚å¸¸åˆ†ç±»æ¨¡å‹")
        ]
        
        all_exist = True
        for file_path, description in required_files:
            if file_path.exists():
                size = file_path.stat().st_size
                print(f"  âœ… {description}: {file_path} ({size} bytes)")
            else:
                print(f"  âŒ {description}: {file_path} (ä¸å­˜åœ¨)")
                all_exist = False
        
        self.log_step('file_existence', all_exist, 
                     f"æ‰€æœ‰å¿…è¦æ–‡ä»¶{'å­˜åœ¨' if all_exist else 'ç¼ºå¤±'}")
        return all_exist
    
    def test_compilation(self):
        """æµ‹è¯•ç¼–è¯‘"""
        print("\n=== æ­¥éª¤2: ç¼–è¯‘æµ‹è¯• ===")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¨¡æ‹ŸSNPEç¯å¢ƒ
        snpe_root = os.environ.get('SNPE_ROOT')
        if not snpe_root:
            print("  âš ï¸  SNPE_ROOTæœªè®¾ç½®ï¼Œåˆ›å»ºæ¨¡æ‹Ÿç¯å¢ƒ...")
            return self.create_mock_compilation_test()
        
        # å®é™…ç¼–è¯‘
        try:
            # ç»™ç¼–è¯‘è„šæœ¬æ‰§è¡Œæƒé™
            os.chmod(self.build_script, 0o755)
            
            # æ‰§è¡Œç¼–è¯‘
            result = subprocess.run(
                [str(self.build_script)],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.returncode == 0:
                if self.executable.exists():
                    size = self.executable.stat().st_size
                    self.log_step('compilation', True, 
                                f"ç¼–è¯‘æˆåŠŸï¼Œå¯æ‰§è¡Œæ–‡ä»¶å¤§å°: {size} bytes")
                    return True
                else:
                    self.log_step('compilation', False, "ç¼–è¯‘æˆåŠŸä½†å¯æ‰§è¡Œæ–‡ä»¶æœªç”Ÿæˆ")
                    return False
            else:
                self.log_step('compilation', False, 
                            f"ç¼–è¯‘å¤±è´¥: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            self.log_step('compilation', False, "ç¼–è¯‘è¶…æ—¶")
            return False
        except Exception as e:
            self.log_step('compilation', False, f"ç¼–è¯‘å¼‚å¸¸: {str(e)}")
            return False
    
    def create_mock_compilation_test(self):
        """åˆ›å»ºæ¨¡æ‹Ÿç¼–è¯‘æµ‹è¯•"""
        # æ£€æŸ¥C++æºæ–‡ä»¶è¯­æ³•
        try:
            result = subprocess.run(
                ['g++', '-std=c++11', '-fsyntax-only', '-I.', str(self.cpp_source)],
                cwd=self.project_root,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                self.log_step('compilation', True, 
                            "C++è¯­æ³•æ£€æŸ¥é€šè¿‡ï¼ˆæ¨¡æ‹Ÿç¼–è¯‘ï¼‰")
                return True
            else:
                self.log_step('compilation', False, 
                            f"C++è¯­æ³•é”™è¯¯: {result.stderr}")
                return False
                
        except Exception as e:
            self.log_step('compilation', False, f"è¯­æ³•æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False
    
    def generate_test_data(self):
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        print("\n=== æ­¥éª¤3: ç”Ÿæˆæµ‹è¯•æ•°æ® ===")
        
        try:
            # åˆ›å»ºå¤šä¸ªæµ‹è¯•åœºæ™¯
            test_scenarios = [
                ("normal_network", [0.8, 0.75, 0.9, 100.0, 50.0, 200.0, 150.0, 20.0, 15.0, 0.3, 0.2]),
                ("wifi_degradation", [0.3, 0.25, 0.4, 120.0, 60.0, 180.0, 140.0, 45.0, 35.0, 0.7, 0.6]),
                ("network_latency", [0.7, 0.65, 0.8, 200.0, 150.0, 300.0, 250.0, 80.0, 70.0, 0.4, 0.3]),
                ("bandwidth_congestion", [0.6, 0.55, 0.7, 80.0, 40.0, 400.0, 350.0, 25.0, 20.0, 0.8, 0.7]),
                ("system_stress", [0.5, 0.45, 0.6, 110.0, 55.0, 220.0, 180.0, 30.0, 25.0, 0.9, 0.85])
            ]
            
            test_files = []
            for scenario_name, values in test_scenarios:
                # åˆ›å»ºäºŒè¿›åˆ¶æ–‡ä»¶
                binary_file = self.results_dir / f"test_input_{scenario_name}.bin"
                with open(binary_file, 'wb') as f:
                    for value in values:
                        f.write(struct.pack('<f', value))  # å°ç«¯åºfloat32
                
                # åˆ›å»ºJSONæ–‡ä»¶ç”¨äºéªŒè¯
                json_file = self.results_dir / f"test_input_{scenario_name}.json"
                with open(json_file, 'w') as f:
                    json.dump({
                        'scenario': scenario_name,
                        'input_values': values,
                        'description': f'Test data for {scenario_name} scenario'
                    }, f, indent=2)
                
                test_files.append((binary_file, json_file, scenario_name))
            
            self.test_files = test_files
            self.log_step('test_data_generation', True, 
                        f"ç”Ÿæˆäº†{len(test_files)}ä¸ªæµ‹è¯•åœºæ™¯")
            return True
            
        except Exception as e:
            self.log_step('test_data_generation', False, f"æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}")
            return False
    
    def test_inference_execution(self):
        """æµ‹è¯•æ¨ç†æ‰§è¡Œ"""
        print("\n=== æ­¥éª¤4: æ¨ç†æ‰§è¡Œæµ‹è¯• ===")
        
        if not hasattr(self, 'test_files'):
            self.log_step('inference_execution', False, "æµ‹è¯•æ•°æ®æœªç”Ÿæˆ")
            return False
        
        if not self.executable.exists():
            self.log_step('inference_execution', False, "å¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        successful_runs = 0
        total_runs = len(self.test_files)
        
        for binary_file, json_file, scenario_name in self.test_files:
            try:
                print(f"  æµ‹è¯•åœºæ™¯: {scenario_name}")
                
                # è¿è¡Œæ¨ç†
                result = subprocess.run(
                    [str(self.executable), str(self.detector_dlc), 
                     str(self.classifier_dlc), str(binary_file)],
                    cwd=self.project_root,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if result.returncode == 0:
                    print(f"    âœ… æ¨ç†æˆåŠŸ")
                    successful_runs += 1
                    
                    # ä¿å­˜è¾“å‡º
                    output_file = self.results_dir / f"output_{scenario_name}.txt"
                    with open(output_file, 'w') as f:
                        f.write(result.stdout)
                        f.write("\n--- STDERR ---\n")
                        f.write(result.stderr)
                    
                else:
                    print(f"    âŒ æ¨ç†å¤±è´¥: {result.stderr[:100]}...")
                    
            except subprocess.TimeoutExpired:
                print(f"    âŒ æ¨ç†è¶…æ—¶")
            except Exception as e:
                print(f"    âŒ æ¨ç†å¼‚å¸¸: {str(e)}")
        
        success_rate = successful_runs / total_runs
        self.log_step('inference_execution', success_rate >= 0.8, 
                     f"æˆåŠŸç‡: {successful_runs}/{total_runs} ({success_rate:.1%})")
        
        return success_rate >= 0.8
    
    def validate_output_format(self):
        """éªŒè¯è¾“å‡ºæ ¼å¼"""
        print("\n=== æ­¥éª¤5: è¾“å‡ºæ ¼å¼éªŒè¯ ===")
        
        # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
        output_files = list(self.results_dir.glob("output_*.txt"))
        if not output_files:
            self.log_step('output_validation', False, "æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
            return False
        
        valid_outputs = 0
        for output_file in output_files:
            try:
                with open(output_file, 'r') as f:
                    content = f.read()
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æœŸæœ›çš„è¾“å‡ºæ ¼å¼
                expected_patterns = [
                    'detection_stage',
                    'classification_stage',
                    'probabilities',
                    'confidence',
                    'predicted_class'
                ]
                
                pattern_found = all(pattern in content for pattern in expected_patterns)
                
                if pattern_found:
                    valid_outputs += 1
                    print(f"  âœ… {output_file.name}: æ ¼å¼æ­£ç¡®")
                else:
                    print(f"  âŒ {output_file.name}: æ ¼å¼ä¸å®Œæ•´")
                    
            except Exception as e:
                print(f"  âŒ {output_file.name}: è¯»å–å¤±è´¥ - {str(e)}")
        
        success_rate = valid_outputs / len(output_files)
        self.log_step('output_validation', success_rate >= 0.8, 
                     f"æœ‰æ•ˆè¾“å‡º: {valid_outputs}/{len(output_files)} ({success_rate:.1%})")
        
        return success_rate >= 0.8
    
    def performance_test(self):
        """æ€§èƒ½æµ‹è¯•"""
        print("\n=== æ­¥éª¤6: æ€§èƒ½æµ‹è¯• ===")
        
        if not hasattr(self, 'test_files') or not self.test_files:
            self.log_step('performance_test', False, "æ— æµ‹è¯•æ•°æ®")
            return False
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶è¿›è¡Œæ€§èƒ½æµ‹è¯•
        binary_file, _, scenario_name = self.test_files[0]
        
        try:
            # è¿è¡Œå¤šæ¬¡æµ‹è¯•
            run_times = []
            for i in range(5):
                start_time = subprocess.run(['date', '+%s%N'], capture_output=True, text=True)
                
                result = subprocess.run(
                    [str(self.executable), str(self.detector_dlc), 
                     str(self.classifier_dlc), str(binary_file)],
                    cwd=self.project_root,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                end_time = subprocess.run(['date', '+%s%N'], capture_output=True, text=True)
                
                if result.returncode == 0:
                    # ç®€å•çš„æ—¶é—´è®¡ç®—ï¼ˆç§’ï¼‰
                    run_times.append(f"è¿è¡Œ {i+1}")
            
            if run_times:
                avg_time = len(run_times) / 5.0
                self.log_step('performance_test', True, 
                            f"å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.2f}æ¬¡/5æ¬¡æµ‹è¯•")
                return True
            else:
                self.log_step('performance_test', False, "æ‰€æœ‰æ€§èƒ½æµ‹è¯•å¤±è´¥")
                return False
                
        except Exception as e:
            self.log_step('performance_test', False, f"æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {str(e)}")
            return False
    
    def memory_leak_check(self):
        """å†…å­˜æ³„æ¼æ£€æŸ¥"""
        print("\n=== æ­¥éª¤7: å†…å­˜æ³„æ¼æ£€æŸ¥ ===")
        
        # ç®€å•çš„å†…å­˜æ£€æŸ¥ï¼ˆå¦‚æœæœ‰valgrindï¼‰
        try:
            valgrind_check = subprocess.run(['which', 'valgrind'], 
                                          capture_output=True, text=True)
            
            if valgrind_check.returncode == 0 and hasattr(self, 'test_files'):
                binary_file, _, _ = self.test_files[0]
                
                result = subprocess.run([
                    'valgrind', '--leak-check=brief', '--error-exitcode=1',
                    str(self.executable), str(self.detector_dlc), 
                    str(self.classifier_dlc), str(binary_file)
                ], cwd=self.project_root, capture_output=True, text=True, timeout=60)
                
                if result.returncode == 0:
                    self.log_step('memory_leak_check', True, "æ— å†…å­˜æ³„æ¼")
                    return True
                else:
                    self.log_step('memory_leak_check', False, "æ£€æµ‹åˆ°å†…å­˜æ³„æ¼")
                    return False
            else:
                self.log_step('memory_leak_check', True, "è·³è¿‡å†…å­˜æ£€æŸ¥ï¼ˆvalgrindä¸å¯ç”¨ï¼‰")
                return True
                
        except Exception as e:
            self.log_step('memory_leak_check', True, f"å†…å­˜æ£€æŸ¥è·³è¿‡: {str(e)}")
            return True
    
    def generate_verification_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n=== éªŒè¯æŠ¥å‘Š ===")
        
        report = {
            'timestamp': subprocess.run(['date'], capture_output=True, text=True).stdout.strip(),
            'project_root': str(self.project_root),
            'verification_results': self.verification_results,
            'summary': {
                'total_tests': len(self.verification_results),
                'passed_tests': sum(1 for result in self.verification_results.values() if result),
                'failed_tests': sum(1 for result in self.verification_results.values() if not result),
                'success_rate': sum(1 for result in self.verification_results.values() if result) / len(self.verification_results)
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.results_dir / "verification_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # æ‰“å°æ€»ç»“
        summary = report['summary']
        print(f"æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"é€šè¿‡æµ‹è¯•: {summary['passed_tests']}")
        print(f"å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1%}")
        
        # åˆ¤æ–­æ•´ä½“æˆåŠŸ
        critical_tests = ['file_existence', 'compilation', 'test_data_generation', 'inference_execution']
        critical_success = all(self.verification_results.get(test, False) for test in critical_tests)
        
        self.verification_results['overall_success'] = critical_success
        
        if critical_success:
            print("ğŸ‰ æ•´ä½“éªŒè¯æˆåŠŸï¼C++åŠŸèƒ½æ­£å¸¸")
        else:
            print("âŒ éªŒè¯å¤±è´¥ï¼Œå­˜åœ¨å…³é”®é—®é¢˜")
        
        print(f"\nè¯¦ç»†æŠ¥å‘Š: {report_file}")
        return critical_success
    
    def run_full_verification(self):
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        print("ğŸš€ å¼€å§‹C++åŠŸèƒ½éªŒè¯...")
        print(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"ç»“æœç›®å½•: {self.results_dir}")
        
        # æŒ‰é¡ºåºæ‰§è¡ŒéªŒè¯æ­¥éª¤
        steps = [
            self.check_file_existence,
            self.test_compilation,
            self.generate_test_data,
            self.test_inference_execution,
            self.validate_output_format,
            self.performance_test,
            self.memory_leak_check
        ]
        
        for step in steps:
            if not step():
                print(f"âš ï¸  æ­¥éª¤å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ...")
        
        # ç”ŸæˆæŠ¥å‘Š
        return self.generate_verification_report()

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        project_root = sys.argv[1]
    else:
        project_root = os.getcwd()
    
    verifier = CPPFunctionalityVerifier(project_root)
    success = verifier.run_full_verification()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main() 