#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIç½‘ç»œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ - æ€§èƒ½æµ‹è¯•è„šæœ¬
"""

import numpy as np
import pandas as pd
import time
import sys
import os

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.append('src')
sys.path.append('.')

# ä¿®æ­£å¯¼å…¥è·¯å¾„
try:
    from ai_models.autoencoder_model import AutoencoderModel
    from ai_models.error_classifier import ErrorClassifier
    from logger.system_logger import Logger
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("å°è¯•å…¶ä»–å¯¼å…¥æ–¹å¼...")
    # ç›´æ¥åˆ›å»ºç®€å•æ—¥å¿—ç±»
    class Logger:
        def info(self, msg): print(f"[INFO] {msg}")
        def warning(self, msg): print(f"[WARNING] {msg}")
        def error(self, msg): print(f"[ERROR] {msg}")
        def debug(self, msg): pass

print('ğŸš€ AIç½‘ç»œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ - æ€§èƒ½æµ‹è¯•')
print('=' * 60)

# åˆå§‹åŒ–æ—¥å¿—
logger = Logger()

# åŠ è½½æµ‹è¯•æ•°æ®
print('ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...')
try:
    df = pd.read_csv('data/improved_training_data_6d.csv')
    normal_data = df[df['label'] == 0].drop(['label', 'anomaly_type'], axis=1)
    anomaly_data = df[df['label'] == 1].drop(['label', 'anomaly_type'], axis=1)
    
    # éšæœºé‡‡æ ·
    normal_samples = normal_data.sample(n=min(50, len(normal_data))).values
    anomaly_samples = anomaly_data.sample(n=min(50, len(anomaly_data))).values
    
    print(f'âœ… åŠ è½½æ•°æ®: æ­£å¸¸{len(normal_samples)}æ¡, å¼‚å¸¸{len(anomaly_samples)}æ¡')
    
    # æ˜¾ç¤ºå¼‚å¸¸ç±»å‹åˆ†å¸ƒ
    anomaly_types = df[df['label'] == 1]['anomaly_type'].value_counts()
    print('ğŸ“Š å¼‚å¸¸ç±»å‹åˆ†å¸ƒ:')
    for atype, count in anomaly_types.items():
        print(f'  {atype}: {count}')
    
except Exception as e:
    print(f'âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}')
    print('ğŸ”§ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...')
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    normal_samples = np.random.normal(
        loc=[8.0, 2.5, 10.0, 0.001, 0.8, 0.95],
        scale=[1.0, 0.5, 2.0, 0.005, 0.2, 0.1],
        size=(50, 6)
    )
    
    anomaly_samples = np.random.normal(
        loc=[2.0, 1.0, 80.0, 0.15, 0.9, 0.6],
        scale=[1.0, 0.5, 20.0, 0.05, 0.1, 0.2],
        size=(50, 6)
    )
    
    print(f'âœ… ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: æ­£å¸¸{len(normal_samples)}æ¡, å¼‚å¸¸{len(anomaly_samples)}æ¡')

# åˆå§‹åŒ–æ¨¡å‹
print('ğŸ¤– åˆå§‹åŒ–AIæ¨¡å‹...')
try:
    # è‡ªç¼–ç å™¨é…ç½®
    autoencoder_config = {
        'input_features': 6,
        'encoding_dim': 3,
        'threshold': 0.489394,
        'model_path': 'models/autoencoder_model_retrained'
    }
    
    autoencoder = AutoencoderModel(
        config=autoencoder_config,
        logger=logger
    )
    print('âœ… è‡ªç¼–ç å™¨åˆå§‹åŒ–æˆåŠŸ')
    
    # åˆ†ç±»å™¨é…ç½®
    classifier_config = {
        'model_path': 'models/rf_classifier_improved.pkl',
        'classes': ['connection_timeout', 'mixed_anomaly', 'network_congestion', 
                   'packet_corruption', 'resource_overload', 'signal_degradation'],
        'confidence_threshold': 0.7
    }
    
    classifier = ErrorClassifier(
        config=classifier_config,
        logger=logger
    )
    print('âœ… åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ')
    
except Exception as e:
    print(f'âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}')
    exit(1)

# æµ‹è¯•è‡ªç¼–ç å™¨æ€§èƒ½
print('\nğŸ¯ æµ‹è¯•è‡ªç¼–ç å™¨æ€§èƒ½...')
print('-' * 40)

# æµ‹è¯•æ­£å¸¸æ•°æ®
print('ğŸ“ˆ æµ‹è¯•æ­£å¸¸æ•°æ®...')
normal_errors = []
normal_predictions = []

for i, sample in enumerate(normal_samples):
    try:
        result = autoencoder.predict(sample)
        is_anomaly = result['is_anomaly']
        error = result['reconstruction_error']
        normal_errors.append(error)
        normal_predictions.append(is_anomaly)
        
        if i < 5:
            print(f'  æ ·æœ¬ {i+1}: é‡æ„è¯¯å·®={error:.6f}, å¼‚å¸¸={is_anomaly}')
            
    except Exception as e:
        print(f'  æ ·æœ¬ {i+1} æµ‹è¯•å¤±è´¥: {e}')

# æµ‹è¯•å¼‚å¸¸æ•°æ®
print('ğŸ“‰ æµ‹è¯•å¼‚å¸¸æ•°æ®...')
anomaly_errors = []
anomaly_predictions = []

for i, sample in enumerate(anomaly_samples):
    try:
        result = autoencoder.predict(sample)
        is_anomaly = result['is_anomaly']
        error = result['reconstruction_error']
        anomaly_errors.append(error)
        anomaly_predictions.append(is_anomaly)
        
        if i < 5:
            print(f'  æ ·æœ¬ {i+1}: é‡æ„è¯¯å·®={error:.6f}, å¼‚å¸¸={is_anomaly}')
            
    except Exception as e:
        print(f'  æ ·æœ¬ {i+1} æµ‹è¯•å¤±è´¥: {e}')

# è®¡ç®—æ€§èƒ½æŒ‡æ ‡
if normal_errors and anomaly_errors:
    normal_accuracy = sum(not pred for pred in normal_predictions) / len(normal_predictions)
    anomaly_accuracy = sum(anomaly_predictions) / len(anomaly_predictions)
    overall_accuracy = (normal_accuracy * len(normal_predictions) + 
                      anomaly_accuracy * len(anomaly_predictions)) / (len(normal_predictions) + len(anomaly_predictions))
    
    print(f'\nğŸ“Š è‡ªç¼–ç å™¨æ€§èƒ½æŒ‡æ ‡:')
    print(f'  å¼‚å¸¸æ£€æµ‹é˜ˆå€¼: {autoencoder.threshold:.6f}')
    print(f'  æ­£å¸¸æ•°æ®å‡†ç¡®ç‡: {normal_accuracy:.3f}')
    print(f'  å¼‚å¸¸æ•°æ®å‡†ç¡®ç‡: {anomaly_accuracy:.3f}')
    print(f'  æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.3f}')
    print(f'  æ­£å¸¸æ•°æ®é‡æ„è¯¯å·®: {np.mean(normal_errors):.6f} Â± {np.std(normal_errors):.6f}')
    print(f'  å¼‚å¸¸æ•°æ®é‡æ„è¯¯å·®: {np.mean(anomaly_errors):.6f} Â± {np.std(anomaly_errors):.6f}')

# æµ‹è¯•åˆ†ç±»å™¨æ€§èƒ½
print('\nğŸ·ï¸ æµ‹è¯•åˆ†ç±»å™¨æ€§èƒ½...')
print('-' * 40)

predictions = []
confidences = []

for i, sample in enumerate(anomaly_samples):
    try:
        result = classifier.classify_error(sample)
        pred_class = result['predicted_class']
        confidence = result['confidence']
        predictions.append(pred_class)
        confidences.append(confidence)
        
        if i < 10:
            print(f'  æ ·æœ¬ {i+1}: ç±»åˆ«={pred_class}, ç½®ä¿¡åº¦={confidence:.3f}')
            
    except Exception as e:
        print(f'  æ ·æœ¬ {i+1} åˆ†ç±»å¤±è´¥: {e}')

# è®¡ç®—åˆ†ç±»æ€§èƒ½
if predictions:
    known_predictions = [p for p in predictions if p != 'unknown']
    unknown_rate = predictions.count('unknown') / len(predictions)
    
    valid_confidences = [c for c in confidences if c > 0]
    avg_confidence = np.mean(valid_confidences) if valid_confidences else 0.0
    
    # ç»Ÿè®¡å„ç±»åˆ«åˆ†å¸ƒ
    class_counts = {}
    for pred in predictions:
        class_counts[pred] = class_counts.get(pred, 0) + 1
    
    print(f'\nğŸ“Š åˆ†ç±»å™¨æ€§èƒ½æŒ‡æ ‡:')
    print(f'  æµ‹è¯•æ ·æœ¬æ•°: {len(predictions)}')
    print(f'  æœ‰æ•ˆé¢„æµ‹æ•°: {len(known_predictions)}')
    print(f'  æœªçŸ¥é¢„æµ‹ç‡: {unknown_rate:.3f}')
    print(f'  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}')
    print(f'  ç±»åˆ«åˆ†å¸ƒ: {class_counts}')

# æµ‹è¯•æ¨ç†é€Ÿåº¦
print('\nâš¡ æµ‹è¯•æ¨ç†é€Ÿåº¦...')
print('-' * 40)

test_sample = normal_samples[0]

# è‡ªç¼–ç å™¨é€Ÿåº¦æµ‹è¯•
print('ğŸ”¥ æµ‹è¯•è‡ªç¼–ç å™¨æ¨ç†é€Ÿåº¦...')
ae_times = []
for i in range(100):
    start_time = time.time()
    try:
        autoencoder.predict(test_sample)
        ae_times.append(time.time() - start_time)
    except Exception as e:
        if i < 5:
            print(f'  æ¨ç†å¤±è´¥ {i+1}: {e}')

# åˆ†ç±»å™¨é€Ÿåº¦æµ‹è¯•
print('ğŸ”¥ æµ‹è¯•åˆ†ç±»å™¨æ¨ç†é€Ÿåº¦...')
clf_times = []
for i in range(100):
    start_time = time.time()
    try:
        classifier.classify_error(test_sample)
        clf_times.append(time.time() - start_time)
    except Exception as e:
        if i < 5:
            print(f'  åˆ†ç±»å¤±è´¥ {i+1}: {e}')

if ae_times and clf_times:
    print(f'\nğŸ“Š æ¨ç†é€Ÿåº¦åŸºå‡†:')
    print(f'  è‡ªç¼–ç å™¨å¹³å‡æ¨ç†æ—¶é—´: {np.mean(ae_times)*1000:.2f}ms Â± {np.std(ae_times)*1000:.2f}ms')
    print(f'  åˆ†ç±»å™¨å¹³å‡æ¨ç†æ—¶é—´: {np.mean(clf_times)*1000:.2f}ms Â± {np.std(clf_times)*1000:.2f}ms')
    print(f'  ç«¯åˆ°ç«¯å¹³å‡æ¨ç†æ—¶é—´: {(np.mean(ae_times) + np.mean(clf_times))*1000:.2f}ms')
    print(f'  ç³»ç»Ÿååé‡: {1.0 / (np.mean(ae_times) + np.mean(clf_times)):.1f} æ ·æœ¬/ç§’')

# ç”Ÿæˆæ€§èƒ½è¯„ä¼°
print('\nğŸ† æ€§èƒ½è¯„ä¼°æ€»ç»“:')
print('=' * 40)

if normal_errors and anomaly_errors and predictions:
    status = "ä¼˜ç§€"
    if overall_accuracy < 0.8:
        status = "éœ€è¦æ”¹è¿›"
    elif unknown_rate > 0.5:
        status = "è‰¯å¥½"
    
    print(f'ğŸ“ˆ è‡ªç¼–ç å™¨æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.3f}')
    print(f'ğŸ·ï¸ åˆ†ç±»å™¨æœªçŸ¥é¢„æµ‹ç‡: {unknown_rate:.3f}')
    print(f'âš¡ ç³»ç»Ÿå¤„ç†é€Ÿåº¦: {1.0 / (np.mean(ae_times) + np.mean(clf_times)):.1f} æ ·æœ¬/ç§’')
    print(f'ğŸ¯ ç³»ç»Ÿå¥åº·çŠ¶æ€: {status}')
    
    # æ€§èƒ½å»ºè®®
    print('\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:')
    if overall_accuracy < 0.9:
        print('  - è€ƒè™‘è°ƒæ•´è‡ªç¼–ç å™¨å¼‚å¸¸æ£€æµ‹é˜ˆå€¼')
    if unknown_rate > 0.3:
        print('  - åˆ†ç±»å™¨å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæ•°æ®')
    if len(ae_times) > 0 and np.mean(ae_times) > 0.1:
        print('  - è€ƒè™‘æ¨¡å‹ä¼˜åŒ–ä»¥æé«˜æ¨ç†é€Ÿåº¦')

print('\nâœ… å…¨é¢æ€§èƒ½æµ‹è¯•å®Œæˆï¼') 