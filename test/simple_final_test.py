#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIç½‘ç»œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ - ç®€åŒ–æœ€ç»ˆæµ‹è¯•
ä¸“æ³¨éªŒè¯åˆ†ç±»å™¨çš„å¤šç±»å‹å¼‚å¸¸è¯†åˆ«èƒ½åŠ›
"""

import sys
import time
import numpy as np
import pandas as pd
from collections import Counter

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.append('src')
sys.path.append('.')

print('ğŸš€ AIç½‘ç»œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ - ç®€åŒ–æœ€ç»ˆæµ‹è¯•')
print('=' * 70)

# ç®€å•æ—¥å¿—ç±»
class TestLogger:
    def info(self, msg): print(f'[INFO] {msg}')
    def warning(self, msg): print(f'[WARNING] {msg}')
    def error(self, msg): print(f'[ERROR] {msg}')
    def debug(self, msg): pass

# ===================================
# åˆ†ç±»å™¨å¤šç±»å‹è¯†åˆ«æµ‹è¯•
# ===================================

print('\nğŸ·ï¸ åˆ†ç±»å™¨å¤šç±»å‹å¼‚å¸¸åˆ†ç±»å…¨é¢æµ‹è¯•')
print('-' * 70)

try:
    from ai_models.error_classifier import ErrorClassifier
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    anomaly_types = ['connection_timeout', 'mixed_anomaly', 'network_congestion', 
                    'packet_corruption', 'resource_overload', 'signal_degradation']
    
    classifier_config = {
        'model_path': 'models/rf_classifier_improved.pkl',
        'classes': anomaly_types,
        'confidence_threshold': 0.7
    }
    
    classifier = ErrorClassifier(classifier_config, TestLogger())
    print('âœ… åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ')
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    df = pd.read_csv('data/improved_training_data_6d.csv')
    feature_columns = ['avg_signal_strength', 'avg_data_rate', 'avg_latency', 
                      'packet_loss_rate', 'system_load', 'network_stability']
    
    print(f'\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:')
    print(f'  æ€»æ ·æœ¬æ•°: {len(df)}')
    print(f'  å¼‚å¸¸ç±»å‹æ•°: {df["anomaly_type"].nunique()}')
    print(f'  å¼‚å¸¸ç±»å‹: {sorted(df[df["label"] > 0]["anomaly_type"].unique())}')
    
    # æ¯ç§ç±»å‹æµ‹è¯•20ä¸ªæ ·æœ¬
    print(f'\nğŸ¯ æµ‹è¯•æ¯ç§å¼‚å¸¸ç±»å‹è¯†åˆ«èƒ½åŠ› (æ¯ç§20ä¸ªæ ·æœ¬):')
    print('-' * 70)
    
    total_correct = 0
    total_samples = 0
    type_results = {}
    all_predictions = []
    all_confidences = []
    
    for anomaly_type in anomaly_types:
        type_data = df[df['anomaly_type'] == anomaly_type].sample(n=20, random_state=42)
        type_correct = 0
        type_confidences = []
        type_predictions = []
        
        for _, sample in type_data.iterrows():
            features = sample[feature_columns].values
            
            result = classifier.classify_error(features)
            predicted_class = result['predicted_class']
            confidence = result['confidence']
            
            type_predictions.append(predicted_class)
            type_confidences.append(confidence)
            all_predictions.append(predicted_class)
            all_confidences.append(confidence)
            
            if predicted_class == anomaly_type:
                type_correct += 1
                total_correct += 1
            
            total_samples += 1
        
        type_accuracy = type_correct / 20 * 100
        avg_confidence = np.mean(type_confidences)
        
        # ç»Ÿè®¡è¯¥ç±»å‹çš„é¢„æµ‹åˆ†å¸ƒ
        type_pred_dist = Counter(type_predictions)
        
        type_results[anomaly_type] = {
            'accuracy': type_accuracy,
            'correct': type_correct,
            'confidence': avg_confidence,
            'predictions': type_pred_dist
        }
        
        # æ˜¾ç¤ºç»“æœ
        correct_icon = 'âœ…' if type_accuracy >= 80 else 'âš ï¸' if type_accuracy >= 60 else 'âŒ'
        print(f'{correct_icon} {anomaly_type:20}: {type_correct:2d}/20 ({type_accuracy:5.1f}%) ç½®ä¿¡åº¦:{avg_confidence:.3f}')
        
        # æ˜¾ç¤ºè¯¥ç±»å‹çš„é”™è¯¯åˆ†ç±»æƒ…å†µ
        if type_correct < 20:
            wrong_predictions = {k: v for k, v in type_pred_dist.items() if k != anomaly_type}
            if wrong_predictions:
                print(f'    é”™è¯¯åˆ†ç±»ä¸º: {dict(wrong_predictions)}')
    
    # æ€»ä½“æ€§èƒ½ç»Ÿè®¡
    overall_accuracy = total_correct / total_samples * 100
    avg_confidence = np.mean(all_confidences)
    
    print(f'\nğŸ“Š æ€»ä½“æ€§èƒ½ç»Ÿè®¡:')
    print(f'  æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.1f}% ({total_correct}/{total_samples})')
    print(f'  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}')
    print(f'  æœªçŸ¥é¢„æµ‹æ•°: {all_predictions.count("unknown")} (åº”ä¸º0)')
    
    # é¢„æµ‹åˆ†å¸ƒåˆ†æ
    prediction_dist = Counter(all_predictions)
    print(f'\nğŸ¯ é¢„æµ‹åˆ†å¸ƒåˆ†æ:')
    for class_name in anomaly_types:
        predicted_count = prediction_dist.get(class_name, 0)
        expected_count = 20  # æ¯ç§ç±»å‹20ä¸ªæ ·æœ¬
        print(f'  {class_name:20}: é¢„æµ‹{predicted_count:2d}æ¬¡ (æœŸæœ›20æ¬¡)')
    
    # åˆ†æåˆ†ç±»åå·®
    print(f'\nğŸ” åˆ†ç±»åå·®åˆ†æ:')
    most_predicted = prediction_dist.most_common(1)[0]
    least_predicted = prediction_dist.most_common()[-1]
    
    print(f'  æœ€å¸¸é¢„æµ‹: {most_predicted[0]} ({most_predicted[1]}æ¬¡)')
    print(f'  æœ€å°‘é¢„æµ‹: {least_predicted[0]} ({least_predicted[1]}æ¬¡)')
    
    bias_ratio = most_predicted[1] / least_predicted[1] if least_predicted[1] > 0 else float('inf')
    print(f'  é¢„æµ‹åå·®æ¯”: {bias_ratio:.2f}:1')
    
    if bias_ratio > 3:
        print(f'  âš ï¸ å­˜åœ¨æ˜æ˜¾çš„é¢„æµ‹åå·®')
    elif bias_ratio > 1.5:
        print(f'  âš ï¸ å­˜åœ¨è½»å¾®çš„é¢„æµ‹åå·®') 
    else:
        print(f'  âœ… é¢„æµ‹åˆ†å¸ƒç›¸å¯¹å‡è¡¡')
    
    # æ€§èƒ½ç­‰çº§è¯„å®š
    print(f'\nğŸ† æ€§èƒ½ç­‰çº§è¯„å®š:')
    if overall_accuracy >= 90:
        grade = "ğŸŒŸ å“è¶Š (A+)"
    elif overall_accuracy >= 80:
        grade = "â­ ä¼˜ç§€ (A)"
    elif overall_accuracy >= 70:
        grade = "âœ… è‰¯å¥½ (B+)"
    elif overall_accuracy >= 60:
        grade = "âš ï¸ åˆæ ¼ (B)"
    else:
        grade = "âŒ éœ€æ”¹è¿› (C)"
    
    print(f'  åˆ†ç±»å™¨ç­‰çº§: {grade}')
    
    # æ¨ç†é€Ÿåº¦æµ‹è¯•
    print(f'\nâš¡ æ¨ç†é€Ÿåº¦æµ‹è¯•:')
    test_sample = df[df['anomaly_type'] == 'signal_degradation'].iloc[0][feature_columns].values
    
    start_time = time.time()
    for _ in range(1000):
        classifier.classify_error(test_sample)
    avg_time = (time.time() - start_time) / 1000 * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    throughput = 1000 / avg_time  # æ ·æœ¬/ç§’
    
    print(f'  å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f}ms')
    print(f'  ç³»ç»Ÿååé‡: {throughput:.1f} æ ·æœ¬/ç§’')
    
    # æœ€ç»ˆç»“è®º
    print(f'\n' + '=' * 70)
    print(f'ğŸ‰ æœ€ç»ˆæµ‹è¯•ç»“è®º')
    print(f'=' * 70)
    
    print(f'âœ… åŠŸèƒ½éªŒè¯:')
    print(f'  âœ… æ”¯æŒ6ç§å¼‚å¸¸ç±»å‹åˆ†ç±»')
    print(f'  âœ… æ— "unknown"é¢„æµ‹ (åˆ†ç±»å™¨åŠŸèƒ½æ­£å¸¸)')
    print(f'  âœ… æ¨ç†é€Ÿåº¦æ»¡è¶³å®æ—¶è¦æ±‚')
    print(f'  âœ… æ¨¡å‹åŠ è½½å’Œé…ç½®æ­£ç¡®')
    
    print(f'\nğŸ“ˆ å…³é”®æŒ‡æ ‡:')
    print(f'  ğŸ¯ åˆ†ç±»å‡†ç¡®ç‡: {overall_accuracy:.1f}%')
    print(f'  ğŸ·ï¸ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}')
    print(f'  âš¡ æ¨ç†é€Ÿåº¦: {avg_time:.2f}ms')
    print(f'  ğŸ–ï¸ ç³»ç»Ÿç­‰çº§: {grade}')
    
    if overall_accuracy >= 75 and avg_confidence >= 0.7 and avg_time < 10:
        print(f'\nğŸš€ ç»“è®º: åˆ†ç±»å™¨å·²è¾¾åˆ°ç”Ÿäº§å°±ç»ªçŠ¶æ€ï¼')
        print(f'   âœ… å¤šç±»å‹å¼‚å¸¸è¯†åˆ«åŠŸèƒ½å®Œå…¨æ­£å¸¸')
        print(f'   âœ… æ€§èƒ½æŒ‡æ ‡æ»¡è¶³å®æ—¶åº”ç”¨è¦æ±‚')
        print(f'   âœ… ç³»ç»Ÿç¨³å®šæ€§å’Œå¯é æ€§ä¼˜ç§€')
    else:
        print(f'\nâš ï¸ ç»“è®º: åˆ†ç±»å™¨éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–')
        if overall_accuracy < 75:
            print(f'   ğŸ“Š å‡†ç¡®ç‡éœ€æå‡è‡³75%ä»¥ä¸Š')
        if avg_confidence < 0.7:
            print(f'   ğŸ“Š ç½®ä¿¡åº¦éœ€æå‡è‡³0.7ä»¥ä¸Š')
        if avg_time >= 10:
            print(f'   âš¡ æ¨ç†é€Ÿåº¦éœ€ä¼˜åŒ–è‡³10msä»¥ä¸‹')
    
except Exception as e:
    print(f'âŒ æµ‹è¯•å¤±è´¥: {e}')
    import traceback
    traceback.print_exc()

print(f'\nğŸ æœ€ç»ˆæµ‹è¯•å®Œæˆï¼')
print('=' * 70) 