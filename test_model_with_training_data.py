#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒæ•°æ®ä¸­çš„å¼‚å¸¸æ ·æœ¬æµ‹è¯•æ¨¡å‹å¤šåˆ†ç±»èƒ½åŠ›
"""
import torch
import numpy as np
from train_multitask_model import MultiTaskAnomalyModel
from train_realistic_end_to_end_networks import generate_realistic_network_data

def test_with_training_data():
    print("ğŸ” ä½¿ç”¨è®­ç»ƒæ•°æ®æµ‹è¯•æ¨¡å‹å¤šåˆ†ç±»èƒ½åŠ›")
    print("=" * 50)
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    X, y_binary, y_multiclass = generate_realistic_network_data(n_samples=1000)
    
    # åŠ è½½æ¨¡å‹
    model = MultiTaskAnomalyModel()
    model.load_state_dict(torch.load("multitask_model.pth", map_location='cpu'))
    model.eval()
    
    # è·å–å¼‚å¸¸æ ·æœ¬
    anomaly_indices = np.where(y_binary == 1)[0]
    anomaly_data = X[anomaly_indices]
    anomaly_labels = y_multiclass[anomaly_indices] - 1  # è½¬æ¢ä¸º0-5
    
    anomaly_types = [
        "wifi_degradation",
        "network_latency", 
        "connection_instability",
        "bandwidth_congestion",
        "system_stress",
        "dns_issues"
    ]
    
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(anomaly_data)}")
    print(f"å¼‚å¸¸ç±»å‹åˆ†å¸ƒ: {np.bincount(anomaly_labels)}")
    
    # æµ‹è¯•æ¯ä¸ªå¼‚å¸¸ç±»å‹
    correct_predictions = 0
    total_predictions = 0
    
    for i, anomaly_type in enumerate(anomaly_types):
        type_indices = np.where(anomaly_labels == i)[0]
        if len(type_indices) == 0:
            continue
            
        type_data = anomaly_data[type_indices]
        type_labels = anomaly_labels[type_indices]
        
        print(f"\nã€{anomaly_type}ã€‘æ ·æœ¬æ•°: {len(type_data)}")
        
        # éšæœºé€‰æ‹©5ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
        test_indices = np.random.choice(len(type_data), min(5, len(type_data)), replace=False)
        
        for idx in test_indices:
            sample = type_data[idx]
            true_label = type_labels[idx]
            
            # æ¨ç†
            input_tensor = torch.FloatTensor(sample).unsqueeze(0)
            with torch.no_grad():
                output = model(input_tensor)
            
            detection_output = output[0, 0:2]
            classification_output = output[0, 2:8]
            
            detection_probs = torch.softmax(detection_output, dim=0)
            classification_probs = torch.softmax(classification_output, dim=0)
            
            predicted_class = torch.argmax(classification_probs).item()
            is_correct = predicted_class == true_label
            
            print(f"  çœŸå®: {anomaly_types[true_label]}, é¢„æµ‹: {anomaly_types[predicted_class]}, æ­£ç¡®: {'âœ…' if is_correct else 'âŒ'}")
            print(f"  å„ç±»å‹æ¦‚ç‡: {[f'{anomaly_types[j]}={classification_probs[j]:.3f}' for j in range(6)]}")
            
            if is_correct:
                correct_predictions += 1
            total_predictions += 1
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"  æ€»é¢„æµ‹æ•°: {total_predictions}")
    print(f"  æ­£ç¡®é¢„æµ‹: {correct_predictions}")
    print(f"  å‡†ç¡®ç‡: {correct_predictions/total_predictions*100:.2f}%")

if __name__ == "__main__":
    test_with_training_data() 