#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®é™…æ•°æ®æµ‹è¯•è„šæœ¬

ç”¨äºå…¨é¢æµ‹è¯•å·²è®­ç»ƒçš„AIå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿï¼š
1. äº¤äº’å¼å•æ¬¡æµ‹è¯•
2. æ‰¹é‡æ•°æ®æµ‹è¯•
3. æ€§èƒ½åŸºå‡†æµ‹è¯•
4. æ¨¡æ‹ŸçœŸå®åœºæ™¯æµ‹è¯•

ä½¿ç”¨æ–¹æ³•ï¼š
- äº¤äº’å¼æµ‹è¯•: python scripts/test_with_real_data.py --interactive
- æ‰¹é‡æµ‹è¯•: python scripts/test_with_real_data.py --batch
- æ€§èƒ½æµ‹è¯•: python scripts/test_with_real_data.py --benchmark
- åœºæ™¯æµ‹è¯•: python scripts/test_with_real_data.py --scenarios
- å®Œæ•´æµ‹è¯•: python scripts/test_with_real_data.py --all
"""

import os
import sys
import json
import argparse
import time
import numpy as np
import pandas as pd
from typing import Dict, List, Any
from pathlib import Path

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.logger.system_logger import SystemLogger
from src.ai_models.autoencoder_model import AutoencoderModel
from src.ai_models.error_classifier import ErrorClassifier
from src.anomaly_detector.anomaly_engine import AnomalyDetectionEngine
from src.feature_processor.feature_extractor import FeatureExtractor

class RealDataTester:
    """å®é™…æ•°æ®æµ‹è¯•å™¨"""
    
    def __init__(self, config_path="config/system_config.json"):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.config = self._load_config(config_path)
        self.logger = SystemLogger(self.config['logging'])
        self.logger.set_log_level('INFO')
        
        # åˆå§‹åŒ–ç»„ä»¶ - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„11ä¸ªçœŸå®ç½‘ç»œæŒ‡æ ‡
        real_metrics = [
            'wlan0_wireless_quality', 'wlan0_signal_level', 'wlan0_noise_level',
            'wlan0_rx_packets', 'wlan0_tx_packets', 'wlan0_rx_bytes', 'wlan0_tx_bytes',
            'gateway_ping_time', 'dns_resolution_time', 'memory_usage_percent', 'cpu_usage_percent'
        ]
        self.feature_extractor = FeatureExtractor(
            real_metrics, 
            self.logger,
            scaler_path=os.path.join(self.config['ai_models']['autoencoder']['model_path'], 'autoencoder_scaler.pkl')
        )
        
        self.autoencoder = AutoencoderModel(
            self.config['ai_models']['autoencoder'], 
            self.logger
        )
        
        self.classifier = ErrorClassifier(
            self.config['ai_models']['classifier'], 
            self.logger
        )
        
        self.engine = AnomalyDetectionEngine(
            config=self.config['anomaly_detection'],
            autoencoder=self.autoencoder,
            error_classifier=self.classifier,
            buffer_manager=None,
            logger=self.logger
        )
        
        # æµ‹è¯•ç»Ÿè®¡
        self.test_results = []
        
        print("ğŸš€ AIå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæµ‹è¯•å™¨å·²åˆå§‹åŒ–")
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ é…ç½®æ–‡ä»¶ '{config_path}' æœªæ‰¾åˆ°")
            sys.exit(1)
        except json.JSONDecodeError:
            print(f"âŒ é…ç½®æ–‡ä»¶ '{config_path}' æ ¼å¼é”™è¯¯")
            sys.exit(1)
    
    def interactive_test(self):
        """äº¤äº’å¼å•æ¬¡æµ‹è¯•"""
        print("\n" + "="*50)
        print("ğŸ” äº¤äº’å¼AIå¼‚å¸¸æ£€æµ‹æµ‹è¯•")
        print("="*50)
        
        # åŠ è½½é»˜è®¤æ•°æ®
        default_data = self._get_default_data()
        
        print("\nğŸ“ è¯·è¾“å…¥ç½‘ç»œæŒ‡æ ‡æ•°æ®ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰:")
        input_data = {}
        
        for key, default_value in default_data.items():
            while True:
                try:
                    prompt = f"  {key} (é»˜è®¤: {default_value}): "
                    user_input = input(prompt).strip()
                    
                    if not user_input:
                        input_data[key] = default_value
                        break
                    
                    input_data[key] = float(user_input)
                    break
                except ValueError:
                    print("    âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
                except KeyboardInterrupt:
                    print("\n\nğŸ‘‹ æµ‹è¯•å·²å–æ¶ˆ")
                    return
        
        # æ‰§è¡Œæ£€æµ‹
        result = self._perform_detection(input_data, "äº¤äº’å¼æµ‹è¯•")
        self._display_single_result(result)
    
    def batch_test(self):
        """æ‰¹é‡æ•°æ®æµ‹è¯•"""
        print("\n" + "="*50)
        print("ğŸ“Š æ‰¹é‡æ•°æ®æµ‹è¯•")
        print("="*50)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®é›†
        test_cases = self._generate_test_cases()
        
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯• {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹...")
        
        results = []
        for i, (name, data) in enumerate(test_cases.items(), 1):
            print(f"\n[{i}/{len(test_cases)}] æµ‹è¯•: {name}")
            result = self._perform_detection(data, name)
            results.append(result)
            
            # æ˜¾ç¤ºç®€è¦ç»“æœ
            status = "ğŸ”´ å¼‚å¸¸" if result['is_anomaly'] else "ğŸŸ¢ æ­£å¸¸"
            if result['is_anomaly']:
                print(f"  ç»“æœ: {status} ({result['details'].get('predicted_class', 'unknown')})")
            else:
                print(f"  ç»“æœ: {status}")
        
        # æ˜¾ç¤ºæ‰¹é‡æµ‹è¯•æ€»ç»“
        self._display_batch_summary(results)
    
    def benchmark_test(self):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\n" + "="*50)
        print("âš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("="*50)
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        normal_data = self._get_default_data()
        test_sizes = [1, 10, 50, 100, 500]
        
        print("ğŸ”¥ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•...")
        
        for size in test_sizes:
            print(f"\næµ‹è¯•æ‰¹é‡å¤§å°: {size}")
            
            # å‡†å¤‡æ•°æ®
            batch_data = [normal_data.copy() for _ in range(size)]
            
            # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
            start_time = time.time()
            for data in batch_data:
                self._perform_detection(data, f"benchmark_{size}")
            end_time = time.time()
            
            total_time = end_time - start_time
            avg_time_per_sample = total_time / size
            throughput = size / total_time
            
            print(f"  æ€»æ—¶é—´: {total_time:.3f}s")
            print(f"  å¹³å‡æ¯æ ·æœ¬: {avg_time_per_sample:.4f}s")
            print(f"  ååé‡: {throughput:.1f} samples/s")
    
    def scenario_test(self):
        """æ¨¡æ‹ŸçœŸå®åœºæ™¯æµ‹è¯•"""
        print("\n" + "="*50)
        print("ğŸ­ çœŸå®åœºæ™¯æ¨¡æ‹Ÿæµ‹è¯•")
        print("="*50)
        
        scenarios = self._get_realistic_scenarios()
        
        print(f"ğŸ¬ æµ‹è¯• {len(scenarios)} ä¸ªçœŸå®åœºæ™¯...")
        
        for i, (scenario_name, scenario_data) in enumerate(scenarios.items(), 1):
            print(f"\n[{i}/{len(scenarios)}] åœºæ™¯: {scenario_name}")
            print(f"  æè¿°: {scenario_data.get('description', 'æ— æè¿°')}")
            
            result = self._perform_detection(scenario_data['data'], scenario_name)
            
            # æ˜¾ç¤ºåœºæ™¯ç»“æœ
            expected = scenario_data.get('expected_anomaly', None)
            actual = result['is_anomaly']
            
            if expected is not None:
                if expected == actual:
                    print(f"  âœ… é¢„æœŸ: {'å¼‚å¸¸' if expected else 'æ­£å¸¸'}, å®é™…: {'å¼‚å¸¸' if actual else 'æ­£å¸¸'}")
                else:
                    print(f"  âŒ é¢„æœŸ: {'å¼‚å¸¸' if expected else 'æ­£å¸¸'}, å®é™…: {'å¼‚å¸¸' if actual else 'æ­£å¸¸'}")
            else:
                print(f"  ğŸ“‹ æ£€æµ‹ç»“æœ: {'ğŸ”´ å¼‚å¸¸' if actual else 'ğŸŸ¢ æ­£å¸¸'}")
            
            if result['is_anomaly']:
                predicted_class = result['details'].get('predicted_class', 'unknown')
                confidence = result['details'].get('confidence', 0.0)
                print(f"  ğŸ¯ å¼‚å¸¸ç±»å‹: {predicted_class} (ç½®ä¿¡åº¦: {confidence:.2%})")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("\n" + "="*60)
        print("ğŸš€ è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶")
        print("="*60)
        
        print("\n1ï¸âƒ£ æ‰¹é‡æ•°æ®æµ‹è¯•")
        self.batch_test()
        
        print("\n2ï¸âƒ£ æ€§èƒ½åŸºå‡†æµ‹è¯•")
        self.benchmark_test()
        
        print("\n3ï¸âƒ£ çœŸå®åœºæ™¯æµ‹è¯•")
        self.scenario_test()
        
        print("\n" + "="*60)
        print("âœ… å®Œæ•´æµ‹è¯•å¥—ä»¶æ‰§è¡Œå®Œæ¯•")
        print("="*60)
    
    def _perform_detection(self, input_data: Dict, test_name: str) -> Dict:
        """æ‰§è¡Œå¼‚å¸¸æ£€æµ‹"""
        start_time = time.time()
        
        try:
            # å°†11ä¸ªå®é™…ç½‘ç»œæŒ‡æ ‡è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            metrics_data = {
                'wlan0_wireless_quality': input_data.get('wlan0_wireless_quality', 70.0),
                'wlan0_signal_level': input_data.get('wlan0_wireless_level', -55.0),
                'wlan0_noise_level': input_data.get('wlan0_noise_level', -95.0),
                'wlan0_rx_packets': input_data.get('wlan0_recv_rate_bps', 1500000.0) / 1000,
                'wlan0_tx_packets': input_data.get('wlan0_send_rate_bps', 500000.0) / 1000,
                'wlan0_rx_bytes': input_data.get('wlan0_recv_rate_bps', 1500000.0),
                'wlan0_tx_bytes': input_data.get('wlan0_send_rate_bps', 500000.0),
                'gateway_ping_time': input_data.get('gateway_ping_time', 12.5),
                'dns_resolution_time': input_data.get('dns_response_time', 25.0),
                'memory_usage_percent': input_data.get('memory_percent', 45.0),
                'cpu_usage_percent': input_data.get('cpu_percent', 15.0)
            }
            
            # ä½¿ç”¨FeatureExtractoræå–24ç»´ç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰
            feature_vector = self.feature_extractor.extract_features(metrics_data)
            
            if feature_vector.size == 0:
                return {
                    'test_name': test_name,
                    'is_anomaly': False,
                    'error': 'ç‰¹å¾æå–å¤±è´¥',
                    'detection_time': time.time() - start_time
                }
            
            # ä½¿ç”¨è®­ç»ƒæ—¶çš„ç‰¹å¾åç§°ï¼ˆ24ä¸ªç‰¹å¾ï¼‰
            feature_names = [f'feature_{i}' for i in range(len(feature_vector))]
            
            # å¼‚å¸¸æ£€æµ‹
            is_anomaly, details = self.engine.detect_anomaly_from_vector(
                feature_vector, feature_names
            )
            
            detection_time = time.time() - start_time
            
            result = {
                'test_name': test_name,
                'is_anomaly': is_anomaly,
                'details': details,
                'detection_time': detection_time,
                'input_data': input_data,
                'feature_vector': feature_vector.tolist()
            }
            
            self.test_results.append(result)
            return result
            
        except Exception as e:
            return {
                'test_name': test_name,
                'is_anomaly': False,
                'error': str(e),
                'detection_time': time.time() - start_time
            }
    
    # åˆ é™¤è¿™ä¸ªæ–¹æ³•ï¼Œä¸å†éœ€è¦æ‰‹å·¥æ˜ å°„ç‰¹å¾
    # ç°åœ¨ç»Ÿä¸€ä½¿ç”¨FeatureExtractorè¿›è¡Œ24ç»´ç‰¹å¾æå–
    
    def _display_single_result(self, result: Dict):
        """æ˜¾ç¤ºå•ä¸ªæ£€æµ‹ç»“æœ"""
        print("\n" + "="*40)
        print("ğŸ” æ£€æµ‹ç»“æœ")
        print("="*40)
        
        if 'error' in result:
            print(f"âŒ é”™è¯¯: {result['error']}")
            return
        
        # åŸºæœ¬ä¿¡æ¯
        status = "ğŸ”´ æ£€æµ‹åˆ°å¼‚å¸¸!" if result['is_anomaly'] else "ğŸŸ¢ ä¸€åˆ‡æ­£å¸¸"
        print(f"çŠ¶æ€: {status}")
        print(f"æ£€æµ‹è€—æ—¶: {result['detection_time']:.4f}s")
        
        if result['is_anomaly']:
            details = result['details']
            predicted_class = details.get('predicted_class', 'unknown')
            confidence = details.get('confidence', 0.0)
            
            print(f"å¼‚å¸¸ç±»å‹: {predicted_class}")
            print(f"ç½®ä¿¡åº¦: {confidence:.2%}")
        
        # æŠ€æœ¯è¯¦æƒ…
        details = result['details']
        reconstruction_error = details.get('reconstruction_error', 'N/A')
        threshold = details.get('threshold', 'N/A')
        
        print(f"\nğŸ“Š æŠ€æœ¯æŒ‡æ ‡:")
        print(f"  é‡æ„è¯¯å·®: {reconstruction_error}")
        print(f"  å¼‚å¸¸é˜ˆå€¼: {threshold}")
        
        if isinstance(reconstruction_error, (int, float)) and isinstance(threshold, (int, float)):
            anomaly_score = reconstruction_error / threshold
            print(f"  å¼‚å¸¸åˆ†æ•°: {anomaly_score:.3f}")
    
    def _display_batch_summary(self, results: List[Dict]):
        """æ˜¾ç¤ºæ‰¹é‡æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*40)
        print("ğŸ“Š æ‰¹é‡æµ‹è¯•æ€»ç»“")
        print("="*40)
        
        total_tests = len(results)
        anomaly_count = sum(1 for r in results if r.get('is_anomaly', False))
        normal_count = total_tests - anomaly_count
        error_count = sum(1 for r in results if 'error' in r)
        
        avg_time = np.mean([r.get('detection_time', 0) for r in results])
        
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"æ­£å¸¸æ ·æœ¬: {normal_count} ({normal_count/total_tests*100:.1f}%)")
        print(f"å¼‚å¸¸æ ·æœ¬: {anomaly_count} ({anomaly_count/total_tests*100:.1f}%)")
        print(f"é”™è¯¯æ•°: {error_count}")
        print(f"å¹³å‡æ£€æµ‹æ—¶é—´: {avg_time:.4f}s")
        
        # å¼‚å¸¸ç±»å‹åˆ†å¸ƒ
        if anomaly_count > 0:
            anomaly_types = {}
            for r in results:
                if r.get('is_anomaly', False) and 'details' in r:
                    predicted_class = r['details'].get('predicted_class', 'unknown')
                    anomaly_types[predicted_class] = anomaly_types.get(predicted_class, 0) + 1
            
            print(f"\nğŸ¯ å¼‚å¸¸ç±»å‹åˆ†å¸ƒ:")
            for anomaly_type, count in anomaly_types.items():
                print(f"  {anomaly_type}: {count} ({count/anomaly_count*100:.1f}%)")
    
    def _get_default_data(self) -> Dict:
        """è·å–é»˜è®¤æµ‹è¯•æ•°æ®"""
        return {
            'wlan0_wireless_quality': 70.0,
            'wlan0_wireless_level': -55.0,
            'wlan0_packet_loss_rate': 0.01,
            'wlan0_send_rate_bps': 500000.0,
            'wlan0_recv_rate_bps': 1500000.0,
            'tcp_retrans_segments': 5,
            'gateway_ping_time': 12.5,
            'dns_response_time': 25.0,
            'tcp_connection_count': 30,
            'cpu_percent': 15.0,
            'memory_percent': 45.0
        }
    
    def _generate_test_cases(self) -> Dict[str, Dict]:
        """ç”Ÿæˆæ‰¹é‡æµ‹è¯•ç”¨ä¾‹"""
        base_data = self._get_default_data()
        test_cases = {}
        
        # æ­£å¸¸æƒ…å†µ
        test_cases['æ­£å¸¸_æ ‡å‡†'] = base_data.copy()
        
        # è½»å¾®å˜åŒ–çš„æ­£å¸¸æƒ…å†µ
        normal_variant = base_data.copy()
        normal_variant['cpu_percent'] = 20.0
        normal_variant['memory_percent'] = 50.0
        test_cases['æ­£å¸¸_è½»å¾®å˜åŒ–'] = normal_variant
        
        # å„ç§å¼‚å¸¸æƒ…å†µ
        # CPUè¿‡è½½
        cpu_overload = base_data.copy()
        cpu_overload['cpu_percent'] = 95.0
        cpu_overload['memory_percent'] = 80.0
        test_cases['CPUè¿‡è½½'] = cpu_overload
        
        # ç½‘ç»œå»¶è¿Ÿå¼‚å¸¸
        high_latency = base_data.copy()
        high_latency['gateway_ping_time'] = 500.0
        high_latency['dns_response_time'] = 1000.0
        test_cases['ç½‘ç»œå»¶è¿Ÿå¼‚å¸¸'] = high_latency
        
        # æ•°æ®åŒ…ä¸¢å¤±å¼‚å¸¸
        packet_loss = base_data.copy()
        packet_loss['wlan0_packet_loss_rate'] = 0.15
        packet_loss['tcp_retrans_segments'] = 50
        test_cases['æ•°æ®åŒ…ä¸¢å¤±å¼‚å¸¸'] = packet_loss
        
        # ä¿¡å·è´¨é‡å·®
        poor_signal = base_data.copy()
        poor_signal['wlan0_wireless_quality'] = 20.0
        poor_signal['wlan0_wireless_level'] = -85.0
        test_cases['ä¿¡å·è´¨é‡å·®'] = poor_signal
        
        # å¸¦å®½å¼‚å¸¸
        bandwidth_issue = base_data.copy()
        bandwidth_issue['wlan0_send_rate_bps'] = 50000.0
        bandwidth_issue['wlan0_recv_rate_bps'] = 100000.0
        test_cases['å¸¦å®½å¼‚å¸¸'] = bandwidth_issue
        
        return test_cases
    
    def _get_realistic_scenarios(self) -> Dict[str, Dict]:
        """è·å–çœŸå®åœºæ™¯æµ‹è¯•æ•°æ®"""
        base_data = self._get_default_data()
        scenarios = {}
        
        # åœºæ™¯1: è§†é¢‘ä¼šè®®æœŸé—´ç½‘ç»œæ‹¥å¡
        video_call_congestion = {
            'description': 'è§†é¢‘ä¼šè®®æœŸé—´ç½‘ç»œæ‹¥å¡ï¼Œå»¶è¿Ÿå¢åŠ ',
            'expected_anomaly': True,
            'data': {
                **base_data,
                'gateway_ping_time': 150.0,
                'dns_response_time': 200.0,
                'wlan0_packet_loss_rate': 0.08,
                'tcp_connection_count': 45
            }
        }
        scenarios['è§†é¢‘ä¼šè®®ç½‘ç»œæ‹¥å¡'] = video_call_congestion
        
        # åœºæ™¯2: æ·±å¤œæ­£å¸¸æµè§ˆ
        night_browsing = {
            'description': 'æ·±å¤œæ­£å¸¸ç½‘é¡µæµè§ˆï¼Œç³»ç»Ÿè´Ÿè½½ä½',
            'expected_anomaly': False,
            'data': {
                **base_data,
                'cpu_percent': 8.0,
                'memory_percent': 35.0,
                'tcp_connection_count': 15,
                'gateway_ping_time': 8.0
            }
        }
        scenarios['æ·±å¤œæ­£å¸¸æµè§ˆ'] = night_browsing
        
        # åœºæ™¯3: ä¸‹è½½å¤§æ–‡ä»¶æ—¶ç³»ç»Ÿå¼‚å¸¸
        large_download_issue = {
            'description': 'ä¸‹è½½å¤§æ–‡ä»¶æ—¶å‡ºç°ç³»ç»Ÿèµ„æºå¼‚å¸¸',
            'expected_anomaly': True,
            'data': {
                **base_data,
                'cpu_percent': 85.0,
                'memory_percent': 90.0,
                'wlan0_recv_rate_bps': 2000000.0,
                'tcp_connection_count': 8
            }
        }
        scenarios['å¤§æ–‡ä»¶ä¸‹è½½å¼‚å¸¸'] = large_download_issue
        
        # åœºæ™¯4: ç§»åŠ¨è®¾å¤‡æ¼«æ¸¸
        mobile_roaming = {
            'description': 'ç§»åŠ¨è®¾å¤‡åœ¨ä¸åŒWiFié—´æ¼«æ¸¸',
            'expected_anomaly': None,  # ä¸ç¡®å®šæ˜¯å¦åº”è¯¥è¢«æ£€æµ‹ä¸ºå¼‚å¸¸
            'data': {
                **base_data,
                'wlan0_wireless_quality': 45.0,
                'wlan0_wireless_level': -70.0,
                'gateway_ping_time': 35.0,
                'wlan0_packet_loss_rate': 0.03
            }
        }
        scenarios['è®¾å¤‡æ¼«æ¸¸'] = mobile_roaming
        
        return scenarios

    def test_realistic_scenarios(self, scenarios_file: str = "data/realistic_test_scenarios.json"):
        """æµ‹è¯•çœŸå®é”™è¯¯åœºæ™¯æ•°æ®"""
        print("\n" + "="*60)
        print("ğŸŒ çœŸå®ç½‘ç»œé”™è¯¯åœºæ™¯æµ‹è¯•")
        print("="*60)
        
        try:
            # åŠ è½½åœºæ™¯æ•°æ®
            with open(scenarios_file, 'r', encoding='utf-8') as f:
                scenarios = json.load(f)
            
            print(f"ğŸ“Š åŠ è½½äº† {len(scenarios)} ä¸ªçœŸå®åœºæ™¯")
            
            # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
            results_by_type = {}
            all_results = []
            
            print(f"\nğŸ§ª å¼€å§‹é€ä¸ªæµ‹è¯•åœºæ™¯...")
            
            for i, scenario in enumerate(scenarios, 1):
                scenario_name = scenario['name']
                scenario_type = scenario.get('expected_type', 'unknown')
                expected_anomaly = scenario.get('expected_anomaly', None)
                
                print(f"\n[{i}/{len(scenarios)}] æµ‹è¯•: {scenario_name}")
                print(f"  ç±»å‹: {scenario_type}")
                print(f"  æè¿°: {scenario['description']}")
                
                # æ‰§è¡Œæ£€æµ‹
                result = self._perform_detection(scenario['data'], scenario_name)
                result['scenario_type'] = scenario_type
                result['expected_anomaly'] = expected_anomaly
                
                all_results.append(result)
                
                # æŒ‰ç±»å‹åˆ†ç»„
                if scenario_type not in results_by_type:
                    results_by_type[scenario_type] = []
                results_by_type[scenario_type].append(result)
                
                # æ˜¾ç¤ºç»“æœ
                actual_anomaly = result.get('is_anomaly', False)
                if expected_anomaly is not None:
                    if expected_anomaly == actual_anomaly:
                        status_icon = "âœ…"
                    else:
                        status_icon = "âŒ"
                    print(f"  {status_icon} é¢„æœŸ: {'å¼‚å¸¸' if expected_anomaly else 'æ­£å¸¸'}, å®é™…: {'å¼‚å¸¸' if actual_anomaly else 'æ­£å¸¸'}")
                else:
                    status_icon = "ğŸ”´" if actual_anomaly else "ğŸŸ¢"
                    print(f"  {status_icon} æ£€æµ‹ç»“æœ: {'å¼‚å¸¸' if actual_anomaly else 'æ­£å¸¸'}")
                
                if actual_anomaly:
                    predicted_class = result['details'].get('predicted_class', 'unknown')
                    confidence = result['details'].get('confidence', 0.0)
                    print(f"  ğŸ¯ æ£€æµ‹ç±»å‹: {predicted_class} (ç½®ä¿¡åº¦: {confidence:.1%})")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸é¢„æœŸç±»å‹åŒ¹é…
                    if scenario_type in predicted_class or predicted_class in scenario_type:
                        print(f"  ğŸ¯ ç±»å‹åŒ¹é…: ç¬¦åˆé¢„æœŸ")
                    else:
                        print(f"  âš ï¸  ç±»å‹å·®å¼‚: é¢„æœŸ {scenario_type}, æ£€æµ‹åˆ° {predicted_class}")
            
            # æ˜¾ç¤ºè¯¦ç»†åˆ†æç»“æœ
            self._display_realistic_scenario_analysis(all_results, results_by_type)
            
        except FileNotFoundError:
            print(f"âŒ åœºæ™¯æ–‡ä»¶æœªæ‰¾åˆ°: {scenarios_file}")
            print("è¯·å…ˆè¿è¡Œ python scripts/generate_realistic_test_data.py ç”Ÿæˆæµ‹è¯•æ•°æ®")
        except json.JSONDecodeError:
            print(f"âŒ åœºæ™¯æ–‡ä»¶æ ¼å¼é”™è¯¯: {scenarios_file}")
        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    
    def _display_realistic_scenario_analysis(self, all_results: List[Dict], results_by_type: Dict):
        """æ˜¾ç¤ºçœŸå®åœºæ™¯æµ‹è¯•åˆ†æç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“ˆ çœŸå®åœºæ™¯æµ‹è¯•åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        total_scenarios = len(all_results)
        anomaly_count = sum(1 for r in all_results if r.get('is_anomaly', False))
        normal_count = total_scenarios - anomaly_count
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"  æ€»åœºæ™¯æ•°: {total_scenarios}")
        print(f"  æ£€æµ‹ä¸ºå¼‚å¸¸: {anomaly_count} ({anomaly_count/total_scenarios*100:.1f}%)")
        print(f"  æ£€æµ‹ä¸ºæ­£å¸¸: {normal_count} ({normal_count/total_scenarios*100:.1f}%)")
        
        # é¢„æœŸvså®é™…å¯¹æ¯”
        with_expectation = [r for r in all_results if r.get('expected_anomaly') is not None]
        if with_expectation:
            correct_predictions = sum(1 for r in with_expectation 
                                    if r.get('expected_anomaly') == r.get('is_anomaly'))
            accuracy = correct_predictions / len(with_expectation) * 100
            print(f"\nğŸ¯ é¢„æµ‹å‡†ç¡®æ€§:")
            print(f"  æœ‰é¢„æœŸç»“æœçš„åœºæ™¯: {len(with_expectation)}")
            print(f"  é¢„æµ‹æ­£ç¡®: {correct_predictions}")
            print(f"  å‡†ç¡®ç‡: {accuracy:.1f}%")
        
        # æŒ‰é”™è¯¯ç±»å‹åˆ†æ
        print(f"\nğŸ” é”™è¯¯ç±»å‹æ£€æµ‹åˆ†æ:")
        for error_type, type_results in sorted(results_by_type.items()):
            anomalies_in_type = sum(1 for r in type_results if r.get('is_anomaly', False))
            detection_rate = anomalies_in_type / len(type_results) * 100
            
            print(f"\n  {error_type} ({len(type_results)} ä¸ªåœºæ™¯):")
            print(f"    æ£€æµ‹ç‡: {anomalies_in_type}/{len(type_results)} ({detection_rate:.1f}%)")
            
            # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„AIæ¨¡å‹åˆ†ç±»
            detected_classes = {}
            for r in type_results:
                if r.get('is_anomaly', False):
                    predicted_class = r['details'].get('predicted_class', 'unknown')
                    detected_classes[predicted_class] = detected_classes.get(predicted_class, 0) + 1
            
            if detected_classes:
                print(f"    AIåˆ†ç±»ç»“æœ:")
                for ai_class, count in sorted(detected_classes.items()):
                    print(f"      {ai_class}: {count} æ¬¡")
        
        # æ€§èƒ½ç»Ÿè®¡
        avg_time = np.mean([r.get('detection_time', 0) for r in all_results])
        print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¹³å‡æ£€æµ‹æ—¶é—´: {avg_time:.4f}s")
        print(f"  æ€»æ£€æµ‹æ—¶é—´: {sum(r.get('detection_time', 0) for r in all_results):.3f}s")
        
        # å»ºè®®å’Œæ€»ç»“
        print(f"\nğŸ’¡ åˆ†æå»ºè®®:")
        
        # æ£€æµ‹æ•æ„Ÿæ€§åˆ†æ
        if anomaly_count / total_scenarios > 0.8:
            print("  ğŸ“ˆ ç³»ç»Ÿæ£€æµ‹æ•æ„Ÿæ€§è¾ƒé«˜ï¼Œå€¾å‘äºå®‰å…¨ä¼˜å…ˆç­–ç•¥")
        elif anomaly_count / total_scenarios < 0.3:
            print("  ğŸ“‰ ç³»ç»Ÿæ£€æµ‹æ•æ„Ÿæ€§è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨æ¼æ£€é£é™©")
        else:
            print("  âš–ï¸  ç³»ç»Ÿæ£€æµ‹æ•æ„Ÿæ€§é€‚ä¸­")
        
        # ç±»å‹åŒ¹é…åˆ†æ
        normal_scenarios = [r for r in all_results if r.get('scenario_type', '').startswith('normal')]
        if normal_scenarios:
            false_positive_rate = sum(1 for r in normal_scenarios if r.get('is_anomaly', False)) / len(normal_scenarios)
            if false_positive_rate > 0.5:
                print("  âš ï¸  æ­£å¸¸åœºæ™¯è¯¯æŠ¥ç‡è¾ƒé«˜ï¼Œå»ºè®®è°ƒæ•´æ£€æµ‹é˜ˆå€¼")
        
        print(f"\nğŸ¯ å»ºè®®ä¸‹ä¸€æ­¥:")
        print(f"  1. æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´å¼‚å¸¸æ£€æµ‹é˜ˆå€¼")
        print(f"  2. é’ˆå¯¹ç‰¹å®šé”™è¯¯ç±»å‹ä¼˜åŒ–ç‰¹å¾æ˜ å°„")
        print(f"  3. æ”¶é›†æ›´å¤šçœŸå®åœºæ™¯æ•°æ®è¿›è¡Œæ¨¡å‹å¾®è°ƒ")
        print(f"  4. è€ƒè™‘ä¸ºä¸åŒåº”ç”¨ç¯å¢ƒè®¾ç½®ä¸åŒçš„æ£€æµ‹å‚æ•°")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AIå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿå®é™…æ•°æ®æµ‹è¯•å·¥å…·")
    parser.add_argument('--interactive', action='store_true', help='è¿è¡Œäº¤äº’å¼å•æ¬¡æµ‹è¯•')
    parser.add_argument('--batch', action='store_true', help='è¿è¡Œæ‰¹é‡æ•°æ®æµ‹è¯•')
    parser.add_argument('--benchmark', action='store_true', help='è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•')
    parser.add_argument('--scenarios', action='store_true', help='è¿è¡ŒçœŸå®åœºæ™¯æµ‹è¯•')
    parser.add_argument('--realistic', action='store_true', help='è¿è¡ŒçœŸå®é”™è¯¯åœºæ™¯æµ‹è¯•')
    parser.add_argument('--file', type=str, default='data/realistic_test_scenarios.json', 
                       help='çœŸå®åœºæ™¯æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰æµ‹è¯•')
    
    args = parser.parse_args()
    
    try:
        tester = RealDataTester()
        
        if args.interactive:
            tester.interactive_test()
        elif args.batch:
            tester.batch_test()
        elif args.benchmark:
            tester.benchmark_test()
        elif args.scenarios:
            tester.scenario_test()
        elif args.realistic:
            tester.test_realistic_scenarios(args.file)
        elif args.all:
            tester.run_all_tests()
            # ä¹Ÿè¿è¡ŒçœŸå®åœºæ™¯æµ‹è¯•
            print("\n4ï¸âƒ£ çœŸå®é”™è¯¯åœºæ™¯æµ‹è¯•")
            tester.test_realistic_scenarios(args.file)
        else:
            # é»˜è®¤è¿è¡Œäº¤äº’å¼æµ‹è¯•
            print("æœªæŒ‡å®šæµ‹è¯•æ¨¡å¼ï¼Œè¿è¡Œäº¤äº’å¼æµ‹è¯•...")
            print("ä½¿ç”¨ --help æŸ¥çœ‹æ‰€æœ‰å¯ç”¨é€‰é¡¹")
            tester.interactive_test()
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æµ‹è¯•å·²å–æ¶ˆ")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 