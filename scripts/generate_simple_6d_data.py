#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç®€åŒ–çš„6ç»´ç‰¹å¾æ•°æ®ç”Ÿæˆå™¨

ç›´æ¥ç”Ÿæˆ6ç»´ç‰¹å¾æ•°æ®ï¼Œä¸é€šè¿‡FeatureExtractorè¿›è¡Œå¤„ç†
åŸºäºçœŸå®ç½‘ç»œæ€§èƒ½æŒ‡æ ‡çš„æ­£å¸¸å’Œå¼‚å¸¸æ¨¡å¼
"""

import os
import numpy as np
import pandas as pd
from pathlib import Path

# é…ç½®å‚æ•°
NUM_NORMAL_SAMPLES = 15000
NUM_ANOMALY_SAMPLES_PER_TYPE = 300

# 6ä¸ªæ ¸å¿ƒç‰¹å¾åç§°ï¼ˆä¸FeatureExtractor._convert_to_vectorä¸­çš„é¡ºåºä¸€è‡´ï¼‰
FEATURE_NAMES = [
    'avg_signal_strength',  # å¹³å‡ä¿¡å·å¼ºåº¦
    'avg_data_rate',        # å¹³å‡æ•°æ®ä¼ è¾“é€Ÿç‡
    'avg_latency',          # å¹³å‡ç½‘ç»œå»¶è¿Ÿ
    'total_packet_loss',    # æ€»ä¸¢åŒ…ç‡
    'cpu_usage',            # CPUä½¿ç”¨ç‡
    'memory_usage'          # å†…å­˜ä½¿ç”¨ç‡
]

# å¼‚å¸¸ç±»å‹
ANOMALY_TYPES = [
    'signal_degradation',   # ä¿¡å·è¡°å‡
    'network_congestion',   # ç½‘ç»œæ‹¥å¡
    'connection_timeout',   # è¿æ¥è¶…æ—¶
    'packet_corruption',    # æ•°æ®åŒ…æŸå
    'resource_overload',    # èµ„æºè¿‡è½½
    'mixed_anomaly'         # æ··åˆå¼‚å¸¸
]

def generate_normal_features():
    """ç”Ÿæˆæ­£å¸¸çš„6ç»´ç‰¹å¾æ•°æ®"""
    # åŸºäºçœŸå®ç½‘ç»œæ€§èƒ½æŒ‡æ ‡çš„æ­£å¸¸èŒƒå›´
    features = np.random.normal(size=(NUM_NORMAL_SAMPLES, 6))
    
    # ä¸ºæ¯ä¸ªç‰¹å¾è®¾ç½®åˆç†çš„å‡å€¼å’Œæ ‡å‡†å·®
    # avg_signal_strength: ä¿¡å·å¼ºåº¦ (70-90)
    features[:, 0] = features[:, 0] * 5 + 80
    
    # avg_data_rate: æ•°æ®ä¼ è¾“é€Ÿç‡ (æ­£å¸¸åŒ–åˆ°0-1èŒƒå›´)
    features[:, 1] = (features[:, 1] * 0.15 + 0.6)  # 0.45-0.75å·¦å³
    
    # avg_latency: ç½‘ç»œå»¶è¿Ÿ (10-30ms)
    features[:, 2] = np.abs(features[:, 2]) * 8 + 15
    
    # total_packet_loss: ä¸¢åŒ…ç‡ (0.001-0.05)
    features[:, 3] = np.abs(features[:, 3]) * 0.02 + 0.01
    
    # cpu_usage: CPUä½¿ç”¨ç‡ (5-30%)
    features[:, 4] = np.abs(features[:, 4]) * 8 + 15
    
    # memory_usage: å†…å­˜ä½¿ç”¨ç‡ (30-70%)
    features[:, 5] = np.abs(features[:, 5]) * 12 + 50
    
    return features

def generate_anomaly_features(anomaly_type, num_samples):
    """ç”ŸæˆæŒ‡å®šç±»å‹çš„å¼‚å¸¸ç‰¹å¾æ•°æ®"""
    features = np.random.normal(size=(num_samples, 6))
    
    if anomaly_type == 'signal_degradation':
        # ä¿¡å·è¡°å‡ï¼šä¿¡å·å¼ºåº¦ä½ï¼Œä¼ è¾“é€Ÿç‡ä¸‹é™ï¼Œå»¶è¿Ÿå¢åŠ 
        features[:, 0] = features[:, 0] * 8 + 30   # ä¿¡å·å¼ºåº¦ 15-45
        features[:, 1] = features[:, 1] * 0.1 + 0.2  # ä¼ è¾“é€Ÿç‡ä½ 0.1-0.3
        features[:, 2] = np.abs(features[:, 2]) * 30 + 80  # å»¶è¿Ÿé«˜ 50-140ms
        features[:, 3] = np.abs(features[:, 3]) * 0.1 + 0.15  # ä¸¢åŒ…ç‡é«˜
        features[:, 4] = np.abs(features[:, 4]) * 8 + 15   # CPUæ­£å¸¸
        features[:, 5] = np.abs(features[:, 5]) * 12 + 50  # å†…å­˜æ­£å¸¸
        
    elif anomaly_type == 'network_congestion':
        # ç½‘ç»œæ‹¥å¡ï¼šé«˜ä¸¢åŒ…ç‡ï¼Œé«˜å»¶è¿Ÿï¼Œä¼ è¾“é€Ÿç‡ä¸‹é™
        features[:, 0] = features[:, 0] * 6 + 55   # ä¿¡å·å¼ºåº¦ä¸­ç­‰ 45-65
        features[:, 1] = features[:, 1] * 0.12 + 0.25  # ä¼ è¾“é€Ÿç‡ä½
        features[:, 2] = np.abs(features[:, 2]) * 25 + 90  # å»¶è¿Ÿé«˜ 65-140ms
        features[:, 3] = np.abs(features[:, 3]) * 0.15 + 0.2  # ä¸¢åŒ…ç‡å¾ˆé«˜
        features[:, 4] = np.abs(features[:, 4]) * 10 + 20  # CPUç¨é«˜
        features[:, 5] = np.abs(features[:, 5]) * 12 + 50  # å†…å­˜æ­£å¸¸
        
    elif anomaly_type == 'connection_timeout':
        # è¿æ¥è¶…æ—¶ï¼šæé«˜å»¶è¿Ÿï¼Œä¼ è¾“é€Ÿç‡ä¸¥é‡ä¸‹é™
        features[:, 0] = features[:, 0] * 8 + 60   # ä¿¡å·å¼ºåº¦ä¸­ç­‰ 50-70
        features[:, 1] = features[:, 1] * 0.08 + 0.1  # ä¼ è¾“é€Ÿç‡æä½
        features[:, 2] = np.abs(features[:, 2]) * 50 + 200  # å»¶è¿Ÿæé«˜ 150-350ms
        features[:, 3] = np.abs(features[:, 3]) * 0.2 + 0.3  # ä¸¢åŒ…ç‡æé«˜
        features[:, 4] = np.abs(features[:, 4]) * 8 + 15   # CPUæ­£å¸¸
        features[:, 5] = np.abs(features[:, 5]) * 12 + 50  # å†…å­˜æ­£å¸¸
        
    elif anomaly_type == 'packet_corruption':
        # æ•°æ®åŒ…æŸåï¼šä¸­ç­‰ä¸¢åŒ…ç‡ï¼Œä¼ è¾“å—å½±å“
        features[:, 0] = features[:, 0] * 10 + 50  # ä¿¡å·å¼ºåº¦ä¸­ç­‰ 40-60
        features[:, 1] = features[:, 1] * 0.15 + 0.35  # ä¼ è¾“é€Ÿç‡ä¸­ç­‰ 0.2-0.5
        features[:, 2] = np.abs(features[:, 2]) * 20 + 40  # å»¶è¿Ÿä¸­ç­‰ 20-80ms
        features[:, 3] = np.abs(features[:, 3]) * 0.08 + 0.08  # ä¸¢åŒ…ç‡ä¸­é«˜
        features[:, 4] = np.abs(features[:, 4]) * 8 + 15   # CPUæ­£å¸¸
        features[:, 5] = np.abs(features[:, 5]) * 12 + 50  # å†…å­˜æ­£å¸¸
        
    elif anomaly_type == 'resource_overload':
        # èµ„æºè¿‡è½½ï¼šCPUå’Œå†…å­˜ä½¿ç”¨ç‡æé«˜
        features[:, 0] = features[:, 0] * 6 + 70   # ä¿¡å·å¼ºåº¦æ­£å¸¸ 60-80
        features[:, 1] = features[:, 1] * 0.15 + 0.45  # ä¼ è¾“é€Ÿç‡ç¨ä½
        features[:, 2] = np.abs(features[:, 2]) * 15 + 35  # å»¶è¿Ÿç¨é«˜ 20-65ms
        features[:, 3] = np.abs(features[:, 3]) * 0.03 + 0.02  # ä¸¢åŒ…ç‡ç¨é«˜
        features[:, 4] = np.abs(features[:, 4]) * 8 + 85   # CPUæé«˜ 80-95%
        features[:, 5] = np.abs(features[:, 5]) * 8 + 88   # å†…å­˜æé«˜ 85-95%
        
    elif anomaly_type == 'mixed_anomaly':
        # æ··åˆå¼‚å¸¸ï¼šå¤šä¸ªæŒ‡æ ‡åŒæ—¶å¼‚å¸¸
        features[:, 0] = features[:, 0] * 10 + 35  # ä¿¡å·å¼ºåº¦ä½ 25-45
        features[:, 1] = features[:, 1] * 0.12 + 0.2  # ä¼ è¾“é€Ÿç‡ä½
        features[:, 2] = np.abs(features[:, 2]) * 40 + 120  # å»¶è¿Ÿé«˜ 80-200ms
        features[:, 3] = np.abs(features[:, 3]) * 0.12 + 0.15  # ä¸¢åŒ…ç‡é«˜
        features[:, 4] = np.abs(features[:, 4]) * 15 + 70  # CPUé«˜ 60-85%
        features[:, 5] = np.abs(features[:, 5]) * 15 + 75  # å†…å­˜é«˜ 65-90%
    
    # ç¡®ä¿æ‰€æœ‰å€¼åœ¨åˆç†èŒƒå›´å†…
    features[:, 0] = np.clip(features[:, 0], 10, 100)  # ä¿¡å·å¼ºåº¦
    features[:, 1] = np.clip(features[:, 1], 0.05, 1.0)  # ä¼ è¾“é€Ÿç‡
    features[:, 2] = np.clip(features[:, 2], 5, 500)     # å»¶è¿Ÿ
    features[:, 3] = np.clip(features[:, 3], 0.001, 0.8) # ä¸¢åŒ…ç‡
    features[:, 4] = np.clip(features[:, 4], 5, 100)     # CPUä½¿ç”¨ç‡
    features[:, 5] = np.clip(features[:, 5], 20, 100)    # å†…å­˜ä½¿ç”¨ç‡
    
    return features

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆç®€åŒ–6ç»´ç‰¹å¾æ•°æ®...")
    
    # åˆ›å»ºdataç›®å½•
    data_dir = Path('data')
    data_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ­£å¸¸æ•°æ®
    print(f"ğŸ“Š ç”Ÿæˆ {NUM_NORMAL_SAMPLES} æ¡æ­£å¸¸æ•°æ®...")
    normal_features = generate_normal_features()
    normal_df = pd.DataFrame(normal_features, columns=FEATURE_NAMES)
    
    # ä¿å­˜æ­£å¸¸æ•°æ®
    normal_file = data_dir / '6d_normal_traffic.csv'
    normal_df.to_csv(normal_file, index=False)
    print(f"âœ… æ­£å¸¸æ•°æ®å·²ä¿å­˜åˆ°: {normal_file}")
    
    # ç”Ÿæˆå¼‚å¸¸æ•°æ®
    print(f"ğŸ“Š ç”Ÿæˆå¼‚å¸¸æ•°æ®ï¼Œæ¯ç§ç±»å‹ {NUM_ANOMALY_SAMPLES_PER_TYPE} æ¡...")
    anomaly_data = []
    anomaly_labels = []
    
    for anomaly_type in ANOMALY_TYPES:
        print(f"   - ç”Ÿæˆ {anomaly_type} æ•°æ®...")
        anomaly_features = generate_anomaly_features(anomaly_type, NUM_ANOMALY_SAMPLES_PER_TYPE)
        anomaly_data.append(anomaly_features)
        anomaly_labels.extend([anomaly_type] * NUM_ANOMALY_SAMPLES_PER_TYPE)
    
    # åˆå¹¶æ‰€æœ‰å¼‚å¸¸æ•°æ®
    all_anomaly_features = np.vstack(anomaly_data)
    anomaly_df = pd.DataFrame(all_anomaly_features, columns=FEATURE_NAMES)
    anomaly_df['anomaly_type'] = anomaly_labels
    
    # ä¿å­˜å¼‚å¸¸æ•°æ®
    anomaly_file = data_dir / '6d_labeled_anomalies.csv'
    anomaly_df.to_csv(anomaly_file, index=False)
    print(f"âœ… å¼‚å¸¸æ•°æ®å·²ä¿å­˜åˆ°: {anomaly_file}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ æ•°æ®ç”Ÿæˆæ‘˜è¦:")
    print(f"æ­£å¸¸æ•°æ®: {len(normal_df)} æ¡")
    print(f"å¼‚å¸¸æ•°æ®: {len(anomaly_df)} æ¡")
    print(f"ç‰¹å¾ç»´åº¦: {len(FEATURE_NAMES)}")
    print(f"å¼‚å¸¸ç±»å‹: {len(ANOMALY_TYPES)} ç§")
    
    print(f"\nğŸ“Š æ­£å¸¸æ•°æ®ç»Ÿè®¡:")
    print(normal_df.describe())
    
    print(f"\nğŸ“Š å¼‚å¸¸æ•°æ®ç»Ÿè®¡:")
    print(anomaly_df.groupby('anomaly_type').size())
    
    print(f"\nğŸ¯ 6ç»´ç‰¹å¾æ•°æ®ç”Ÿæˆå®Œæˆ!")
    print(f"ä¸‹ä¸€æ­¥ï¼šé‡æ–°è®­ç»ƒæ¨¡å‹")
    print(f"  python3 scripts/train_model.py autoencoder --data_path {normal_file}")
    print(f"  python3 scripts/train_model.py classifier --data_path {anomaly_file}")

if __name__ == "__main__":
    main() 