#!/usr/bin/env python3
"""
æ”¹è¿›æ¨¡å‹æµ‹è¯•è„šæœ¬
éªŒè¯æ–°è®­ç»ƒçš„6ç»´æ¨¡å‹çš„æ£€æµ‹æ•ˆæœå’Œä¸åŒé˜ˆå€¼ç­–ç•¥
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import joblib
import json
import os
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
import seaborn as sns

def load_improved_model():
    """åŠ è½½æ”¹è¿›çš„æ¨¡å‹ç»„ä»¶"""
    print("ğŸ”„ åŠ è½½æ”¹è¿›çš„æ¨¡å‹ç»„ä»¶...")
    
    # åŠ è½½è‡ªç¼–ç å™¨
    autoencoder_path = 'models/autoencoder_model_improved/autoencoder_model.keras'
    autoencoder = tf.keras.models.load_model(autoencoder_path)
    print(f"âœ… è‡ªç¼–ç å™¨å·²åŠ è½½: {autoencoder_path}")
    
    # åŠ è½½æ ‡å‡†åŒ–å™¨
    scaler_path = 'models/autoencoder_model_improved/autoencoder_scaler.pkl'
    scaler = joblib.load(scaler_path)
    print(f"âœ… æ ‡å‡†åŒ–å™¨å·²åŠ è½½: {scaler_path}")
    
    # åŠ è½½é˜ˆå€¼é…ç½®
    threshold_path = 'models/autoencoder_model_improved/threshold_config.json'
    with open(threshold_path, 'r') as f:
        threshold_config = json.load(f)
    print(f"âœ… é˜ˆå€¼é…ç½®å·²åŠ è½½: {threshold_path}")
    
    # åŠ è½½åˆ†ç±»å™¨
    classifier_path = 'models/rf_classifier_improved.pkl'
    classifier = joblib.load(classifier_path)
    print(f"âœ… åˆ†ç±»å™¨å·²åŠ è½½: {classifier_path}")
    
    return autoencoder, scaler, threshold_config, classifier

def generate_test_samples():
    """ç”Ÿæˆæµ‹è¯•æ ·æœ¬"""
    print("ğŸ“Š ç”Ÿæˆæµ‹è¯•æ ·æœ¬...")
    
    test_samples = []
    
    # æ­£å¸¸æ ·æœ¬
    for i in range(5):
        sample = {
            'name': f'æ­£å¸¸æ ·æœ¬{i+1}',
            'type': 'normal',
            'data': np.array([
                np.random.normal(7.0, 1.0),    # avg_signal_strength (æ­£å¸¸èŒƒå›´)
                np.random.normal(2.5, 0.3),    # avg_data_rate
                np.random.normal(15.0, 3.0),   # avg_latency
                np.random.normal(0.02, 0.01),  # packet_loss_rate
                np.random.normal(0.3, 0.1),    # system_load
                np.random.normal(0.85, 0.05)   # network_stability
            ])
        }
        test_samples.append(sample)
    
    # ä¿¡å·é™çº§å¼‚å¸¸
    for i in range(3):
        sample = {
            'name': f'ä¿¡å·é™çº§å¼‚å¸¸{i+1}',
            'type': 'signal_degradation',
            'data': np.array([
                np.random.normal(3.0, 0.5),    # ä¿¡å·å¼±
                np.random.normal(1.5, 0.3),    # æ•°æ®ç‡ä½
                np.random.normal(25.0, 5.0),   # å»¶è¿Ÿé«˜
                np.random.normal(0.08, 0.02),  # ä¸¢åŒ…å¤š
                np.random.normal(0.3, 0.1),    # ç³»ç»Ÿè´Ÿè½½æ­£å¸¸
                np.random.normal(0.6, 0.1)     # ç¨³å®šæ€§å·®
            ])
        }
        test_samples.append(sample)
    
    # ç½‘ç»œæ‹¥å µå¼‚å¸¸
    for i in range(3):
        sample = {
            'name': f'ç½‘ç»œæ‹¥å µå¼‚å¸¸{i+1}',
            'type': 'network_congestion',
            'data': np.array([
                np.random.normal(6.5, 0.5),    # ä¿¡å·æ­£å¸¸
                np.random.normal(1.2, 0.2),    # æ•°æ®ç‡æä½
                np.random.normal(40.0, 8.0),   # å»¶è¿Ÿæé«˜
                np.random.normal(0.12, 0.03),  # ä¸¢åŒ…ä¸¥é‡
                np.random.normal(0.7, 0.1),    # è´Ÿè½½é«˜
                np.random.normal(0.4, 0.1)     # å¾ˆä¸ç¨³å®š
            ])
        }
        test_samples.append(sample)
    
    # èµ„æºè¿‡è½½å¼‚å¸¸
    for i in range(3):
        sample = {
            'name': f'èµ„æºè¿‡è½½å¼‚å¸¸{i+1}',
            'type': 'resource_overload',
            'data': np.array([
                np.random.normal(6.5, 0.5),    # ä¿¡å·æ­£å¸¸
                np.random.normal(1.8, 0.3),    # æ•°æ®ç‡åä½
                np.random.normal(35.0, 6.0),   # å»¶è¿Ÿé«˜
                np.random.normal(0.06, 0.02),  # ä¸¢åŒ…åå¤š
                np.random.normal(0.9, 0.05),   # æé«˜è´Ÿè½½
                np.random.normal(0.65, 0.1)    # ç¨³å®šæ€§å·®
            ])
        }
        test_samples.append(sample)
    
    # ç¡®ä¿æ•°å€¼åœ¨åˆç†èŒƒå›´å†…
    for sample in test_samples:
        data = sample['data']
        data[0] = np.clip(data[0], 0.5, 10.0)   # signal_strength
        data[1] = np.clip(data[1], 0.1, 5.0)    # data_rate
        data[2] = np.clip(data[2], 1.0, 100.0)  # latency
        data[3] = np.clip(data[3], 0.0, 0.5)    # packet_loss
        data[4] = np.clip(data[4], 0.0, 1.0)    # system_load
        data[5] = np.clip(data[5], 0.0, 1.0)    # network_stability
        sample['data'] = data
    
    print(f"âœ… ç”Ÿæˆäº† {len(test_samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
    return test_samples

def test_anomaly_detection(autoencoder, scaler, threshold_config, classifier, test_samples):
    """æµ‹è¯•å¼‚å¸¸æ£€æµ‹æ•ˆæœ"""
    print("\nğŸ§ª å¼€å§‹å¼‚å¸¸æ£€æµ‹æµ‹è¯•...")
    
    feature_names = [
        'avg_signal_strength', 'avg_data_rate', 'avg_latency',
        'packet_loss_rate', 'system_load', 'network_stability'
    ]
    
    anomaly_types = [
        'signal_degradation', 'network_congestion', 'connection_timeout',
        'packet_corruption', 'resource_overload', 'mixed_anomaly'
    ]
    
    results = []
    
    print("=" * 100)
    print(f"{'æ ·æœ¬åç§°':<20} {'é¢„æœŸç±»å‹':<15} {'é‡æ„è¯¯å·®':<12} {'æ˜¯å¦å¼‚å¸¸':<8} {'å¼‚å¸¸ç±»å‹':<15} {'ç½®ä¿¡åº¦':<8}")
    print("=" * 100)
    
    for sample in test_samples:
        # æ ‡å‡†åŒ–æ•°æ®
        data_scaled = scaler.transform(sample['data'].reshape(1, -1))
        
        # è®¡ç®—é‡æ„è¯¯å·®
        reconstruction = autoencoder.predict(data_scaled, verbose=0)
        mse = np.mean((data_scaled - reconstruction) ** 2)
        
        # æµ‹è¯•ä¸åŒé˜ˆå€¼ç­–ç•¥
        threshold_results = {}
        for threshold_name, threshold_value in threshold_config['all_thresholds'].items():
            is_anomaly = mse > threshold_value
            threshold_results[threshold_name] = is_anomaly
        
        # ä½¿ç”¨é»˜è®¤é˜ˆå€¼ï¼ˆ95%ï¼‰
        default_threshold = threshold_config['selected_threshold']
        is_anomaly = mse > default_threshold
        
        # å¦‚æœæ£€æµ‹ä¸ºå¼‚å¸¸ï¼Œè¿›è¡Œåˆ†ç±»
        predicted_class = 'normal'
        confidence = 0.0
        
        if is_anomaly:
            try:
                class_probs = classifier.predict_proba(data_scaled)[0]
                predicted_class_idx = np.argmax(class_probs)
                predicted_class = anomaly_types[predicted_class_idx]
                confidence = class_probs[predicted_class_idx]
            except:
                predicted_class = 'unknown'
                confidence = 0.0
        
        # è®°å½•ç»“æœ
        result = {
            'name': sample['name'],
            'expected_type': sample['type'],
            'mse': mse,
            'is_anomaly': is_anomaly,
            'predicted_class': predicted_class,
            'confidence': confidence,
            'threshold_results': threshold_results,
            'data': sample['data']
        }
        results.append(result)
        
        # æ˜¾ç¤ºç»“æœ
        anomaly_status = "ğŸš¨å¼‚å¸¸" if is_anomaly else "âœ…æ­£å¸¸"
        print(f"{sample['name']:<20} {sample['type']:<15} {mse:<12.6f} {anomaly_status:<8} {predicted_class:<15} {confidence:<8.3f}")
    
    print("=" * 100)
    return results

def analyze_threshold_strategies(results, threshold_config):
    """åˆ†æä¸åŒé˜ˆå€¼ç­–ç•¥çš„æ•ˆæœ"""
    print("\nğŸ“Š é˜ˆå€¼ç­–ç•¥åˆ†æ...")
    
    threshold_analysis = {}
    
    for threshold_name, threshold_value in threshold_config['all_thresholds'].items():
        true_positives = 0  # æ­£ç¡®è¯†åˆ«çš„å¼‚å¸¸
        false_positives = 0  # è¯¯æŠ¥ï¼ˆæ­£å¸¸è¯†åˆ«ä¸ºå¼‚å¸¸ï¼‰
        true_negatives = 0   # æ­£ç¡®è¯†åˆ«çš„æ­£å¸¸
        false_negatives = 0  # æ¼æŠ¥ï¼ˆå¼‚å¸¸è¯†åˆ«ä¸ºæ­£å¸¸ï¼‰
        
        for result in results:
            is_anomaly_predicted = result['threshold_results'][threshold_name]
            is_anomaly_actual = result['expected_type'] != 'normal'
            
            if is_anomaly_actual and is_anomaly_predicted:
                true_positives += 1
            elif not is_anomaly_actual and is_anomaly_predicted:
                false_positives += 1
            elif not is_anomaly_actual and not is_anomaly_predicted:
                true_negatives += 1
            elif is_anomaly_actual and not is_anomaly_predicted:
                false_negatives += 1
        
        # è®¡ç®—æŒ‡æ ‡
        total_anomalies = true_positives + false_negatives
        total_normal = true_negatives + false_positives
        
        sensitivity = true_positives / total_anomalies if total_anomalies > 0 else 0
        specificity = true_negatives / total_normal if total_normal > 0 else 0
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        accuracy = (true_positives + true_negatives) / len(results)
        
        threshold_analysis[threshold_name] = {
            'threshold_value': threshold_value,
            'sensitivity': sensitivity,      # æ£€å‡ºç‡
            'specificity': specificity,      # ç‰¹å¼‚æ€§
            'precision': precision,          # ç²¾ç¡®ç‡
            'accuracy': accuracy,            # å‡†ç¡®ç‡
            'false_positive_rate': 1 - specificity,
            'true_positives': true_positives,
            'false_positives': false_positives,
            'true_negatives': true_negatives,
            'false_negatives': false_negatives
        }
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    print(f"\n{'ç­–ç•¥åç§°':<15} {'é˜ˆå€¼':<12} {'æ£€å‡ºç‡':<8} {'è¯¯æŠ¥ç‡':<8} {'ç²¾ç¡®ç‡':<8} {'å‡†ç¡®ç‡':<8}")
    print("-" * 70)
    
    for name, analysis in threshold_analysis.items():
        print(f"{name:<15} {analysis['threshold_value']:<12.6f} "
              f"{analysis['sensitivity']:<8.3f} {analysis['false_positive_rate']:<8.3f} "
              f"{analysis['precision']:<8.3f} {analysis['accuracy']:<8.3f}")
    
    return threshold_analysis

def test_classification_accuracy(results):
    """æµ‹è¯•åˆ†ç±»å‡†ç¡®æ€§"""
    print("\nğŸ¯ å¼‚å¸¸åˆ†ç±»å‡†ç¡®æ€§åˆ†æ...")
    
    # ç»Ÿè®¡åˆ†ç±»ç»“æœ
    classification_results = {}
    total_anomalies = 0
    correct_classifications = 0
    
    for result in results:
        if result['expected_type'] != 'normal' and result['is_anomaly']:
            total_anomalies += 1
            expected = result['expected_type']
            predicted = result['predicted_class']
            
            if expected not in classification_results:
                classification_results[expected] = {'total': 0, 'correct': 0, 'predictions': {}}
            
            classification_results[expected]['total'] += 1
            
            if predicted not in classification_results[expected]['predictions']:
                classification_results[expected]['predictions'][predicted] = 0
            classification_results[expected]['predictions'][predicted] += 1
            
            if expected == predicted:
                classification_results[expected]['correct'] += 1
                correct_classifications += 1
    
    # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
    print(f"\n{'é¢„æœŸç±»å‹':<20} {'æ€»æ•°':<6} {'æ­£ç¡®':<6} {'å‡†ç¡®ç‡':<8} {'ä¸»è¦é¢„æµ‹'}")
    print("-" * 60)
    
    for anomaly_type, stats in classification_results.items():
        accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
        main_prediction = max(stats['predictions'].items(), key=lambda x: x[1])[0] if stats['predictions'] else 'N/A'
        print(f"{anomaly_type:<20} {stats['total']:<6} {stats['correct']:<6} {accuracy:<8.3f} {main_prediction}")
    
    overall_accuracy = correct_classifications / total_anomalies if total_anomalies > 0 else 0
    print(f"\nğŸ“ˆ æ•´ä½“åˆ†ç±»å‡†ç¡®ç‡: {overall_accuracy:.3f} ({correct_classifications}/{total_anomalies})")
    
    return classification_results

def display_feature_analysis(results):
    """æ˜¾ç¤ºç‰¹å¾åˆ†æ"""
    print("\nğŸ“ˆ ç‰¹å¾å€¼åˆ†æ...")
    
    feature_names = [
        'avg_signal_strength', 'avg_data_rate', 'avg_latency',
        'packet_loss_rate', 'system_load', 'network_stability'
    ]
    
    # æŒ‰ç±»å‹åˆ†ç»„
    normal_features = []
    anomaly_features = []
    
    for result in results:
        if result['expected_type'] == 'normal':
            normal_features.append(result['data'])
        else:
            anomaly_features.append(result['data'])
    
    if normal_features and anomaly_features:
        normal_features = np.array(normal_features)
        anomaly_features = np.array(anomaly_features)
        
        print(f"\n{'ç‰¹å¾åç§°':<20} {'æ­£å¸¸å‡å€¼':<10} {'å¼‚å¸¸å‡å€¼':<10} {'å·®å¼‚':<8}")
        print("-" * 50)
        
        for i, feature_name in enumerate(feature_names):
            normal_mean = np.mean(normal_features[:, i])
            anomaly_mean = np.mean(anomaly_features[:, i])
            difference = abs(anomaly_mean - normal_mean)
            
            print(f"{feature_name:<20} {normal_mean:<10.3f} {anomaly_mean:<10.3f} {difference:<8.3f}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ æ”¹è¿›æ¨¡å‹æ•ˆæœæµ‹è¯•")
    print("=" * 50)
    
    try:
        # åŠ è½½æ¨¡å‹
        autoencoder, scaler, threshold_config, classifier = load_improved_model()
        
        # ç”Ÿæˆæµ‹è¯•æ ·æœ¬
        test_samples = generate_test_samples()
        
        # æ‰§è¡Œå¼‚å¸¸æ£€æµ‹æµ‹è¯•
        results = test_anomaly_detection(autoencoder, scaler, threshold_config, classifier, test_samples)
        
        # åˆ†æé˜ˆå€¼ç­–ç•¥
        threshold_analysis = analyze_threshold_strategies(results, threshold_config)
        
        # æµ‹è¯•åˆ†ç±»å‡†ç¡®æ€§
        classification_results = test_classification_accuracy(results)
        
        # ç‰¹å¾åˆ†æ
        display_feature_analysis(results)
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
        print(f"   - æµ‹è¯•æ ·æœ¬æ€»æ•°: {len(test_samples)}")
        print(f"   - æ­£å¸¸æ ·æœ¬: {len([r for r in results if r['expected_type'] == 'normal'])}")
        print(f"   - å¼‚å¸¸æ ·æœ¬: {len([r for r in results if r['expected_type'] != 'normal'])}")
        print(f"   - å¯ç”¨é˜ˆå€¼ç­–ç•¥: {len(threshold_config['all_thresholds'])}")
        
        # æ¨èæœ€ä½³é˜ˆå€¼ç­–ç•¥
        best_strategy = None
        best_score = 0
        
        for name, analysis in threshold_analysis.items():
            # å¹³è¡¡æ£€å‡ºç‡å’Œè¯¯æŠ¥ç‡çš„å¾—åˆ†
            score = analysis['sensitivity'] * 0.7 + (1 - analysis['false_positive_rate']) * 0.3
            if score > best_score:
                best_score = score
                best_strategy = name
        
        if best_strategy:
            print(f"\nğŸ’¡ æ¨èé˜ˆå€¼ç­–ç•¥: {best_strategy}")
            print(f"   æ£€å‡ºç‡: {threshold_analysis[best_strategy]['sensitivity']:.3f}")
            print(f"   è¯¯æŠ¥ç‡: {threshold_analysis[best_strategy]['false_positive_rate']:.3f}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 