#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¯¦ç»†åˆ†æå„åœºæ™¯çš„ç‰¹å¾å€¼åˆ†å¸ƒ
æ‰¾å‡ºå¼‚å¸¸åœºæ™¯è®¾è®¡çš„é—®é¢˜æ‰€åœ¨
"""

import sys
import os
import json
import numpy as np
import pandas as pd
from pathlib import Path

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.feature_processor.feature_extractor import FeatureExtractor

def load_test_scenarios():
    """åŠ è½½æ‰€æœ‰æµ‹è¯•åœºæ™¯"""
    scenarios = [
        {"id": 1, "name": "æ­£å¸¸ç½‘ç»œçŠ¶æ€", "type": "normal", "expected": "normal"},
        {"id": 2, "name": "è½»è´Ÿè½½çŠ¶æ€", "type": "normal_light_load", "expected": "normal"},
        {"id": 3, "name": "é«˜è´Ÿè½½æ­£å¸¸çŠ¶æ€", "type": "normal_high_load", "expected": "normal"},
        {"id": 4, "name": "WiFiä¿¡å·è¡°å‡", "type": "signal_degradation", "expected": "anomaly"},
        {"id": 5, "name": "å¸¦å®½é¥±å’Œ", "type": "bandwidth_saturation", "expected": "anomaly"},
        {"id": 6, "name": "DDoSæ”»å‡»", "type": "ddos_attack", "expected": "anomaly"},
        {"id": 7, "name": "DNSé…ç½®é”™è¯¯", "type": "dns_misconfiguration", "expected": "anomaly"},
        {"id": 8, "name": "CPUè¿‡è½½", "type": "cpu_overload", "expected": "anomaly"}
    ]
    return scenarios

def create_scenario_data(scenario_type: str):
    """æ ¹æ®åœºæ™¯ç±»å‹åˆ›å»ºæµ‹è¯•æ•°æ®"""
    base_data = {
        'wlan0_wireless_quality': 85.0,
        'wlan0_signal_level': -45.0,
        'wlan0_noise_level': -90.0,
        'wlan0_rx_packets': 50000,
        'wlan0_tx_packets': 30000,
        'wlan0_rx_bytes': 75000000,
        'wlan0_tx_bytes': 25000000,
        'gateway_ping_time': 8.5,
        'dns_resolution_time': 15.2,
        'memory_usage_percent': 35.0,
        'cpu_usage_percent': 12.0
    }
    
    # æ ¹æ®åœºæ™¯ç±»å‹è°ƒæ•´æ•°æ®
    if scenario_type in ['normal', 'normal_light_load']:
        return base_data
    elif scenario_type == 'normal_high_load':
        base_data.update({
            'wlan0_rx_packets': 120000,
            'wlan0_tx_packets': 80000,
            'cpu_usage_percent': 45.0,
            'memory_usage_percent': 60.0
        })
    elif scenario_type == 'signal_degradation':
        base_data.update({
            'wlan0_wireless_quality': 35.0,
            'wlan0_signal_level': -75.0,
            'wlan0_noise_level': -85.0
        })
    elif scenario_type == 'bandwidth_saturation':
        base_data.update({
            'wlan0_rx_bytes': 150000000,
            'wlan0_tx_bytes': 80000000,
            'gateway_ping_time': 25.0
        })
    elif scenario_type == 'ddos_attack':
        base_data.update({
            'wlan0_rx_packets': 500000,
            'wlan0_tx_packets': 200000,
            'gateway_ping_time': 100.0,
            'cpu_usage_percent': 85.0
        })
    elif scenario_type == 'dns_misconfiguration':
        base_data.update({
            'dns_resolution_time': 5000.0,
            'gateway_ping_time': 12.0
        })
    elif scenario_type == 'cpu_overload':
        base_data.update({
            'cpu_usage_percent': 95.0,
            'memory_usage_percent': 80.0,
            'gateway_ping_time': 30.0
        })
    
    return base_data

def analyze_feature_distributions():
    """åˆ†æå„åœºæ™¯çš„ç‰¹å¾åˆ†å¸ƒ"""
    try:
        # åŠ è½½é…ç½®
        config_path = os.path.join(project_root, 'config', 'system_config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # åˆ›å»ºç®€å•çš„æ—¥å¿—å¯¹è±¡
        class SimpleLogger:
            def info(self, msg): pass
            def error(self, msg): print(f"ERROR: {msg}")
            def debug(self, msg): pass
            def warning(self, msg): pass
        
        logger = SimpleLogger()
        
        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        real_metrics = [
            'wlan0_wireless_quality', 'wlan0_signal_level', 'wlan0_noise_level',
            'wlan0_rx_packets', 'wlan0_tx_packets', 'wlan0_rx_bytes', 'wlan0_tx_bytes',
            'gateway_ping_time', 'dns_resolution_time', 'memory_usage_percent', 'cpu_usage_percent'
        ]
        
        scaler_path = os.path.join(config['ai_models']['autoencoder']['model_path'], 'autoencoder_scaler.pkl')
        feature_extractor = FeatureExtractor(real_metrics, logger, scaler_path=scaler_path)
        
        # åŠ è½½æµ‹è¯•åœºæ™¯
        scenarios = load_test_scenarios()
        
        # æ”¶é›†åŸå§‹æ•°æ®å’Œç‰¹å¾æ•°æ®
        raw_data_list = []
        feature_data_list = []
        
        print("ğŸ” è¯¦ç»†ç‰¹å¾åˆ†æ")
        print("=" * 80)
        
        for scenario in scenarios:
            raw_data = create_scenario_data(scenario['type'])
            features = feature_extractor.extract_features(raw_data)
            
            # è®°å½•æ•°æ®
            raw_data_row = {
                'scenario': scenario['name'],
                'type': scenario['type'],
                'expected': scenario['expected'],
                **raw_data
            }
            raw_data_list.append(raw_data_row)
            
            feature_data_row = {
                'scenario': scenario['name'],
                'type': scenario['type'],
                'expected': scenario['expected']
            }
            
            # æ·»åŠ ç‰¹å¾å€¼ï¼ˆå‡è®¾6ç»´ç‰¹å¾ï¼‰
            for i, feature_value in enumerate(features):
                feature_data_row[f'feature_{i:02d}'] = feature_value
            
            feature_data_list.append(feature_data_row)
            
            print(f"\nğŸ“‹ {scenario['name']} ({scenario['expected']})")
            print(f"   ç±»å‹: {scenario['type']}")
            
            # æ˜¾ç¤ºå…³é”®åŸå§‹æŒ‡æ ‡
            print("   åŸå§‹æŒ‡æ ‡:")
            for metric, value in raw_data.items():
                print(f"     {metric}: {value}")
            
            # æ˜¾ç¤ºå‰10ä¸ªç‰¹å¾å€¼
            print("   æå–ç‰¹å¾ (å‰10ä¸ª):")
            for i in range(min(10, len(features))):
                print(f"     feature_{i:02d}: {features[i]:>10.2f}")
        
        # åˆ›å»ºDataFrameç”¨äºåˆ†æ
        raw_df = pd.DataFrame(raw_data_list)
        feature_df = pd.DataFrame(feature_data_list)
        
        # åˆ†ææ­£å¸¸vså¼‚å¸¸çš„ç‰¹å¾å·®å¼‚
        print(f"\nğŸ“Š æ­£å¸¸ vs å¼‚å¸¸åœºæ™¯ç‰¹å¾å¯¹æ¯”")
        print("=" * 80)
        
        normal_features = feature_df[feature_df['expected'] == 'normal']
        anomaly_features = feature_df[feature_df['expected'] == 'anomaly']
        
        # è®¡ç®—ç‰¹å¾ç»Ÿè®¡
        feature_cols = [col for col in feature_df.columns if col.startswith('feature_')]
        
        print("ç‰¹å¾å·®å¼‚åˆ†æ (å‰12ä¸ªç‰¹å¾):")
        print(f"{'ç‰¹å¾':<12} {'æ­£å¸¸-å¹³å‡':<12} {'æ­£å¸¸-æ ‡å‡†å·®':<12} {'å¼‚å¸¸-å¹³å‡':<12} {'å¼‚å¸¸-æ ‡å‡†å·®':<12} {'å·®å¼‚å€æ•°':<10}")
        print("-" * 80)
        
        for i, feature_col in enumerate(feature_cols[:12]):
            normal_mean = normal_features[feature_col].mean()
            normal_std = normal_features[feature_col].std()
            anomaly_mean = anomaly_features[feature_col].mean()
            anomaly_std = anomaly_features[feature_col].std()
            
            # è®¡ç®—å·®å¼‚å€æ•°
            if abs(normal_mean) > 1e-6:
                diff_ratio = abs(anomaly_mean - normal_mean) / abs(normal_mean)
            else:
                diff_ratio = float('inf') if abs(anomaly_mean) > 1e-6 else 0
            
            print(f"{feature_col:<12} {normal_mean:>11.2f} {normal_std:>11.2f} {anomaly_mean:>11.2f} {anomaly_std:>11.2f} {diff_ratio:>9.2f}")
        
        # æ‰¾å‡ºå·®å¼‚æœ€å¤§çš„ç‰¹å¾
        print(f"\nğŸ¯ å·®å¼‚æœ€å¤§çš„ç‰¹å¾ (Top 5):")
        print("-" * 50)
        
        feature_diffs = []
        for feature_col in feature_cols:
            normal_mean = normal_features[feature_col].mean()
            anomaly_mean = anomaly_features[feature_col].mean()
            
            if abs(normal_mean) > 1e-6:
                diff_ratio = abs(anomaly_mean - normal_mean) / abs(normal_mean)
            else:
                diff_ratio = float('inf') if abs(anomaly_mean) > 1e-6 else 0
            
            feature_diffs.append((feature_col, diff_ratio, normal_mean, anomaly_mean))
        
        # æ’åºå¹¶æ˜¾ç¤ºTop 5
        feature_diffs.sort(key=lambda x: x[1], reverse=True)
        for i, (feature_col, diff_ratio, normal_mean, anomaly_mean) in enumerate(feature_diffs[:5]):
            print(f"{i+1}. {feature_col}: å·®å¼‚å€æ•° {diff_ratio:.2f} (æ­£å¸¸:{normal_mean:.2f}, å¼‚å¸¸:{anomaly_mean:.2f})")
        
        # åˆ†æé—®é¢˜åœºæ™¯
        print(f"\nâš ï¸  é—®é¢˜åˆ†æ:")
        print("-" * 50)
        print("é‡æ„è¯¯å·®åˆ†å¸ƒé—®é¢˜å¯èƒ½çš„åŸå› :")
        print("1. éƒ¨åˆ†å¼‚å¸¸åœºæ™¯çš„ç‰¹å¾å˜åŒ–ä¸å¤Ÿæç«¯")
        print("2. é«˜è´Ÿè½½æ­£å¸¸åœºæ™¯å¯èƒ½è¢«é”™è¯¯åœ°è®¾è®¡å¾—è¿‡äºæç«¯")
        print("3. æŸäº›å¼‚å¸¸ç±»å‹åœ¨å½“å‰ç‰¹å¾ç©ºé—´ä¸‹éš¾ä»¥åŒºåˆ†")
        print("4. éœ€è¦è°ƒæ•´å¼‚å¸¸åœºæ™¯çš„å‚æ•°è®¾ç½®ï¼Œä½¿å…¶æ›´å…·åŒºåˆ†æ€§")
        
        return raw_df, feature_df
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None

if __name__ == "__main__":
    analyze_feature_distributions() 