import torch
import torch.nn as nn
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# è¶…ç®€åŒ–çš„ç«¯åˆ°ç«¯å¼‚å¸¸æ£€æµ‹ç½‘ç»œ (11ç»´è¾“å…¥)
class UltraSimplifiedEndToEndAnomalyDetector(nn.Module):
    def __init__(self):
        super(UltraSimplifiedEndToEndAnomalyDetector, self).__init__()
        
        # ç›´æ¥ä»11ç»´è¾“å…¥åˆ°2åˆ†ç±»è¾“å‡ºï¼Œé¿å…å¤æ‚çš„ç‰¹å¾å·¥ç¨‹
        self.network = nn.Sequential(
            nn.Linear(11, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 2)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        return self.network(x)

# è¶…ç®€åŒ–çš„ç«¯åˆ°ç«¯å¼‚å¸¸åˆ†ç±»ç½‘ç»œ (11ç»´è¾“å…¥)
class UltraSimplifiedEndToEndAnomalyClassifier(nn.Module):
    def __init__(self, n_classes=6):
        super(UltraSimplifiedEndToEndAnomalyClassifier, self).__init__()
        
        # ç›´æ¥ä»11ç»´è¾“å…¥åˆ°6åˆ†ç±»è¾“å‡º
        self.network = nn.Sequential(
            nn.Linear(11, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, n_classes)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        return self.network(x)

def generate_challenging_test_data(n_samples=1000):
    """ç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•æ•°æ®ï¼ŒåŒ…å«è¾¹ç•Œæƒ…å†µå’Œå™ªå£°"""
    print(f"ç”Ÿæˆ {n_samples} ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æµ‹è¯•æ ·æœ¬...")
    
    np.random.seed(123)  # ä½¿ç”¨ä¸åŒçš„éšæœºç§å­
    
    test_data = []
    test_labels_binary = []
    test_labels_multiclass = []
    
    for i in range(n_samples):
        sample_type = np.random.choice([
            'normal', 'borderline_normal', 'borderline_anomaly', 
            'noisy_normal', 'noisy_anomaly', 'mixed_signals'
        ])
        
        if sample_type == 'normal':
            # æ ‡å‡†æ­£å¸¸æ ·æœ¬
            sample = [
                np.random.uniform(70, 95),      # ä¿¡å·è´¨é‡
                np.random.uniform(-55, -30),    # ä¿¡å·å¼ºåº¦
                np.random.uniform(-95, -85),    # å™ªå£°
                np.random.uniform(8000, 25000), # rxåŒ…
                np.random.uniform(6000, 20000), # txåŒ…
                np.random.uniform(1000000, 8000000), # rxå­—èŠ‚
                np.random.uniform(500000, 6000000),  # txå­—èŠ‚
                np.random.uniform(8, 25),       # ping
                np.random.uniform(15, 40),      # dns
                np.random.uniform(20, 60),      # å†…å­˜
                np.random.uniform(5, 30)        # CPU
            ]
            binary_label = 0
            multiclass_label = 0
            
        elif sample_type == 'borderline_normal':
            # è¾¹ç•Œæ­£å¸¸æ ·æœ¬ï¼ˆæ¥è¿‘å¼‚å¸¸é˜ˆå€¼ï¼‰
            sample = [
                np.random.uniform(65, 75),      # ä¿¡å·è´¨é‡ç¨å·®
                np.random.uniform(-60, -50),    # ä¿¡å·å¼ºåº¦ç¨å¼±
                np.random.uniform(-90, -80),    # å™ªå£°ç¨é«˜
                np.random.uniform(6000, 10000), # åŒ…æ•°åå°‘
                np.random.uniform(4000, 8000),  # åŒ…æ•°åå°‘
                np.random.uniform(800000, 1500000), # å­—èŠ‚æ•°åå°‘
                np.random.uniform(400000, 1000000), # å­—èŠ‚æ•°åå°‘
                np.random.uniform(20, 35),      # pingç¨é•¿
                np.random.uniform(30, 50),      # dnsç¨é•¿
                np.random.uniform(50, 70),      # å†…å­˜ç¨é«˜
                np.random.uniform(25, 40)       # CPUç¨é«˜
            ]
            binary_label = 0  # ä»ç„¶æ˜¯æ­£å¸¸
            multiclass_label = 0
            
        elif sample_type == 'borderline_anomaly':
            # è¾¹ç•Œå¼‚å¸¸æ ·æœ¬ï¼ˆè½»å¾®å¼‚å¸¸ï¼‰
            sample = [
                np.random.uniform(50, 70),      # ä¿¡å·è´¨é‡å·®
                np.random.uniform(-70, -55),    # ä¿¡å·å¼ºåº¦å·®
                np.random.uniform(-80, -70),    # å™ªå£°è¾ƒé«˜
                np.random.uniform(3000, 8000),  # åŒ…æ•°å°‘
                np.random.uniform(2000, 6000),  # åŒ…æ•°å°‘
                np.random.uniform(300000, 1000000), # å­—èŠ‚æ•°å°‘
                np.random.uniform(200000, 800000),  # å­—èŠ‚æ•°å°‘
                np.random.uniform(35, 60),      # pingè¾ƒé•¿
                np.random.uniform(45, 80),      # dnsè¾ƒé•¿
                np.random.uniform(60, 80),      # å†…å­˜è¾ƒé«˜
                np.random.uniform(35, 55)       # CPUè¾ƒé«˜
            ]
            binary_label = 1  # è½»å¾®å¼‚å¸¸
            multiclass_label = np.random.choice([1, 2, 3]) + 1  # éšæœºå¼‚å¸¸ç±»å‹
            
        elif sample_type == 'noisy_normal':
            # å¸¦å™ªå£°çš„æ­£å¸¸æ ·æœ¬
            base_sample = [85.0, -45.0, -90.0, 15000, 12000, 3000000, 2500000, 15.0, 25.0, 35.0, 20.0]
            sample = []
            for val in base_sample:
                # æ·»åŠ 10-20%çš„éšæœºå™ªå£°
                noise = np.random.uniform(-0.2, 0.2) * abs(val)
                sample.append(val + noise)
            binary_label = 0
            multiclass_label = 0
            
        elif sample_type == 'noisy_anomaly':
            # å¸¦å™ªå£°çš„å¼‚å¸¸æ ·æœ¬
            base_sample = [10.0, -85.0, -45.0, 50, 30, 5000, 3000, 200.0, 300.0, 30.0, 15.0]
            sample = []
            for val in base_sample:
                # æ·»åŠ 15-25%çš„éšæœºå™ªå£°
                noise = np.random.uniform(-0.25, 0.25) * abs(val) if val != 0 else np.random.uniform(-5, 5)
                sample.append(val + noise)
            binary_label = 1
            multiclass_label = 1  # wifi_disconnection
            
        elif sample_type == 'mixed_signals':
            # æ··åˆä¿¡å·æ ·æœ¬ï¼ˆä¸€äº›æŒ‡æ ‡æ­£å¸¸ï¼Œä¸€äº›å¼‚å¸¸ï¼‰
            sample = [
                np.random.uniform(70, 90),      # ä¿¡å·è´¨é‡æ­£å¸¸
                np.random.uniform(-50, -35),    # ä¿¡å·å¼ºåº¦æ­£å¸¸
                np.random.uniform(-90, -85),    # å™ªå£°æ­£å¸¸
                np.random.uniform(100, 1000),   # åŒ…æ•°å¼‚å¸¸ä½
                np.random.uniform(80, 800),     # åŒ…æ•°å¼‚å¸¸ä½
                np.random.uniform(10000, 100000), # å­—èŠ‚æ•°å¼‚å¸¸ä½
                np.random.uniform(8000, 80000),    # å­—èŠ‚æ•°å¼‚å¸¸ä½
                np.random.uniform(10, 30),      # pingæ­£å¸¸
                np.random.uniform(20, 50),      # dnsæ­£å¸¸
                np.random.uniform(25, 45),      # å†…å­˜æ­£å¸¸
                np.random.uniform(10, 30)       # CPUæ­£å¸¸
            ]
            binary_label = 1  # åº”è¯¥è¢«æ£€æµ‹ä¸ºå¼‚å¸¸
            multiclass_label = 2  # packet_loss
        
        test_data.append(sample)
        test_labels_binary.append(binary_label)
        test_labels_multiclass.append(multiclass_label)
    
    return np.array(test_data), np.array(test_labels_binary), np.array(test_labels_multiclass)

def test_model_robustness():
    """æµ‹è¯•æ¨¡å‹åœ¨å…·æœ‰æŒ‘æˆ˜æ€§æ•°æ®ä¸Šçš„è¡¨ç°"""
    print("=== æ¨¡å‹é²æ£’æ€§æµ‹è¯• ===")
    print()
    
    # åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
    scaler = joblib.load('ultra_simplified_raw_data_scaler.pkl')
    
    detector_model = UltraSimplifiedEndToEndAnomalyDetector()
    detector_model.load_state_dict(torch.load('ultra_simplified_end_to_end_anomaly_detector.pth', map_location='cpu'))
    detector_model.eval()
    
    classifier_model = UltraSimplifiedEndToEndAnomalyClassifier(n_classes=6)
    classifier_model.load_state_dict(torch.load('ultra_simplified_end_to_end_anomaly_classifier.pth', map_location='cpu'))
    classifier_model.eval()
    
    # ç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æµ‹è¯•æ•°æ®
    test_data, test_labels_binary, test_labels_multiclass = generate_challenging_test_data(1000)
    
    # æ ‡å‡†åŒ–æµ‹è¯•æ•°æ®
    test_data_scaled = scaler.transform(test_data)
    test_tensor = torch.FloatTensor(test_data_scaled)
    
    # æµ‹è¯•å¼‚å¸¸æ£€æµ‹
    print("ğŸ” **å¼‚å¸¸æ£€æµ‹æ€§èƒ½æµ‹è¯•**")
    with torch.no_grad():
        detection_output = detector_model(test_tensor)
        detection_probs = torch.softmax(detection_output, dim=1)
        predicted_binary = torch.argmax(detection_output, dim=1).numpy()
    
    # è®¡ç®—å¼‚å¸¸æ£€æµ‹å‡†ç¡®ç‡
    detection_accuracy = accuracy_score(test_labels_binary, predicted_binary)
    print(f"   å¼‚å¸¸æ£€æµ‹å‡†ç¡®ç‡: {detection_accuracy:.3f} ({detection_accuracy*100:.1f}%)")
    
    # è¯¦ç»†åˆ†æ
    cm_binary = confusion_matrix(test_labels_binary, predicted_binary)
    print(f"   æ··æ·†çŸ©é˜µ:")
    print(f"   å®é™…\\é¢„æµ‹  æ­£å¸¸   å¼‚å¸¸")
    print(f"   æ­£å¸¸      {cm_binary[0,0]:4d}   {cm_binary[0,1]:4d}")
    print(f"   å¼‚å¸¸      {cm_binary[1,0]:4d}   {cm_binary[1,1]:4d}")
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒ
    confidence_normal = detection_probs[test_labels_binary == 0, 0].numpy()
    confidence_anomaly = detection_probs[test_labels_binary == 1, 1].numpy()
    
    print(f"   æ­£å¸¸æ ·æœ¬ç½®ä¿¡åº¦: å‡å€¼={confidence_normal.mean():.3f}, æœ€å°={confidence_normal.min():.3f}")
    print(f"   å¼‚å¸¸æ ·æœ¬ç½®ä¿¡åº¦: å‡å€¼={confidence_anomaly.mean():.3f}, æœ€å°={confidence_anomaly.min():.3f}")
    
    # æµ‹è¯•å¼‚å¸¸åˆ†ç±»ï¼ˆä»…å¯¹æ£€æµ‹ä¸ºå¼‚å¸¸çš„æ ·æœ¬ï¼‰
    anomaly_mask = predicted_binary == 1
    if np.sum(anomaly_mask) > 0:
        print()
        print("ğŸ¯ **å¼‚å¸¸åˆ†ç±»æ€§èƒ½æµ‹è¯•**")
        
        with torch.no_grad():
            classification_output = classifier_model(test_tensor[anomaly_mask])
            predicted_multiclass = torch.argmax(classification_output, dim=1).numpy()
        
        # è½¬æ¢çœŸå®æ ‡ç­¾ï¼ˆ0=normal, 1-6=anomaly types -> 0-5=anomaly typesï¼‰
        true_multiclass = test_labels_multiclass[anomaly_mask] - 1
        true_multiclass = np.clip(true_multiclass, 0, 5)  # ç¡®ä¿åœ¨0-5èŒƒå›´å†…
        
        classification_accuracy = accuracy_score(true_multiclass, predicted_multiclass)
        print(f"   å¼‚å¸¸åˆ†ç±»å‡†ç¡®ç‡: {classification_accuracy:.3f} ({classification_accuracy*100:.1f}%)")
        
        # åˆ†ç±»æŠ¥å‘Š
        print("   åˆ†ç±»è¯¦ç»†æŠ¥å‘Š:")
        unique_classes = np.unique(np.concatenate([true_multiclass, predicted_multiclass]))
        class_names = ['wifi_disconnection', 'high_latency', 'packet_loss', 'bandwidth_saturation', 'system_overload', 'dns_failure']
        active_class_names = [class_names[i] for i in unique_classes if i < len(class_names)]
        
        if len(active_class_names) > 0:
            print(classification_report(true_multiclass, predicted_multiclass, 
                                      labels=unique_classes, target_names=active_class_names))
        else:
            print("   æ²¡æœ‰è¶³å¤Ÿçš„åˆ†ç±»æ•°æ®è¿›è¡Œåˆ†æ")
    
    # åˆ†æä½ç½®ä¿¡åº¦æ ·æœ¬
    print()
    print("ğŸ” **ä½ç½®ä¿¡åº¦æ ·æœ¬åˆ†æ**")
    low_confidence_threshold = 0.8
    
    # å¼‚å¸¸æ£€æµ‹ä½ç½®ä¿¡åº¦
    detection_confidence = np.max(detection_probs.numpy(), axis=1)
    low_conf_mask = detection_confidence < low_confidence_threshold
    
    print(f"   ç½®ä¿¡åº¦ < {low_confidence_threshold} çš„æ ·æœ¬: {np.sum(low_conf_mask)} / {len(test_data)} ({np.sum(low_conf_mask)/len(test_data)*100:.1f}%)")
    
    if np.sum(low_conf_mask) > 0:
        low_conf_accuracy = accuracy_score(test_labels_binary[low_conf_mask], predicted_binary[low_conf_mask])
        print(f"   ä½ç½®ä¿¡åº¦æ ·æœ¬å‡†ç¡®ç‡: {low_conf_accuracy:.3f} ({low_conf_accuracy*100:.1f}%)")

def main():
    print("=== æ¨¡å‹é²æ£’æ€§å’ŒæŒ‘æˆ˜æ€§æµ‹è¯• ===")
    print()
    
    print("ğŸ¯ **æµ‹è¯•ç›®æ ‡**:")
    print("   - éªŒè¯æ¨¡å‹åœ¨è¾¹ç•Œæƒ…å†µä¸‹çš„è¡¨ç°")
    print("   - æµ‹è¯•å¯¹å™ªå£°æ•°æ®çš„é²æ£’æ€§")
    print("   - æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿‡æ‹Ÿåˆ")
    print("   - åˆ†æç½®ä¿¡åº¦åˆ†å¸ƒ")
    print()
    
    test_model_robustness()
    
    print()
    print("=== æµ‹è¯•åˆ†æç»“è®º ===")
    print("å¦‚æœå‡†ç¡®ç‡ä»ç„¶æ¥è¿‘100%ï¼Œè¯´æ˜:")
    print("1. å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
    print("2. æµ‹è¯•æ•°æ®å¯èƒ½ä»ç„¶è¿‡äºç®€å•")
    print("3. éœ€è¦æ”¶é›†çœŸå®ä¸–ç•Œçš„æ•°æ®è¿›è¡ŒéªŒè¯")

if __name__ == "__main__":
    main() 