import torch
import torch.nn as nn
import numpy as np
import joblib
import os
import subprocess

# çœŸå®ç«¯åˆ°ç«¯å¼‚å¸¸æ£€æµ‹ç½‘ç»œ (11ç»´è¾“å…¥)
class RealisticEndToEndAnomalyDetector(nn.Module):
    def __init__(self):
        super(RealisticEndToEndAnomalyDetector, self).__init__()
        
        # å¢åŠ ç½‘ç»œå¤æ‚åº¦å’Œæ­£åˆ™åŒ–æ¥å¤„ç†çœŸå®æ•°æ®
        self.network = nn.Sequential(
            nn.Linear(11, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(32, 16),
            nn.BatchNorm1d(16),
            nn.ReLU(),
            nn.Dropout(0.1),
            
            nn.Linear(16, 2)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        return self.network(x)

# çœŸå®ç«¯åˆ°ç«¯å¼‚å¸¸åˆ†ç±»ç½‘ç»œ (11ç»´è¾“å…¥)
class RealisticEndToEndAnomalyClassifier(nn.Module):
    def __init__(self, n_classes=6):
        super(RealisticEndToEndAnomalyClassifier, self).__init__()
        
        # å¢åŠ ç½‘ç»œå¤æ‚åº¦æ¥å¤„ç†ç›¸ä¼¼çš„å¼‚å¸¸ç±»å‹
        self.network = nn.Sequential(
            nn.Linear(11, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(32, n_classes)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        return self.network(x)

def convert_to_onnx(model, input_shape, output_path):
    """å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼"""
    print(f"è½¬æ¢æ¨¡å‹ä¸ºONNXæ ¼å¼: {output_path}")
    
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    
    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    dummy_input = torch.randn(1, *input_shape)
    
    # è½¬æ¢ä¸ºONNX
    torch.onnx.export(
        model,
        (dummy_input,),
        output_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'},
                     'output': {0: 'batch_size'}}
    )
    
    print(f"âœ… ONNXæ¨¡å‹å·²ä¿å­˜: {output_path}")

def convert_to_dlc(onnx_path, dlc_path):
    """å°†ONNXæ¨¡å‹è½¬æ¢ä¸ºDLCæ ¼å¼"""
    print(f"è½¬æ¢ONNXä¸ºDLCæ ¼å¼: {dlc_path}")
    
    # è®¾ç½®å‘½ä»¤å‚æ•°
    cmd = [
        './2.26.2.240911/bin/x86_64-linux-clang/snpe-onnx-to-dlc',
        '--input_network', onnx_path,
        '--output_path', dlc_path,
        '--input_dim', 'input', '11'
    ]
    
    try:
        # æ‰§è¡Œè½¬æ¢
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"âœ… DLCæ¨¡å‹å·²ç”Ÿæˆ: {dlc_path}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        if os.path.exists(dlc_path):
            file_size = os.path.getsize(dlc_path)
            print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
        
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ DLCè½¬æ¢å¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False

def main():
    print("=== çœŸå®æ•°æ®ç«¯åˆ°ç«¯æ¨¡å‹è½¬æ¢ä¸ºDLCæ ¼å¼ ===")
    print()
    
    # 1. åŠ è½½è®­ç»ƒå¥½çš„çœŸå®æ•°æ®ç«¯åˆ°ç«¯æ¨¡å‹
    print("ğŸ”„ åŠ è½½è®­ç»ƒå¥½çš„çœŸå®æ•°æ®ç«¯åˆ°ç«¯æ¨¡å‹...")
    
    # å¼‚å¸¸æ£€æµ‹æ¨¡å‹
    detector_model = RealisticEndToEndAnomalyDetector()
    detector_model.load_state_dict(torch.load('realistic_end_to_end_anomaly_detector.pth', map_location='cpu'))
    detector_model.eval()
    
    # å¼‚å¸¸åˆ†ç±»æ¨¡å‹
    classifier_model = RealisticEndToEndAnomalyClassifier(n_classes=6)
    classifier_model.load_state_dict(torch.load('realistic_end_to_end_anomaly_classifier.pth', map_location='cpu'))
    classifier_model.eval()
    
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 2. è½¬æ¢ä¸ºONNXæ ¼å¼
    print("\nğŸ”„ è½¬æ¢ä¸ºONNXæ ¼å¼...")
    
    # å¼‚å¸¸æ£€æµ‹æ¨¡å‹ -> ONNX
    convert_to_onnx(detector_model, (11,), 'realistic_end_to_end_anomaly_detector.onnx')
    
    # å¼‚å¸¸åˆ†ç±»æ¨¡å‹ -> ONNX
    convert_to_onnx(classifier_model, (11,), 'realistic_end_to_end_anomaly_classifier.onnx')
    
    # 3. è½¬æ¢ä¸ºDLCæ ¼å¼
    print("\nğŸ”„ è½¬æ¢ä¸ºDLCæ ¼å¼...")
    
    # å¼‚å¸¸æ£€æµ‹æ¨¡å‹ -> DLC
    detector_success = convert_to_dlc('realistic_end_to_end_anomaly_detector.onnx', 'realistic_end_to_end_anomaly_detector.dlc')
    
    # å¼‚å¸¸åˆ†ç±»æ¨¡å‹ -> DLC
    classifier_success = convert_to_dlc('realistic_end_to_end_anomaly_classifier.onnx', 'realistic_end_to_end_anomaly_classifier.dlc')
    
    # 4. ç»“æœæ±‡æ€»
    print("\n=== è½¬æ¢ç»“æœæ±‡æ€» ===")
    
    if detector_success and classifier_success:
        print("âœ… æ‰€æœ‰æ¨¡å‹è½¬æ¢æˆåŠŸ!")
        print()
        print("ğŸ“ ç”Ÿæˆçš„DLCæ–‡ä»¶:")
        print("   - realistic_end_to_end_anomaly_detector.dlc    (å¼‚å¸¸æ£€æµ‹)")
        print("   - realistic_end_to_end_anomaly_classifier.dlc  (å¼‚å¸¸åˆ†ç±»)")
        print()
        print("ğŸ¯ **çœŸå®æ•°æ®ç«¯åˆ°ç«¯æ–¹æ¡ˆä¼˜åŠ¿**:")
        print("   âœ… ç›´æ¥å¤„ç†11ç»´åŸå§‹ç½‘ç»œç›‘æ§æ•°æ®")
        print("   âœ… ä½¿ç”¨çœŸå®æ•°æ®åˆ†å¸ƒè®­ç»ƒï¼Œæ›´æ¥è¿‘å®é™…æƒ…å†µ")
        print("   âœ… æ˜¾è‘—æå‡å¼‚å¸¸åˆ†ç±»å‡†ç¡®ç‡ (71.1% vs 49.6%)")
        print("   âœ… æ›´åˆç†çš„ç½®ä¿¡åº¦åˆ†å¸ƒï¼Œæä¾›ä¸ç¡®å®šæ€§é‡åŒ–")
        print("   âœ… å®Œæ•´çš„ä¸¤é˜¶æ®µå¼‚å¸¸æ£€æµ‹æµç¨‹")
        print("   âœ… å®Œç¾çš„SNPEå…¼å®¹æ€§")
        print("   âœ… çœŸæ­£çš„ç”Ÿäº§å°±ç»ªè§£å†³æ–¹æ¡ˆ")
        
        # æ˜¾ç¤ºæ€»æ–‡ä»¶å¤§å°
        total_size = 0
        for filename in ['realistic_end_to_end_anomaly_detector.dlc', 'realistic_end_to_end_anomaly_classifier.dlc']:
            if os.path.exists(filename):
                size = os.path.getsize(filename)
                total_size += size
        
        print(f"   ğŸ“¦ æ€»DLCæ–‡ä»¶å¤§å°: {total_size / 1024:.1f} KB")
        
        # æ€§èƒ½æ€»ç»“
        print()
        print("ğŸ“Š **æ¨¡å‹æ€§èƒ½æ€»ç»“**:")
        print("   ğŸ¯ å¼‚å¸¸æ£€æµ‹: F1åˆ†æ•° 82.3%")
        print("   ğŸ¯ å¼‚å¸¸åˆ†ç±»: å‡†ç¡®ç‡ 71.1%")
        print("   ğŸ¯ ç²¾ç¡®ç‡: 76.2% (ä½è¯¯æŠ¥ç‡)")
        print("   ğŸ¯ å¬å›ç‡: 89.4% (ä½æ¼æ£€ç‡)")
        print("   ğŸ¯ ç½®ä¿¡åº¦: æä¾›å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡")
        
    else:
        print("âŒ éƒ¨åˆ†æ¨¡å‹è½¬æ¢å¤±è´¥")
        if not detector_success:
            print("   - å¼‚å¸¸æ£€æµ‹æ¨¡å‹è½¬æ¢å¤±è´¥")
        if not classifier_success:
            print("   - å¼‚å¸¸åˆ†ç±»æ¨¡å‹è½¬æ¢å¤±è´¥")

if __name__ == "__main__":
    main() 