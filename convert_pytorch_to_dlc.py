#!/usr/bin/env python3
"""
AIç½‘ç»œå¼‚å¸¸æ£€æµ‹æ¨¡å‹è½¬æ¢è„šæœ¬
å°†è®­ç»ƒå¥½çš„PyTorchæ¨¡å‹è½¬æ¢ä¸ºç›®æ ‡æ¿å­å¯ç”¨çš„DLCæ ¼å¼
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

def load_multitask_model():
    """
    åŠ è½½è®­ç»ƒå¥½çš„å¤šä»»åŠ¡æ¨¡å‹
    """
    from train_multitask_model import MultiTaskAnomalyModel
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = MultiTaskAnomalyModel()
    
    # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    model_path = "multitask_model.pth"
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_path}")
    else:
        print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ train_multitask_model.py è®­ç»ƒæ¨¡å‹")
        return None
    
    model.eval()
    return model

def convert_to_onnx(model, output_path="multitask_model.onnx"):
    """
    å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼
    """
    print(f"ğŸ”„ å¼€å§‹è½¬æ¢ä¸ºONNXæ ¼å¼...")
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    dummy_input = torch.randn(1, 11)  # 11ç»´è¾“å…¥
    
    # å¯¼å‡ºä¸ºONNX
    torch.onnx.export(
        model,
        (dummy_input,),  # å°†tensoråŒ…è£…ä¸ºtuple
        output_path,
        input_names=['input'],
        output_names=['detection_output', 'classification_output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'detection_output': {0: 'batch_size'},
            'classification_output': {0: 'batch_size'}
        },
        opset_version=11,
        do_constant_folding=True,
        verbose=False
    )
    
    # éªŒè¯ONNXæ¨¡å‹
    try:
        import onnx
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)
        print(f"âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡: {output_path}")
        print(f"ğŸ“Š æ¨¡å‹å¤§å°: {os.path.getsize(output_path) / 1024:.1f} KB")
        return True
    except Exception as e:
        print(f"âŒ ONNXæ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return False

def convert_to_dlc(onnx_path, dlc_path="multitask_model.dlc"):
    """
    å°†ONNXæ¨¡å‹è½¬æ¢ä¸ºDLCæ ¼å¼
    """
    print(f"ğŸ”„ å¼€å§‹è½¬æ¢ä¸ºDLCæ ¼å¼...")
    
    # æ£€æŸ¥SNPEç¯å¢ƒ
    snpe_root = "2.26.2.240911"
    if not os.path.exists(snpe_root):
        print(f"âŒ SNPE SDKæœªæ‰¾åˆ°: {snpe_root}")
        print("è¯·ç¡®ä¿SNPE SDKå·²æ­£ç¡®å®‰è£…")
        return False
    
    # è®¾ç½®SNPEç¯å¢ƒå˜é‡
    os.environ['SNPE_ROOT'] = os.path.abspath(snpe_root)
    
    # æ„å»ºSNPEè½¬æ¢å‘½ä»¤
    snpe_converter = os.path.join(snpe_root, "bin", "x86_64-linux-clang", "snpe-onnx-to-dlc")
    
    if not os.path.exists(snpe_converter):
        print(f"âŒ SNPEè½¬æ¢å·¥å…·æœªæ‰¾åˆ°: {snpe_converter}")
        return False
    
    # æ‰§è¡Œè½¬æ¢
    import subprocess
    
    cmd = [
        snpe_converter,
        "-i", onnx_path,
        "-o", dlc_path,
        "--input_encoding", "float",
        "--output_encoding", "float"
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print(f"âœ… DLCè½¬æ¢æˆåŠŸ: {dlc_path}")
        print(f"ğŸ“Š æ¨¡å‹å¤§å°: {os.path.getsize(dlc_path) / 1024:.1f} KB")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ DLCè½¬æ¢å¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False

def validate_dlc_model(dlc_path="multitask_model.dlc"):
    """
    éªŒè¯DLCæ¨¡å‹æ–‡ä»¶
    """
    print(f"ğŸ” éªŒè¯DLCæ¨¡å‹æ–‡ä»¶...")
    
    if not os.path.exists(dlc_path):
        print(f"âŒ DLCæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {dlc_path}")
        return False
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(dlc_path)
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
    
    # æ£€æŸ¥æ–‡ä»¶å¤´ï¼ˆç®€å•çš„DLCæ–‡ä»¶éªŒè¯ï¼‰
    with open(dlc_path, 'rb') as f:
        header = f.read(16)
        if header.startswith(b'DLC'):
            print("âœ… DLCæ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
            return True
        else:
            print("âŒ DLCæ–‡ä»¶æ ¼å¼éªŒè¯å¤±è´¥")
            return False

def main():
    """
    ä¸»è½¬æ¢æµç¨‹
    """
    print("ğŸš€ AIç½‘ç»œå¼‚å¸¸æ£€æµ‹æ¨¡å‹è½¬æ¢å¼€å§‹")
    print("=" * 50)
    
    # 1. åŠ è½½PyTorchæ¨¡å‹
    model = load_multitask_model()
    if model is None:
        return False
    
    # 2. è½¬æ¢ä¸ºONNX
    onnx_success = convert_to_onnx(model)
    if not onnx_success:
        return False
    
    # 3. è½¬æ¢ä¸ºDLC
    dlc_success = convert_to_dlc("multitask_model.onnx")
    if not dlc_success:
        return False
    
    # 4. éªŒè¯DLCæ¨¡å‹
    validation_success = validate_dlc_model()
    
    print("=" * 50)
    if validation_success:
        print("ğŸ‰ æ¨¡å‹è½¬æ¢å®Œæˆï¼")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("   - multitask_model.onnx (ONNXæ ¼å¼)")
        print("   - multitask_model.dlc (DLCæ ¼å¼)")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   å°† multitask_model.dlc æ–‡ä»¶å¤åˆ¶åˆ°ç›®æ ‡æ¿å­")
        print("   å‚è€ƒ guide/æ¨¡å‹é›†æˆæŒ‡å—.md äº†è§£é›†æˆæ–¹æ³•")
        return True
    else:
        print("âŒ æ¨¡å‹è½¬æ¢å¤±è´¥")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 