#!/usr/bin/env python3
"""
æµ‹è¯•åˆ†åˆ«è®­ç»ƒçš„å¼‚å¸¸æ£€æµ‹å’Œåˆ†ç±»æ¨¡å‹
"""
import torch
import numpy as np
import joblib
from train_separate_models import AnomalyDetector, AnomalyClassifier

def test_separate_models():
    print("ğŸ§ª æµ‹è¯•åˆ†åˆ«è®­ç»ƒçš„æ¨¡å‹")
    print("=" * 50)
    
    # åŠ è½½æ¨¡å‹
    detector = AnomalyDetector()
    detector.load_state_dict(torch.load("anomaly_detector.pth", map_location='cpu'))
    detector.eval()
    
    classifier = AnomalyClassifier()
    classifier.load_state_dict(torch.load("anomaly_classifier.pth", map_location='cpu'))
    classifier.eval()
    
    # åŠ è½½æ ‡å‡†åŒ–å™¨
    scaler = joblib.load('separate_models_scaler.pkl')
    
    # æµ‹è¯•è¾“å…¥
    test_inputs = [
        # æ­£å¸¸æƒ…å†µ
        [85.0, -45.0, -90.0, 15000, 12000, 3000000, 2500000, 25.0, 30.0, 40.0, 25.0],
        # æ¨¡ç³Šæƒ…å†µ - è¾¹ç•Œæ•°æ®
        [58.0, -68.0, -75.0, 18000, 15000, 4000000, 3500000, 95.0, 180.0, 78.0, 85.0],
        # wifi_degradation
        [20.0, -80.0, -60.0, 8000, 6000, 1500000, 1200000, 40.0, 50.0, 45.0, 30.0],
        # network_latency  
        [70.0, -55.0, -85.0, 12000, 10000, 2500000, 2000000, 150.0, 180.0, 40.0, 25.0],
        # connection_instability
        [40.0, -75.0, -65.0, 2000, 1500, 300000, 250000, 80.0, 100.0, 35.0, 20.0],
        # bandwidth_congestion
        [85.0, -40.0, -95.0, 35000, 30000, 12000000, 10000000, 70.0, 60.0, 75.0, 60.0],
        # system_stress
        [75.0, -50.0, -90.0, 14000, 11000, 2800000, 2300000, 30.0, 40.0, 95.0, 90.0],
        # dns_issues
        [75.0, -50.0, -90.0, 15000, 12000, 3000000, 2500000, 25.0, 400.0, 40.0, 25.0]
    ]
    
    anomaly_types = [
        "normal",
        "ambiguous",
        "wifi_degradation",
        "network_latency", 
        "connection_instability",
        "bandwidth_congestion",
        "system_stress",
        "dns_issues"
    ]
    
    for i, (input_data, expected_type) in enumerate(zip(test_inputs, anomaly_types)):
        print(f"\nã€{expected_type}ã€‘:")
        
        # æ ‡å‡†åŒ–è¾“å…¥
        input_scaled = scaler.transform([input_data])
        input_tensor = torch.FloatTensor(input_scaled)
        
        # å¼‚å¸¸æ£€æµ‹
        with torch.no_grad():
            detection_output = detector(input_tensor)
            detection_probs = torch.softmax(detection_output, dim=1)
            is_anomaly = torch.argmax(detection_probs, dim=1).item()
            
            print(f"  å¼‚å¸¸æ£€æµ‹: {'å¼‚å¸¸' if is_anomaly == 1 else 'æ­£å¸¸'} (æ¦‚ç‡: {detection_probs[0].detach().numpy()})")
            
            # å¦‚æœæ˜¯å¼‚å¸¸ï¼Œè¿›è¡Œåˆ†ç±»
            if is_anomaly == 1:
                classification_output = classifier(input_tensor)
                classification_probs = torch.softmax(classification_output, dim=1)
                predicted_class = int(torch.argmax(classification_probs, dim=1).item())
                
                # å¯¹äºæ­£å¸¸æƒ…å†µï¼ŒæœŸæœ›æ£€æµ‹ä¸ºæ­£å¸¸
                if expected_type == "normal":
                    print(f"  æœŸæœ›ç»“æœ: æ­£å¸¸")
                    print(f"  æ˜¯å¦æ­£ç¡®: {'âœ…' if is_anomaly == 0 else 'âŒ'}")
                elif expected_type == "ambiguous":
                    print(f"  æ¨¡ç³Šæ•°æ® - æ£€æµ‹ç»“æœ: {'å¼‚å¸¸' if is_anomaly == 1 else 'æ­£å¸¸'}")
                    print(f"  æ³¨æ„: è¿™æ˜¯è¾¹ç•Œæ•°æ®ï¼Œç»“æœå¯èƒ½ä¸ç¡®å®š")
                else:
                    # å¼‚å¸¸åˆ†ç±»å™¨åªå¤„ç†6ç§å¼‚å¸¸ç±»å‹ï¼ˆä¸åŒ…æ‹¬normalå’Œambiguousï¼‰
                    anomaly_class_names = ["wifi_degradation", "network_latency", "connection_instability", 
                                         "bandwidth_congestion", "system_stress", "dns_issues"]
                    predicted_class_name = anomaly_class_names[predicted_class] if predicted_class < len(anomaly_class_names) else f"æœªçŸ¥ç±»å‹({predicted_class})"
                    print(f"  å¼‚å¸¸åˆ†ç±»: {predicted_class_name} (ç´¢å¼•: {predicted_class})")
                    print(f"  åˆ†ç±»æ¦‚ç‡: {classification_probs[0].detach().numpy()}")
                    print(f"  æœŸæœ›ç±»åˆ«: {expected_type} (ç´¢å¼•: {i - 2})")
                    print(f"  æ˜¯å¦æ­£ç¡®: {'âœ…' if predicted_class == (i - 2) else 'âŒ'}")
            else:
                if expected_type == "normal":
                    print("  æœŸæœ›ç»“æœ: æ­£å¸¸")
                    print("  æ˜¯å¦æ­£ç¡®: âœ…")
                elif expected_type == "ambiguous":
                    print("  æ¨¡ç³Šæ•°æ® - æ£€æµ‹ç»“æœ: æ­£å¸¸")
                    print("  æ³¨æ„: è¿™æ˜¯è¾¹ç•Œæ•°æ®ï¼Œç»“æœå¯èƒ½ä¸ç¡®å®š")
                else:
                    print("  è·³è¿‡åˆ†ç±»ï¼ˆæ£€æµ‹ä¸ºæ­£å¸¸ï¼‰")
                    print("  æ˜¯å¦æ­£ç¡®: âŒ (åº”è¯¥æ£€æµ‹ä¸ºå¼‚å¸¸)")

if __name__ == "__main__":
    test_separate_models() 