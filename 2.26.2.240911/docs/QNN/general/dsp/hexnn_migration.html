

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Migrating from Hexagon-nn &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.26.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend.html">Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Migrating from Hexagon-nn</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="migrating-from-hexagon-nn">
<h1>Migrating from Hexagon-nn<a class="headerlink" href="#migrating-from-hexagon-nn" title="Permalink to this heading">¶</a></h1>
<p>Developers familiar with Hexagon-nn APIs can follow this short guide to learn how to translate
Hexagon-nn API function calls into the equivalent QNN API function calls.</p>
<p>Both Hexagon-nn and QNN follow a similar process to create and execute a neural network (graph).</p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_process.png"><img alt="../../_static/resources/qnn_tutorial_migrate_process.png" src="../../_static/resources/qnn_tutorial_migrate_process.png" style="width: 750px;" /></a>
<p>The examples below will use the following format to show comparisons of <strong>Hexagon-nn</strong> vs <strong>QNN</strong>
code blocks. Notable APIs will be highlighted within the code blocks.</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Initialize</span><a class="headerlink" href="#id1" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="linenos">1</span><span class="n">hexagon_nn_init</span><span class="p">((</span><span class="n">hexagon_nn_nn_id</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nng_id</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">QNN Backend Creation</span><a class="headerlink" href="#id2" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="linenos">1</span><span class="n">QnnBackend_create</span><span class="p">(</span><span class="n">Qnn_LogHandle_t</span><span class="w"> </span><span class="n">logger</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">(</span><span class="n">QnnBackend_Config_t</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="w"> </span><span class="n">config</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">Qnn_BackendHandle_t</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">backend</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p>In the examples that follow, error handling is shown but not in all cases to limit the amount of
code clutter in the examples. A full solution would require more robust error handling which is
left as an exercise for the developer.</p>
<p>To illustrate the various APIs the following simple graph (migration) will serve as an example for
this tutorial.</p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_tiny.png"><img alt="../../_static/resources/qnn_tutorial_migrate_tiny.png" src="../../_static/resources/qnn_tutorial_migrate_tiny.png" style="width: 150px;" /></a>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial assumes that you are familiar with all the concepts required to create
and run a quantized neural network with Hexagon-nn. The topic of quanitized networks,
input and output tensors will not be covered here. For the purposes of this guide
all tensor data is assumed to be in a quantized format.</p>
</div>
<div class="section" id="create-graph">
<h2>Create Graph<a class="headerlink" href="#create-graph" title="Permalink to this heading">¶</a></h2>
<p>Create an instance of the neural network graph.</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Create Graph</span><a class="headerlink" href="#id3" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="n">hexagon_nn_nn_id</span><span class="w"> </span><span class="n">nng_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 2</span>
<span class="hll"><span class="linenos"> 3</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hexagon_nn_config</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
</span><span class="linenos"> 4</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 5</span><span class="w">     </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;hexagon_nn_config failed.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="p">}</span>
<span class="hll"><span class="linenos"> 7</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">hexagon_nn_init</span><span class="p">((</span><span class="n">hexagon_nn_nn_id</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="n">nng_id</span><span class="p">))</span>
</span><span class="linenos"> 8</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 9</span><span class="w">     </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;hexagon_nn_init failed.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="linenos">10</span><span class="w"> </span><span class="p">}</span>
</pre></div>
</div>
</div>
<p>Graphs for QNN require the following objects to be created:</p>
<blockquote>
<div><ul class="simple">
<li><p>log (optional)</p></li>
<li><p>backend</p></li>
<li><p>device</p></li>
<li><p>context</p></li>
<li><p>graph (associated with context)</p></li>
</ul>
</div></blockquote>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">QNN Create Graph</span><a class="headerlink" href="#id4" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="n">Qnn_LogHandle_t</span><span class="w"> </span><span class="n">logger</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="linenos"> 2</span><span class="n">Qnn_BackendHandle_t</span><span class="w"> </span><span class="n">backend</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="linenos"> 3</span><span class="n">Qnn_DeviceHandle_t</span><span class="w"> </span><span class="n">device</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="linenos"> 4</span>
<span class="linenos"> 5</span><span class="n">QnnLog_Callback_t</span><span class="w"> </span><span class="n">logCallBack</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 6</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">QNN_SUCCESS</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">QnnLog_create</span><span class="p">(</span><span class="n">logCallBack</span><span class="p">,</span><span class="w"> </span><span class="n">QNN_LOG_LEVEL_ERROR</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">logger</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos"> 7</span><span class="w">   </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;QNN log creation failed.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="linenos"> 8</span><span class="p">}</span>
<span class="linenos"> 9</span><span class="k">const</span><span class="w"> </span><span class="n">QnnBackend_Config_t</span><span class="w"> </span><span class="o">*</span><span class="n">backendConfigs</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="hll"><span class="linenos">10</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">QNN_SUCCESS</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">QnnBackend_create</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">backendConfigs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">backend</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">11</span><span class="w">   </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;QNN backend creation failed.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="linenos">12</span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">13</span><span class="w">   </span><span class="k">const</span><span class="w"> </span><span class="n">QnnDevice_Config_t</span><span class="w"> </span><span class="o">*</span><span class="n">deviveConfigs</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="hll"><span class="linenos">14</span><span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">QNN_SUCCESS</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">QnnDevice_create</span><span class="p">(</span><span class="n">logger</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">deviveConfigs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">device</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">15</span><span class="w">      </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;QNN device creation failed.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="linenos">16</span><span class="w">   </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">17</span><span class="w">      </span><span class="n">Qnn_ContextHandle_t</span><span class="w"> </span><span class="n">context</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="linenos">18</span><span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="n">QnnContext_Config_t</span><span class="w"> </span><span class="o">*</span><span class="n">contextConfigs</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="hll"><span class="linenos">19</span><span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">QNN_SUCCESS</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">QnnContext_create</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">contextConfigs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">context</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">20</span><span class="w">         </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;QNN context creation failed.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="linenos">21</span><span class="w">      </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">22</span><span class="w">         </span><span class="c1">// choose any name to identify the graph</span>
<span class="linenos">23</span><span class="w">         </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">graphName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;migrate&quot;</span><span class="p">;</span>
<span class="linenos">24</span><span class="w">         </span><span class="k">const</span><span class="w"> </span><span class="n">QnnGraph_Config_t</span><span class="w"> </span><span class="o">*</span><span class="n">graphConfigs</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="linenos">25</span><span class="w">         </span><span class="n">Qnn_GraphHandle_t</span><span class="w"> </span><span class="n">graph</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="hll"><span class="linenos">26</span><span class="w">         </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">QNN_SUCCESS</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">QnnGraph_create</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">graphName</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graphConfigs</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">27</span><span class="w">            </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;QNN graph creation failed.</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="linenos">28</span><span class="w">         </span><span class="p">}</span>
<span class="linenos">29</span><span class="w">      </span><span class="p">}</span>
<span class="linenos">30</span><span class="w">   </span><span class="p">}</span>
<span class="linenos">31</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="add-nodes">
<h2>Add Nodes<a class="headerlink" href="#add-nodes" title="Permalink to this heading">¶</a></h2>
<p>This next section will cover adding nodes to the graph. Nodes are added with the following APIs.</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Add Nodes</span><a class="headerlink" href="#id5" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="kt">int</span><span class="w"> </span><span class="nf">hexagon_nn_append_node</span><span class="p">(</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">);</span>
<span class="linenos">2</span><span class="kt">int</span><span class="w"> </span><span class="nf">hexagon_nn_append_const_node</span><span class="p">(</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">QNN Add Nodes</span><a class="headerlink" href="#id6" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="nf">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">);</span>
<span class="linenos">2</span><span class="n">Qnn_ErrorHandle_t</span><span class="w"> </span><span class="nf">QnnGraph_addNode</span><span class="p">(</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">);</span>
</pre></div>
</div>
</div>
<p>Nodes in Hexagon-nn graphs use unique IDs to identify graph nodes. Node weights, biases, and
parameters are generally added as constant nodes. The diagram below shows the simple example graph
with Hexagon-nn unique IDs.</p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_hexnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_hexnn.png" src="../../_static/resources/qnn_tutorial_migrate_hexnn.png" style="width: 350px;" /></a>
<p>In QNN nodes the weights, biases and parameters are added as tensors with static data.
The diagram below shows the simple example graph with QNN names to help identify each node.</p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_qnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_qnn.png" src="../../_static/resources/qnn_tutorial_migrate_qnn.png" style="width: 350px;" /></a>
<div class="section" id="adding-tensors-and-nodes">
<h3>Adding Tensors and Nodes<a class="headerlink" href="#adding-tensors-and-nodes" title="Permalink to this heading">¶</a></h3>
<p>Each node operation is associated with a set of input and output tensors. The node operation
definition defines the type and ordering of the inputs and outputs.</p>
<p><strong>Hexagon-nn</strong></p>
<p>A node can be a constant node or a graph node. Nodes are added to the graph via
hexagon_nn_append_node or hexagon_nn_append_const_node.</p>
<p>For example,</p>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Add Constant Node</span><a class="headerlink" href="#id7" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="w"> </span><span class="c1">// add constant nodes</span>
<span class="linenos">2</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">weights</span><span class="p">[</span><span class="mi">108</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">219</span><span class="p">,</span><span class="w"> </span><span class="mi">39</span><span class="p">,</span><span class="w"> </span><span class="mi">82</span><span class="p">,</span><span class="w"> </span><span class="mi">157</span><span class="p">,</span><span class="w"> </span><span class="mi">172</span><span class="p">,</span><span class="w"> </span><span class="mi">80</span><span class="p">,</span><span class="w"> </span><span class="p">...};</span>
<span class="linenos">3</span>
<span class="hll"><span class="linenos">4</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x12001</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="mi">108</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p>Each graph node is supplied with a set of inputs and outputs. These will include the constant
nodes and activation tensors. Each of these are identified by a node ID and an index value.</p>
<p>These inputs and outputs are specified as lists when adding nodes into the graph. The lists
contain node ID references which are used to create the connectivity of the graph.</p>
<div class="literal-block-wrapper docutils container" id="id8">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Add Graph Node</span><a class="headerlink" href="#id8" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// define the input</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="n">hexagon_nn_input</span><span class="w"> </span><span class="n">inputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 3</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// output of the INPUT node</span>
<span class="linenos"> 4</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x01000</span><span class="p">,</span>
<span class="linenos"> 5</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos"> 6</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos"> 7</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// weights</span>
<span class="linenos"> 8</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x12001</span><span class="p">,</span>
<span class="linenos"> 9</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">10</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos">11</span>
<span class="linenos">12</span><span class="w">                               </span><span class="p">...</span>
<span class="linenos">13</span><span class="w">                             </span><span class="p">};</span>
<span class="linenos">14</span>
<span class="linenos">15</span><span class="w"> </span><span class="c1">// define the output</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">hexagon_nn_output</span><span class="w"> </span><span class="n">outputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">17</span><span class="w">                                 </span><span class="p">{.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">18</span><span class="w">                                  </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">19</span><span class="w">                                  </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">20</span><span class="w">                                  </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">21</span><span class="w">                                  </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">},</span>
<span class="linenos">22</span>
<span class="linenos">23</span><span class="w">                                 </span><span class="p">...</span>
<span class="linenos">24</span>
<span class="linenos">25</span><span class="w">                                 </span><span class="p">{.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">26</span><span class="w">                                  </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">27</span><span class="w">                                  </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">28</span><span class="w">                                  </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">29</span><span class="w">                                  </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">}</span>
<span class="linenos">30</span><span class="w">                               </span><span class="p">};</span>
<span class="linenos">31</span>
<span class="linenos">32</span><span class="w"> </span><span class="c1">// add the node to the graph</span>
<span class="hll"><span class="linenos">33</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x02000</span><span class="p">,</span><span class="w"> </span><span class="n">OP_QuantizedConv2d_8x8to32</span><span class="p">,</span><span class="w"> </span><span class="n">NN_PAD_VALID</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p><strong>QNN</strong></p>
<p>The Qnn_Tensor_t data structure is used to define the attributes when creating a tensor.
Before a node can be created, the set of activation and parameter tensors connected to it
need to be created.</p>
<p>Note that the tensor ID does not need to be set. When calling the QnnTensor_createGraphTensor
function, a tenor ID will be generated and written back to tensor.v2.id. And creating a tensor
with a name that duplicates a previously created tensor name in the graph results in undefined
behaviour.</p>
<p>For example,</p>
<div class="literal-block-wrapper docutils container" id="id9">
<div class="code-block-caption"><span class="caption-text">QNN Create Tensors</span><a class="headerlink" href="#id9" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// input (activation tensor)</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">inputDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 3</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">inputTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 4</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 5</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;input&quot;</span><span class="p">;</span>
<span class="hll"><span class="linenos"> 7</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_APP_WRITE</span><span class="p">;</span>
</span><span class="linenos"> 8</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos"> 9</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">10</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">11</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">12</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0256975870579481</span><span class="p">;</span>
<span class="linenos">13</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-132</span><span class="p">;</span>
<span class="linenos">14</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos">15</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">inputDimensions</span><span class="p">;</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">17</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_CLIENT_BUFFER_INIT</span>
<span class="linenos">18</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">19</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">20</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">21</span>
<span class="hll"><span class="linenos">22</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputTensor</span><span class="p">);</span>
</span><span class="linenos">23</span>
<span class="linenos">24</span><span class="w"> </span><span class="c1">// weights (static tensor)</span>
<span class="linenos">25</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">weights</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">232</span><span class="p">,</span><span class="w"> </span><span class="mi">177</span><span class="p">,</span><span class="w"> </span><span class="mi">126</span><span class="p">,</span><span class="w"> </span><span class="mi">160</span><span class="p">,</span><span class="w"> </span><span class="mi">15</span><span class="p">,</span><span class="w"> </span><span class="mi">171</span><span class="p">,</span><span class="w"> </span><span class="p">...};</span>
<span class="linenos">26</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">weightsDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">};</span>
<span class="hll"><span class="linenos">27</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">weightsTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">28</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">29</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">30</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;weights&quot;</span><span class="p">;</span>
<span class="linenos">31</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos">32</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">33</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">34</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">35</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">36</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0012544898781925</span><span class="p">;</span>
<span class="linenos">37</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-129</span><span class="p">;</span>
<span class="linenos">38</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos">39</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">weightsDimensions</span><span class="p">;</span>
<span class="linenos">40</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">41</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">weights</span><span class="p">;</span>
<span class="linenos">42</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">108</span><span class="p">;</span>
<span class="linenos">43</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">44</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">45</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">46</span>
<span class="hll"><span class="linenos">47</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">weightsTensor</span><span class="p">);</span>
</span><span class="linenos">48</span>
<span class="linenos">49</span><span class="w"> </span><span class="c1">// output (activation tensor)</span>
<span class="linenos">50</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">outputDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">};</span>
<span class="hll"><span class="linenos">51</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">outputTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">52</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">53</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">54</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;output&quot;</span><span class="p">;</span>
<span class="hll"><span class="linenos">55</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_APP_READ</span><span class="p">;</span>
</span><span class="linenos">56</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">57</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">58</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">59</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">60</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0166513100266457</span><span class="p">;</span>
<span class="linenos">61</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-107</span><span class="p">;</span>
<span class="linenos">62</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos">63</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">outputDimensions</span><span class="p">;</span>
<span class="linenos">64</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">65</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_CLIENT_BUFFER_INIT</span><span class="p">;</span>
<span class="linenos">66</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">67</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">68</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">69</span>
<span class="hll"><span class="linenos">70</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">outputTensor</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p>Unlike Hexagon-nn where the weights and weights min/max are set in multiple constant nodes, QNN
directly includes the quantization scale and offset values during tensor creation.</p>
<p>Parameters for a node are defined via an array Qnn_Param_t parameters, each of which are uniquely
named. The parameter values can apply to tensors or scalars, with specific values defined in the
operation definitions.</p>
<div class="literal-block-wrapper docutils container" id="id10">
<div class="code-block-caption"><span class="caption-text">QNN Params Tensor</span><a class="headerlink" href="#id10" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// parameter tensors</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">pad</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">};</span>
<span class="linenos"> 3</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">padDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 4</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">padTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 5</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 7</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;pad&quot;</span><span class="p">;</span>
<span class="linenos"> 8</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos"> 9</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">10</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UINT_32</span><span class="p">;</span>
<span class="linenos">11</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_UNDEFINED</span><span class="p">;</span>
<span class="linenos">12</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_UNDEFINED</span><span class="p">;</span>
<span class="linenos">13</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="linenos">14</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">15</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">padDimensions</span><span class="p">;</span>
<span class="linenos">17</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">18</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">pad</span><span class="p">;</span>
<span class="linenos">19</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="linenos">20</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">21</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">22</span><span class="w"> </span><span class="n">padTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">23</span>
<span class="hll"><span class="linenos">24</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">padTensor</span><span class="p">);</span>
</span><span class="linenos">25</span>
<span class="hll"><span class="linenos">26</span><span class="w"> </span><span class="n">Qnn_Param_t</span><span class="w"> </span><span class="n">nodeParams</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">QNN_PARAM_INIT</span><span class="p">};</span>
</span><span class="linenos">27</span><span class="w"> </span><span class="n">nodeParams</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">paramType</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_PARAMTYPE_TENSOR</span><span class="p">;</span>
<span class="linenos">28</span><span class="w"> </span><span class="n">nodeParams</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_CONV_2D_PARAM_PAD_AMOUNT</span><span class="p">;</span>
<span class="linenos">29</span><span class="w"> </span><span class="n">nodeParams</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">tensorParam</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">padTensor</span><span class="p">;</span>
</pre></div>
</div>
</div>
<p>After the set up of the parameters, static and activation tensors,
the next step is to add the node to the graph.</p>
<p>The Qnn_OpConfig_t data structure is used to define the graph node when it is created.</p>
<div class="literal-block-wrapper docutils container" id="id11">
<div class="code-block-caption"><span class="caption-text">QNN Add Node</span><a class="headerlink" href="#id11" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// create a list of all input tensors</span>
<span class="hll"><span class="linenos"> 2</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">inputList</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">QNN_TENSOR_INIT</span><span class="p">,</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">};</span>
</span><span class="linenos"> 3</span><span class="w"> </span><span class="n">inputList</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w">              </span><span class="o">=</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">;</span>
<span class="linenos"> 4</span><span class="w"> </span><span class="n">inputList</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w">              </span><span class="o">=</span><span class="w"> </span><span class="n">weightsTensor</span><span class="p">;</span>
<span class="linenos"> 5</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="c1">// create a list of all output tensors</span>
<span class="hll"><span class="linenos"> 7</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">outputList</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">QNN_TENSOR_INIT</span><span class="p">};</span>
</span><span class="linenos"> 8</span><span class="w"> </span><span class="n">outputList</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w">              </span><span class="o">=</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">;</span>
<span class="linenos"> 9</span>
<span class="linenos">10</span><span class="w"> </span><span class="c1">// operation attributes</span>
<span class="hll"><span class="linenos">11</span><span class="w"> </span><span class="n">Qnn_OpConfig_t</span><span class="w"> </span><span class="n">opDefinition</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OPCONFIG_INIT</span><span class="p">;</span>
</span><span class="linenos">12</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">name</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;exampleOp&quot;</span><span class="p">;</span>
<span class="linenos">13</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">packageName</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;qti.aisw&quot;</span><span class="p">;</span>
<span class="linenos">14</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">typeName</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_XYZ</span><span class="p">;</span>
<span class="linenos">15</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfParams</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">params</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">nodeParams</span><span class="p">;</span>
<span class="linenos">17</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfInputs</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">18</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">inputTensors</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">inputList</span><span class="p">;</span>
<span class="linenos">19</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfOutputs</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos">20</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">outputTensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outputList</span><span class="p">;</span>
<span class="linenos">21</span>
<span class="linenos">22</span><span class="w"> </span><span class="c1">// add the node to the graph</span>
<span class="hll"><span class="linenos">23</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnGraph_addNode</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">opDefinition</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p>Now with a comparative understanding of how nodes are added to Hexagon-nn and QNN the next section
will illustrate adding nodes to the simple network to show the connectivity.</p>
</div>
<div class="section" id="add-nodes-input">
<h3>Add Nodes - input<a class="headerlink" href="#add-nodes-input" title="Permalink to this heading">¶</a></h3>
<p><strong>Hexagon-nn Input</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_input_hnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_input_hnn.png" src="../../_static/resources/qnn_tutorial_migrate_input_hnn.png" style="width: 200px;" /></a>
<p>Hexagon-nn requires an INPUT op to be added with the output describing the dimensions and sizes of
the graph’s input(s).  It will read in tensors from hexagon_nn_tensordef during the
hexagon_nn_execute call. See the <a class="reference internal" href="#execute-graph">Execute Graph</a> section below for more details.</p>
<div class="literal-block-wrapper docutils container" id="id12">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Input</span><a class="headerlink" href="#id12" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="n">hexagon_nn_output</span><span class="w"> </span><span class="n">outputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{{.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos"> 2</span><span class="w">                                 </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos"> 3</span><span class="w">                                 </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 4</span><span class="w">                                 </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos"> 5</span><span class="w">                                 </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">},</span>
<span class="linenos"> 6</span><span class="w">                                </span><span class="p">{.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos"> 7</span><span class="w">                                 </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos"> 8</span><span class="w">                                 </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos"> 9</span><span class="w">                                 </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">10</span><span class="w">                                 </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">},</span>
<span class="linenos">11</span><span class="w">                                </span><span class="p">{.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
<span class="linenos">12</span><span class="w">                                 </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">13</span><span class="w">                                 </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">14</span><span class="w">                                 </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">15</span><span class="w">                                 </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">}};</span>
<span class="linenos">16</span>
<span class="hll"><span class="linenos">17</span><span class="w"> </span><span class="n">hexagon_nn_append_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x01000</span><span class="p">,</span><span class="w"> </span><span class="n">OP_INPUT</span><span class="p">,</span><span class="w"> </span><span class="n">NN_PAD_NA</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p><strong>QNN Input</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_input_qnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_input_qnn.png" src="../../_static/resources/qnn_tutorial_migrate_input_qnn.png" style="width: 150px;" /></a>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The QNN input is an activation tensor defined to be of type QNN_TENSOR_TYPE_APP_WRITE.</p>
</div>
<div class="literal-block-wrapper docutils container" id="id13">
<div class="code-block-caption"><span class="caption-text">QNN Input</span><a class="headerlink" href="#id13" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// input (activation tensor)</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">inputDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">}</span>
<span class="hll"><span class="linenos"> 3</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">inputTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 4</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 5</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;convInput&quot;</span><span class="p">;</span>
<span class="hll"><span class="linenos"> 7</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_APP_WRITE</span><span class="p">;</span>
</span><span class="linenos"> 8</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos"> 9</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">10</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">11</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">12</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0256975870579481</span><span class="p">;</span>
<span class="linenos">13</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-132</span><span class="p">;</span>
<span class="linenos">14</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos">15</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">inputDimensions</span><span class="p">;</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">17</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_CLIENT_BUFFER_INIT</span><span class="p">;</span>
<span class="linenos">18</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">19</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">20</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">21</span>
<span class="hll"><span class="linenos">22</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">inputTensor</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
</div>
<div class="section" id="add-nodes-convolution">
<h3>Add Nodes - convolution<a class="headerlink" href="#add-nodes-convolution" title="Permalink to this heading">¶</a></h3>
<p><strong>Hexagon-nn Convolution</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_conv_hnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_conv_hnn.png" src="../../_static/resources/qnn_tutorial_migrate_conv_hnn.png" style="width: 325px;" /></a>
<p>Hexagon-nn convolution node accepts 7 inputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] input activation, min and max from the INPUT node</p></li>
<li><p>[3] weights, min and max added as constant nodes</p></li>
<li><p>[1] stride shape added as a constant node</p></li>
</ul>
</div></blockquote>
<p>and 3 outputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] output activation, min and max</p></li>
</ul>
</div></blockquote>
<div class="literal-block-wrapper docutils container" id="id14">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Convolution</span><a class="headerlink" href="#id14" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// create weight constant nodes</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">weights</span><span class="p">[</span><span class="mi">108</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">219</span><span class="p">,</span><span class="w"> </span><span class="mi">39</span><span class="p">,</span><span class="w"> </span><span class="mi">82</span><span class="p">,</span><span class="w"> </span><span class="mi">157</span><span class="p">,</span><span class="w"> </span><span class="mi">172</span><span class="p">,</span><span class="w"> </span><span class="mi">80</span><span class="p">,</span><span class="w"> </span><span class="p">...};</span>
<span class="linenos"> 3</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">weightsMin</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mf">-0.003076</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 4</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">weightsMax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="mf">0.003076</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 5</span>
<span class="hll"><span class="linenos"> 6</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x12001</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="mi">108</span><span class="p">);</span>
</span><span class="hll"><span class="linenos"> 7</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x12002</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">weightsMin</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
</span><span class="hll"><span class="linenos"> 8</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x12003</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">weightsMax</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
</span><span class="linenos"> 9</span>
<span class="linenos">10</span><span class="w"> </span><span class="c1">// create stride constant node</span>
<span class="hll"><span class="linenos">11</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x12004</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
</span><span class="linenos">12</span>
<span class="linenos">13</span><span class="w"> </span><span class="c1">// define the input</span>
<span class="linenos">14</span><span class="w"> </span><span class="n">hexagon_nn_input</span><span class="w"> </span><span class="n">convInputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">15</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// output of the INPUT node</span>
<span class="linenos">16</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x01000</span><span class="p">,</span>
<span class="linenos">17</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">18</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos">19</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// weights</span>
<span class="linenos">20</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x12001</span><span class="p">,</span>
<span class="linenos">21</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">22</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos">23</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// output of the INPUT min</span>
<span class="linenos">24</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x01000</span><span class="p">,</span>
<span class="linenos">25</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">26</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos">27</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// output of the INPUT max</span>
<span class="linenos">28</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x01000</span><span class="p">,</span>
<span class="linenos">29</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="linenos">30</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos">31</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// weights min</span>
<span class="linenos">32</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x12002</span><span class="p">,</span>
<span class="linenos">33</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">34</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos">35</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// weights max</span>
<span class="linenos">36</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x12003</span><span class="p">,</span>
<span class="linenos">37</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">38</span><span class="w">                               </span><span class="p">},</span>
<span class="linenos">39</span><span class="w">                               </span><span class="p">{</span><span class="w"> </span><span class="c1">// stride</span>
<span class="linenos">40</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x12004</span><span class="p">,</span>
<span class="linenos">41</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">42</span><span class="w">                               </span><span class="p">}</span>
<span class="linenos">43</span><span class="w">                             </span><span class="p">};</span>
<span class="linenos">44</span>
<span class="linenos">45</span><span class="w"> </span><span class="c1">// define the output</span>
<span class="linenos">46</span><span class="w"> </span><span class="n">hexagon_nn_output</span><span class="w"> </span><span class="n">convOutputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">47</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">48</span><span class="w">                                   </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">49</span><span class="w">                                   </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">50</span><span class="w">                                   </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">51</span><span class="w">                                   </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">52</span><span class="w">                                   </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">53</span><span class="w">                                 </span><span class="p">},</span>
<span class="linenos">54</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">55</span><span class="w">                                   </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">56</span><span class="w">                                   </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">57</span><span class="w">                                   </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">58</span><span class="w">                                   </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">59</span><span class="w">                                   </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">60</span><span class="w">                                 </span><span class="p">},</span>
<span class="linenos">61</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">62</span><span class="w">                                   </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">63</span><span class="w">                                   </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">64</span><span class="w">                                   </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">65</span><span class="w">                                   </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">66</span><span class="w">                                   </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">67</span><span class="w">                                 </span><span class="p">}</span>
<span class="linenos">68</span><span class="w">                               </span><span class="p">};</span>
<span class="linenos">69</span>
<span class="linenos">70</span><span class="w"> </span><span class="c1">// add the node to the graph</span>
<span class="hll"><span class="linenos">71</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x02000</span><span class="p">,</span><span class="w"> </span><span class="n">OP_QuantizedConv2d_8x8to32</span><span class="p">,</span><span class="w"> </span><span class="n">NN_PAD_VALID</span><span class="p">,</span><span class="w"> </span><span class="n">convInputs</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="n">convOutputs</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Padding is specified as an input argument into the hexagon_nn_append_node API.</p>
</div>
<p>To add the biases after the convolution Hexagon-nn requires a biasAdd node to be appended to the
graph.</p>
<p>This bias node accepts 6 inputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] input activation, min and max from output of the convolution node</p></li>
<li><p>[3] biases, min and max added as constant nodes</p></li>
</ul>
</div></blockquote>
<p>and 3 outputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] output activation, min and max</p></li>
</ul>
</div></blockquote>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_conv_bias_hnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_conv_bias_hnn.png" src="../../_static/resources/qnn_tutorial_migrate_conv_bias_hnn.png" style="width: 350px;" /></a>
<div class="literal-block-wrapper docutils container" id="id15">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Convolution biasAdd</span><a class="headerlink" href="#id15" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// create bias constant nodes</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">convBias</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">-1315013842</span><span class="p">,</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="mi">-2147483647</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 3</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">convBiasMin</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mf">-0.860266387462616</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 4</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">convBiasMax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mf">0.860266387462616</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 5</span>
<span class="hll"><span class="linenos"> 6</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x13001</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">convBias</span><span class="p">,</span><span class="w"> </span><span class="mi">108</span><span class="p">);</span>
</span><span class="hll"><span class="linenos"> 7</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x13002</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">convBiasMin</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
</span><span class="hll"><span class="linenos"> 8</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x13003</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">convBiasMax</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
</span><span class="linenos"> 9</span>
<span class="linenos">10</span><span class="w"> </span><span class="n">hexagon_nn_input</span><span class="w"> </span><span class="n">convBiasInputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">11</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">12</span><span class="w">                                     </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x02000</span><span class="p">,</span>
<span class="linenos">13</span><span class="w">                                     </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">14</span><span class="w">                                   </span><span class="p">},</span>
<span class="linenos">15</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">16</span><span class="w">                                      </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x13001</span><span class="p">,</span>
<span class="linenos">17</span><span class="w">                                      </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">18</span><span class="w">                                   </span><span class="p">},</span>
<span class="linenos">19</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">20</span><span class="w">                                      </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x02000</span><span class="p">,</span>
<span class="linenos">21</span><span class="w">                                      </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">22</span><span class="w">                                   </span><span class="p">},</span>
<span class="linenos">23</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">24</span><span class="w">                                      </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x02000</span><span class="p">,</span>
<span class="linenos">25</span><span class="w">                                      </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="linenos">26</span><span class="w">                                   </span><span class="p">},</span>
<span class="linenos">27</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">28</span><span class="w">                                      </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x13002</span><span class="p">,</span>
<span class="linenos">29</span><span class="w">                                      </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">30</span><span class="w">                                   </span><span class="p">},</span>
<span class="linenos">31</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">32</span><span class="w">                                      </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x13003</span><span class="p">,</span>
<span class="linenos">33</span><span class="w">                                      </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">34</span><span class="w">                                   </span><span class="p">}</span>
<span class="linenos">35</span><span class="w">                                 </span><span class="p">};</span>
<span class="linenos">36</span>
<span class="linenos">37</span><span class="w"> </span><span class="n">hexagon_nn_output</span><span class="w"> </span><span class="n">convBiasOutputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">38</span><span class="w">                                     </span><span class="p">{</span>
<span class="linenos">39</span><span class="w">                                       </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">40</span><span class="w">                                       </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">41</span><span class="w">                                       </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">42</span><span class="w">                                       </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">43</span><span class="w">                                       </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">44</span><span class="w">                                     </span><span class="p">},</span>
<span class="linenos">45</span><span class="w">                                     </span><span class="p">{</span>
<span class="linenos">46</span><span class="w">                                       </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
<span class="linenos">47</span><span class="w">                                       </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">48</span><span class="w">                                       </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">49</span><span class="w">                                       </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">50</span><span class="w">                                       </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">51</span><span class="w">                                     </span><span class="p">},</span>
<span class="linenos">52</span><span class="w">                                     </span><span class="p">{</span>
<span class="linenos">53</span><span class="w">                                       </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
<span class="linenos">54</span><span class="w">                                       </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">55</span><span class="w">                                       </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">56</span><span class="w">                                       </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">57</span><span class="w">                                       </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">58</span><span class="w">                                     </span><span class="p">}</span>
<span class="linenos">59</span><span class="w">                                   </span><span class="p">};</span>
<span class="linenos">60</span>
<span class="hll"><span class="linenos">61</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x03000</span><span class="p">,</span><span class="w"> </span><span class="n">OP_QuantizedBiasAdd_32p32to32</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">62</span><span class="w">                               </span><span class="n">NN_PAD_NA</span><span class="p">,</span><span class="w"> </span><span class="n">convBiasInputs</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">convBiasOutputs</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span>
</span></pre></div>
</div>
</div>
<p>For QNN, the biases are added as a static tensor input to the convolution node. <em>See convolution
example below for details</em>.</p>
<p><strong>QNN Convolution</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_conv_qnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_conv_qnn.png" src="../../_static/resources/qnn_tutorial_migrate_conv_qnn.png" style="width: 350px;" /></a>
<p>QNN convolution node accepts 4 inputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[1] input activation tensor</p></li>
<li><p>[1] weights static tensor</p></li>
<li><p>[1] biases static tensor</p></li>
<li><p>[1] parameter list consisting of</p>
<ul>
<li><p>[1] stride static tensor</p></li>
<li><p>[1] pad static tensor</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<p>and 1 output:</p>
<blockquote>
<div><ul class="simple">
<li><p>[1] output activation</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See the <a class="reference internal" href="#finalize-graph">Finalize Graph</a> section below for more details.</p>
</div>
<div class="literal-block-wrapper docutils container" id="id16">
<div class="code-block-caption"><span class="caption-text">QNN Convolution</span><a class="headerlink" href="#id16" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="w"> </span><span class="c1">// output (activation tensor)</span>
<span class="linenos">  2</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">convOutputDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">};</span>
<span class="hll"><span class="linenos">  3</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">  4</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">  5</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">  6</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;convOutput&quot;</span><span class="p">;</span>
<span class="linenos">  7</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_NATIVE</span><span class="p">;</span>
<span class="linenos">  8</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">  9</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos"> 10</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos"> 11</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos"> 12</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0166513100266457</span><span class="p">;</span>
<span class="linenos"> 13</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-107</span><span class="p">;</span>
<span class="linenos"> 14</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos"> 15</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">convOutputDimensions</span><span class="p">;</span>
<span class="linenos"> 16</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos"> 17</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_CLIENT_BUFFER_INIT</span><span class="p">;</span>
<span class="linenos"> 18</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos"> 19</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos"> 20</span><span class="w"> </span><span class="n">convOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 21</span>
<span class="hll"><span class="linenos"> 22</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">convOutputTensor</span><span class="p">);</span>
</span><span class="linenos"> 23</span>
<span class="linenos"> 24</span><span class="w"> </span><span class="c1">// weights (static tensor)</span>
<span class="linenos"> 25</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">convWeights</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">232</span><span class="p">,</span><span class="w"> </span><span class="mi">177</span><span class="p">,</span><span class="w"> </span><span class="mi">126</span><span class="p">,</span><span class="w"> </span><span class="mi">160</span><span class="p">,</span><span class="w"> </span><span class="mi">15</span><span class="p">,</span><span class="w"> </span><span class="mi">171</span><span class="p">,</span><span class="w"> </span><span class="p">...};</span>
<span class="linenos"> 26</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">convWeightsDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 27</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 28</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 29</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 30</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;convWeights&quot;</span><span class="p">;</span>
<span class="linenos"> 31</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos"> 32</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos"> 33</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos"> 34</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos"> 35</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos"> 36</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0012544898781925</span><span class="p">;</span>
<span class="linenos"> 37</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-129</span><span class="p">;</span>
<span class="linenos"> 38</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos"> 39</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">convWeightsDimensions</span><span class="p">;</span>
<span class="linenos"> 40</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos"> 41</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">convWeights</span><span class="p">;</span>
<span class="linenos"> 42</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">108</span><span class="p">;</span>
<span class="linenos"> 43</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos"> 44</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos"> 45</span><span class="w"> </span><span class="n">convWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 46</span>
<span class="hll"><span class="linenos"> 47</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">convWeightsTensor</span><span class="p">);</span>
</span><span class="linenos"> 48</span>
<span class="linenos"> 49</span><span class="w"> </span><span class="c1">// biases (static tensor)</span>
<span class="linenos"> 50</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">convBiases</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">78</span><span class="p">,</span><span class="w"> </span><span class="mi">255</span><span class="p">,</span><span class="w"> </span><span class="mi">80</span><span class="p">,</span><span class="w"> </span><span class="mi">157</span><span class="p">};</span>
<span class="linenos"> 51</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">convBiasesDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">4</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 52</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 53</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 54</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 55</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;convBiases&quot;</span><span class="p">;</span>
<span class="linenos"> 56</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos"> 57</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos"> 58</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos"> 59</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos"> 60</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos"> 61</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0006514320266433</span><span class="p">;</span>
<span class="linenos"> 62</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 63</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos"> 64</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">convBiasesDimensions</span><span class="p">;</span>
<span class="linenos"> 65</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos"> 66</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">convBiases</span><span class="p">;</span>
<span class="linenos"> 67</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos"> 68</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos"> 69</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos"> 70</span><span class="w"> </span><span class="n">convBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 71</span>
<span class="hll"><span class="linenos"> 72</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">convBiasesTensor</span><span class="p">);</span>
</span><span class="linenos"> 73</span>
<span class="linenos"> 74</span><span class="w"> </span><span class="c1">// stride (static tensor)</span>
<span class="linenos"> 75</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">convStride</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">};</span>
<span class="linenos"> 76</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">convStrideDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 77</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 78</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 79</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 80</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;convStride&quot;</span><span class="p">;</span>
<span class="linenos"> 81</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos"> 82</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos"> 83</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UINT_32</span><span class="p">;</span>
<span class="linenos"> 84</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_UNDEFINED</span><span class="p">;</span>
<span class="linenos"> 85</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_UNDEFINED</span><span class="p">;</span>
<span class="linenos"> 86</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="linenos"> 87</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 88</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos"> 89</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">convStrideDimensions</span><span class="p">;</span>
<span class="linenos"> 90</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">convStride</span><span class="p">;</span>
<span class="linenos"> 91</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="p">;</span>
<span class="linenos"> 92</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos"> 93</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos"> 94</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 95</span>
<span class="hll"><span class="linenos"> 96</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">convStrideTensor</span><span class="p">);</span>
</span><span class="linenos"> 97</span>
<span class="linenos"> 98</span><span class="w"> </span><span class="c1">// pad (static tensor)</span>
<span class="linenos"> 99</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">convPad</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">};</span>
<span class="linenos">100</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">convPadDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">};</span>
<span class="hll"><span class="linenos">101</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">convPadTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">102</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">103</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">104</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;convPad&quot;</span><span class="p">;</span>
<span class="linenos">105</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos">106</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">107</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UINT_32</span><span class="p">;</span>
<span class="linenos">108</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_UNDEFINED</span><span class="p">;</span>
<span class="linenos">109</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_UNDEFINED</span><span class="p">;</span>
<span class="linenos">110</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="linenos">111</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">112</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">113</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">convPadDimensions</span><span class="p">;</span>
<span class="linenos">114</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">convPad</span><span class="p">;</span>
<span class="linenos">115</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="linenos">116</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">117</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">118</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">119</span>
<span class="hll"><span class="linenos">120</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">convPadTensor</span><span class="p">);</span>
</span><span class="linenos">121</span>
<span class="hll"><span class="linenos">122</span><span class="w"> </span><span class="n">Qnn_Param_t</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">QNN_PARAM_INIT</span><span class="p">,</span><span class="w"> </span><span class="n">QNN_PARAM_INIT</span><span class="p">};</span>
</span><span class="linenos">123</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">paramType</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_PARAMTYPE_TENSOR</span><span class="p">;</span>
<span class="linenos">124</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_CONV_2D_PARAM_STRIDE</span><span class="p">;</span>
<span class="linenos">125</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">tensorParam</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convStrideTensor</span><span class="p">;</span>
<span class="linenos">126</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">paramType</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_PARAMTYPE_TENSOR</span><span class="p">;</span>
<span class="linenos">127</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">name</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_CONV_2D_PARAM_PAD_AMOUNT</span><span class="p">;</span>
<span class="linenos">128</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">tensorParam</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convPadTensor</span><span class="p">;</span>
<span class="linenos">129</span>
<span class="linenos">130</span><span class="w"> </span><span class="c1">// create a list of all input tensors</span>
<span class="hll"><span class="linenos">131</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">convInputList</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">132</span><span class="w">                                   </span><span class="n">inputTensor</span><span class="p">,</span>
<span class="linenos">133</span><span class="w">                                   </span><span class="n">convWeightsTensor</span><span class="p">,</span>
<span class="linenos">134</span><span class="w">                                   </span><span class="n">convBiasesTensor</span>
<span class="linenos">135</span><span class="w">                                 </span><span class="p">};</span>
<span class="linenos">136</span>
<span class="linenos">137</span><span class="w"> </span><span class="c1">// create a list of all output tensors</span>
<span class="hll"><span class="linenos">138</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">convOutputList</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">convOutputTensor</span><span class="p">};</span>
</span><span class="linenos">139</span>
<span class="linenos">140</span><span class="w"> </span><span class="c1">// operation definition</span>
<span class="hll"><span class="linenos">141</span><span class="w"> </span><span class="n">Qnn_OpConfig_t</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OPCONFIG_INIT</span><span class="p">;</span>
</span><span class="linenos">142</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">name</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;conv&quot;</span><span class="p">;</span>
<span class="linenos">143</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">packageName</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;qti.aisw&quot;</span><span class="p">;</span>
<span class="linenos">144</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">typeName</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_CONV_2D</span><span class="p">;</span>
<span class="linenos">145</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfParams</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">146</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">params</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">convParamsList</span><span class="p">;</span>
<span class="linenos">147</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfInputs</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<span class="linenos">148</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">inputTensors</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">convInputList</span><span class="p">;</span>
<span class="linenos">149</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfOutputs</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos">150</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">outputTensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convOutputList</span><span class="p">;</span>
<span class="linenos">151</span>
<span class="linenos">152</span><span class="w"> </span><span class="c1">// add the node to the graph</span>
<span class="hll"><span class="linenos">153</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnGraph_addNode</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">convOpDefinition</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
</div>
<div class="section" id="add-nodes-fully-connected-fc">
<h3>Add Nodes - fully connected (fc)<a class="headerlink" href="#add-nodes-fully-connected-fc" title="Permalink to this heading">¶</a></h3>
<p><strong>Hexagon-nn FC</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_fc_hnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_fc_hnn.png" src="../../_static/resources/qnn_tutorial_migrate_fc_hnn.png" style="width: 350px;" /></a>
<p>Hexagon-nn fully connected node is represented by the MatMul operation. It accepts 6 inputs.</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] input activation, min and max from the output of the convolution biasAdd node</p></li>
<li><p>[3] weights, min and max added as constant nodes</p></li>
</ul>
</div></blockquote>
<p>and 3 outputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] output activation, min and max</p></li>
</ul>
</div></blockquote>
<div class="literal-block-wrapper docutils container" id="id17">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Fully Connected</span><a class="headerlink" href="#id17" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// create bias constant nodes</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">bias</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">-1315013842</span><span class="p">,</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="mi">-2147483647</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 3</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">biasMin</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mf">-0.860266387462616</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 4</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">biasMax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mf">0.860266387462616</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 5</span>
<span class="hll"><span class="linenos"> 6</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x14001</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 7</span><span class="w">                                     </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="mi">108</span><span class="p">);</span>
</span><span class="linenos"> 8</span>
<span class="hll"><span class="linenos"> 9</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x14002</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">10</span><span class="w">                                     </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">weightsMin</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
</span><span class="linenos">11</span>
<span class="hll"><span class="linenos">12</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_const_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x14003</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">13</span><span class="w">                                     </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">weightsMax</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
</span><span class="linenos">14</span>
<span class="hll"><span class="linenos">15</span><span class="w"> </span><span class="n">hexagon_nn_input</span><span class="w"> </span><span class="n">fcInputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">16</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">17</span><span class="w">                                   </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x03000</span><span class="p">,</span>
<span class="linenos">18</span><span class="w">                                   </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">19</span><span class="w">                                 </span><span class="p">},</span>
<span class="linenos">20</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">21</span><span class="w">                                    </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x14001</span><span class="p">,</span>
<span class="linenos">22</span><span class="w">                                    </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">23</span><span class="w">                                 </span><span class="p">},</span>
<span class="linenos">24</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">25</span><span class="w">                                    </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x03001</span><span class="p">,</span>
<span class="linenos">26</span><span class="w">                                    </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">27</span><span class="w">                                 </span><span class="p">},</span>
<span class="linenos">28</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">29</span><span class="w">                                    </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x03002</span><span class="p">,</span>
<span class="linenos">30</span><span class="w">                                    </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="linenos">31</span><span class="w">                                 </span><span class="p">},</span>
<span class="linenos">32</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">33</span><span class="w">                                    </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x14002</span><span class="p">,</span>
<span class="linenos">34</span><span class="w">                                    </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">35</span><span class="w">                                 </span><span class="p">},</span>
<span class="linenos">36</span><span class="w">                                 </span><span class="p">{</span>
<span class="linenos">37</span><span class="w">                                    </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0x14003</span><span class="p">,</span>
<span class="linenos">38</span><span class="w">                                    </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">39</span><span class="w">                                 </span><span class="p">}</span>
<span class="linenos">40</span><span class="w">                               </span><span class="p">};</span>
<span class="linenos">41</span>
<span class="hll"><span class="linenos">42</span><span class="w"> </span><span class="n">hexagon_nn_output</span><span class="w"> </span><span class="n">fcOutputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">43</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">44</span><span class="w">                                     </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">45</span><span class="w">                                     </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">46</span><span class="w">                                     </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">47</span><span class="w">                                     </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="linenos">48</span><span class="w">                                     </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">49</span><span class="w">                                   </span><span class="p">},</span>
<span class="linenos">50</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">51</span><span class="w">                                     </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">52</span><span class="w">                                     </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">53</span><span class="w">                                     </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">54</span><span class="w">                                     </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">55</span><span class="w">                                     </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">56</span><span class="w">                                   </span><span class="p">},</span>
<span class="linenos">57</span><span class="w">                                   </span><span class="p">{</span>
<span class="linenos">58</span><span class="w">                                     </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">59</span><span class="w">                                     </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">60</span><span class="w">                                     </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">61</span><span class="w">                                     </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">62</span><span class="w">                                     </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.00000115</span>
<span class="linenos">63</span><span class="w">                                   </span><span class="p">}</span>
<span class="linenos">64</span><span class="w">                                 </span><span class="p">};</span>
<span class="linenos">65</span>
<span class="hll"><span class="linenos">66</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x04000</span><span class="p">,</span><span class="w"> </span><span class="n">OP_QuantizedMatMul_8x8to32</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">67</span><span class="w">                               </span><span class="n">NN_PAD_NA</span><span class="p">,</span><span class="w"> </span><span class="n">fcInputs</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">fcOutputs</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p>A bias node follows the fully connected node and accepts 6 inputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] input activation, min and max from the output of the MatMul (fc) node</p></li>
<li><p>[3] biases, min and max added as constant nodes</p></li>
</ul>
</div></blockquote>
<p>and 3 outputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] output activation, min and max</p></li>
</ul>
</div></blockquote>
<p>For QNN, the biases are added as a static tensor input to the fully connected (FC) node.
<em>See the QNN FC example below for details</em>.</p>
<p><strong>QNN FC</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_fc_qnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_fc_qnn.png" src="../../_static/resources/qnn_tutorial_migrate_fc_qnn.png" style="width: 350px;" /></a>
<p>QNN fully connected node accepts 3 inputs:</p>
<blockquote>
<div><ul class="simple">
<li><p>[1] output activation from the convolution node</p></li>
<li><p>[1] weights static tensor</p></li>
<li><p>[1] biases static tensor</p></li>
</ul>
</div></blockquote>
<p>and 1 output</p>
<blockquote>
<div><ul class="simple">
<li><p>[1] output activation</p></li>
</ul>
</div></blockquote>
<div class="literal-block-wrapper docutils container" id="id18">
<div class="code-block-caption"><span class="caption-text">QNN Fully Connected</span><a class="headerlink" href="#id18" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// output (activation tensor)</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">fcOutputDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 3</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 4</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 5</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;fcOutput&quot;</span><span class="p">;</span>
<span class="linenos"> 7</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_NATIVE</span><span class="p">;</span>
<span class="linenos"> 8</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos"> 9</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">10</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">11</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">12</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0024064707104117</span><span class="p">;</span>
<span class="linenos">13</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-151</span><span class="p">;</span>
<span class="linenos">14</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">15</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">fcOutputDimensions</span><span class="p">;</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">17</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_CLIENT_BUFFER_INIT</span><span class="p">;</span>
<span class="linenos">18</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">19</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">20</span><span class="w"> </span><span class="n">fcOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">21</span>
<span class="hll"><span class="linenos">22</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">fcOutputTensor</span><span class="p">);</span>
</span><span class="linenos">23</span>
<span class="linenos">24</span><span class="w"> </span><span class="c1">// weights (static tensor)</span>
<span class="linenos">25</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">fcWeights</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">223</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">73</span><span class="p">,</span><span class="w"> </span><span class="mi">137</span><span class="p">,</span><span class="w"> </span><span class="mi">199</span><span class="p">,</span><span class="w"> </span><span class="mi">155</span><span class="p">,</span><span class="w"> </span><span class="p">...};</span>
<span class="linenos">26</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">fcWeightsDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">3600</span><span class="p">};</span>
<span class="hll"><span class="linenos">27</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">28</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">29</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">30</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;fcWeights&quot;</span><span class="p">;</span>
<span class="linenos">31</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos">32</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">33</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">34</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">35</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">36</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0000707526414772</span><span class="p">;</span>
<span class="linenos">37</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-128</span><span class="p">;</span>
<span class="linenos">38</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">39</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">fcWeightsDimensions</span><span class="p">;</span>
<span class="linenos">40</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">fcWeights</span><span class="p">;</span>
<span class="linenos">41</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">36000</span><span class="p">;</span>
<span class="linenos">42</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">43</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">44</span><span class="w"> </span><span class="n">fcWeightsTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">45</span>
<span class="hll"><span class="linenos">46</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">fcWeightsTensor</span><span class="p">);</span>
</span><span class="linenos">47</span>
<span class="linenos">48</span><span class="w"> </span><span class="c1">// biases (static tensor)</span>
<span class="linenos">49</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">fcBiases</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">230</span><span class="p">,</span><span class="w"> </span><span class="mi">174</span><span class="p">,</span><span class="w"> </span><span class="mi">41</span><span class="p">,</span><span class="w"> </span><span class="mi">246</span><span class="p">,</span><span class="w"> </span><span class="mi">26</span><span class="p">,</span><span class="w"> </span><span class="mi">247</span><span class="p">,</span><span class="w"> </span><span class="p">...};</span>
<span class="linenos">50</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">fcBiasesDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">};</span>
<span class="hll"><span class="linenos">51</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">52</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">53</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">54</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;fcBiases&quot;</span><span class="p">;</span>
<span class="linenos">55</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_STATIC</span><span class="p">;</span>
<span class="linenos">56</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">57</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">58</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">59</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">60</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0000581612985115</span><span class="p">;</span>
<span class="linenos">61</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-116</span><span class="p">;</span>
<span class="linenos">62</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos">63</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">fcBiasesDimensions</span><span class="p">;</span>
<span class="linenos">64</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">fcBiases</span><span class="p">;</span>
<span class="linenos">65</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span>
<span class="linenos">66</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">67</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">68</span><span class="w"> </span><span class="n">fcBiasesTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">69</span>
<span class="hll"><span class="linenos">70</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">fcBiasesTensor</span><span class="p">);</span>
</span><span class="linenos">71</span>
<span class="linenos">72</span><span class="w"> </span><span class="c1">// create a list of all input tensors</span>
<span class="hll"><span class="linenos">73</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">fcInputList</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">74</span><span class="w">                                 </span><span class="n">convOutputTensor</span><span class="p">,</span><span class="w"> </span><span class="c1">// output activation from convolution node</span>
<span class="linenos">75</span><span class="w">                                 </span><span class="n">fcWeightsTensor</span><span class="p">,</span>
<span class="linenos">76</span><span class="w">                                 </span><span class="n">fcBiasesTensor</span>
<span class="linenos">77</span><span class="w">                               </span><span class="p">};</span>
<span class="linenos">78</span>
<span class="linenos">79</span><span class="w"> </span><span class="c1">// create a list of all output tensors</span>
<span class="hll"><span class="linenos">80</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">fcOutputList</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">fcOutputTensor</span><span class="p">};</span>
</span><span class="linenos">81</span>
<span class="linenos">82</span><span class="w"> </span><span class="c1">// operation definition</span>
<span class="hll"><span class="linenos">83</span><span class="w"> </span><span class="n">Qnn_OpConfig_t</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OPCONFIG_INIT</span><span class="p">;</span>
</span><span class="linenos">84</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">name</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;fc&quot;</span><span class="p">;</span>
<span class="linenos">85</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">packageName</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;qti.aisw&quot;</span><span class="p">;</span>
<span class="linenos">86</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">typeName</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_FULLY_CONNECTED</span><span class="p">;</span>
<span class="linenos">87</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfParams</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">88</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">params</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">89</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfInputs</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<span class="linenos">90</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">inputTensors</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">fcInputList</span><span class="p">;</span>
<span class="linenos">91</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfOutputs</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos">92</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">outputTensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fcOutputList</span><span class="p">;</span>
<span class="linenos">93</span>
<span class="linenos">94</span><span class="w"> </span><span class="c1">// add the node to the graph</span>
<span class="hll"><span class="linenos">95</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnGraph_addNode</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">fcOpDefinition</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
</div>
<div class="section" id="add-nodes-softmax">
<h3>Add Nodes - SoftMax<a class="headerlink" href="#add-nodes-softmax" title="Permalink to this heading">¶</a></h3>
<p><strong>Hexagon-nn SoftMax</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_softmax_hnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_softmax_hnn.png" src="../../_static/resources/qnn_tutorial_migrate_softmax_hnn.png" style="width: 225px;" /></a>
<p>Hexagon-nn fully SoftMax node accepts 3 inputs</p>
<blockquote>
<div><ul class="simple">
<li><p>[3] input activation from the output of the fully connected BiasAdd node</p></li>
</ul>
</div></blockquote>
<p>and 1 output</p>
<blockquote>
<div><ul class="simple">
<li><p>[1] output activation</p></li>
</ul>
</div></blockquote>
<div class="literal-block-wrapper docutils container" id="id19">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn SoftMax</span><a class="headerlink" href="#id19" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="linenos"> 1</span><span class="w"> </span><span class="n">hexagon_nn_input</span><span class="w"> </span><span class="n">softMaxInputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos"> 2</span><span class="w">                                       </span><span class="p">{</span>
<span class="linenos"> 3</span><span class="w">                                          </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mh">0x05000</span><span class="p">),</span>
<span class="linenos"> 4</span><span class="w">                                          </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="linenos"> 5</span><span class="w">                                       </span><span class="p">},</span>
<span class="linenos"> 6</span><span class="w">                                       </span><span class="p">{</span>
<span class="linenos"> 7</span><span class="w">                                          </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mh">0x05001</span><span class="p">),</span>
<span class="linenos"> 8</span><span class="w">                                          </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos"> 9</span><span class="w">                                       </span><span class="p">},</span>
<span class="linenos">10</span><span class="w">                                       </span><span class="p">{</span>
<span class="linenos">11</span><span class="w">                                          </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mh">0x05002</span><span class="p">),</span>
<span class="linenos">12</span><span class="w">                                          </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
<span class="linenos">13</span><span class="w">                                       </span><span class="p">}</span>
<span class="linenos">14</span><span class="w">                                     </span><span class="p">};</span>
<span class="linenos">15</span>
<span class="hll"><span class="linenos">16</span><span class="w"> </span><span class="n">hexagon_nn_output</span><span class="w"> </span><span class="n">softMaxOutputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">17</span><span class="w">                                         </span><span class="p">{</span>
<span class="linenos">18</span><span class="w">                                           </span><span class="p">.</span><span class="n">rank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">19</span><span class="w">                                           </span><span class="p">.</span><span class="n">max_sizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span>
<span class="linenos">20</span><span class="w">                                           </span><span class="p">.</span><span class="n">elementsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">21</span><span class="w">                                           </span><span class="p">.</span><span class="n">zero_offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">22</span><span class="w">                                           </span><span class="p">.</span><span class="n">stepsize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="linenos">23</span><span class="w">                                         </span><span class="p">}</span>
<span class="linenos">24</span><span class="w">                                       </span><span class="p">};</span>
<span class="linenos">25</span>
<span class="hll"><span class="linenos">26</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_append_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x00024002</span><span class="p">,</span><span class="w"> </span><span class="n">OP_Softmax_uint8</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">27</span><span class="w">                               </span><span class="n">NN_PAD_NA</span><span class="p">,</span><span class="w"> </span><span class="n">softMaxInputs</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="n">softMaxOutputs</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p><strong>QNN SoftMax</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_softmax_qnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_softmax_qnn.png" src="../../_static/resources/qnn_tutorial_migrate_softmax_qnn.png" style="width: 225px;" /></a>
<p>QNN SoftMax node accepts 1 input</p>
<blockquote>
<div><ul class="simple">
<li><p>[1] input activation from the output of the fully connected node</p></li>
</ul>
</div></blockquote>
<p>and 1 output</p>
<blockquote>
<div><ul class="simple">
<li><p>[1] output activation</p></li>
</ul>
</div></blockquote>
<div class="literal-block-wrapper docutils container" id="id20">
<div class="code-block-caption"><span class="caption-text">QNN SoftMax</span><a class="headerlink" href="#id20" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// output (activation tensor)</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">softMaxOutputDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">};</span>
<span class="hll"><span class="linenos"> 3</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos"> 4</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos"> 5</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;probOutput&quot;</span><span class="p">;</span>
<span class="hll"><span class="linenos"> 7</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_APP_READ</span><span class="p">;</span>
</span><span class="linenos"> 8</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos"> 9</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">10</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">11</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">12</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.00390625</span><span class="p">;</span>
<span class="linenos">13</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">14</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">15</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">softMaxOutputDimensions</span><span class="p">;</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">17</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_CLIENT_BUFFER_INIT</span><span class="p">;</span>
<span class="linenos">18</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">19</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">20</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">21</span>
<span class="hll"><span class="linenos">22</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnTensor_createGraphTensor</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">softMaxOutputTensor</span><span class="p">);</span>
</span><span class="linenos">23</span>
<span class="linenos">24</span><span class="w"> </span><span class="c1">// create a list of all input tensors</span>
<span class="hll"><span class="linenos">25</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">softMaxInputList</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">fcOutputTensor</span><span class="p">};</span>
</span><span class="linenos">26</span>
<span class="linenos">27</span><span class="w"> </span><span class="c1">// create a list of all output tensors</span>
<span class="hll"><span class="linenos">28</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">softMaxOutputList</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">softMaxOutputTensor</span><span class="p">};</span>
</span><span class="linenos">29</span>
<span class="linenos">30</span><span class="w"> </span><span class="c1">// operation definition</span>
<span class="hll"><span class="linenos">31</span><span class="w"> </span><span class="n">Qnn_OpConfig_t</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OPCONFIG_INIT</span><span class="p">;</span>
</span><span class="linenos">32</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">name</span><span class="w">          </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;prob&quot;</span><span class="p">;</span>
<span class="linenos">33</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">packageName</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;qti.aisw&quot;</span><span class="p">;</span>
<span class="linenos">34</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">typeName</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_OP_SOFTMAX</span><span class="p">;</span>
<span class="linenos">35</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfParams</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">36</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">params</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">37</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfInputs</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos">38</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">inputTensors</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">softMaxInputList</span><span class="p">;</span>
<span class="linenos">39</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">numOfOutputs</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="linenos">40</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">outputTensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">softMaxOutputList</span><span class="p">;</span>
<span class="linenos">41</span>
<span class="linenos">42</span><span class="w"> </span><span class="c1">// add the node to the graph</span>
<span class="hll"><span class="linenos">43</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnGraph_addNode</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">softMaxOpDefinition</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
</div>
<div class="section" id="add-nodes-output">
<h3>Add Nodes - output<a class="headerlink" href="#add-nodes-output" title="Permalink to this heading">¶</a></h3>
<p><strong>Hexagon-nn output</strong></p>
<a class="reference internal image-reference" href="../../_static/resources/qnn_tutorial_migrate_output_hnn.png"><img alt="../../_static/resources/qnn_tutorial_migrate_output_hnn.png" src="../../_static/resources/qnn_tutorial_migrate_output_hnn.png" style="width: 225px;" /></a>
<p>Hexagon-nn requires an OUTPUT node to be added with inputs referring to tensors that will be the
graph’s output(s).  It will output tensors to the hexagon_nn_tensordef provided during the
call to hexagon_nn_execute. See the <a class="reference internal" href="#execute-graph">Execute Graph</a> section below for more details.</p>
<div class="literal-block-wrapper docutils container" id="id21">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Output</span><a class="headerlink" href="#id21" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="w"> </span><span class="n">hexagon_nn_input</span><span class="w"> </span><span class="n">outputInputs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{{</span>
<span class="linenos">2</span><span class="w">     </span><span class="p">.</span><span class="n">src_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mh">0x06000</span><span class="p">),</span>
<span class="linenos">3</span><span class="w">     </span><span class="p">.</span><span class="n">output_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="linenos">4</span><span class="w"> </span><span class="p">}};</span>
<span class="linenos">5</span>
<span class="hll"><span class="linenos">6</span><span class="w"> </span><span class="n">hexagon_nn_append_node</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="mh">0x07000</span><span class="p">,</span><span class="w"> </span><span class="n">OP_OUTPUT</span><span class="p">,</span><span class="w"> </span><span class="n">NN_PAD_NA</span><span class="p">,</span><span class="w"> </span><span class="n">outputInputs</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p><strong>QNN Output</strong></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The QNN output is an activation tensor defined to be of type QNN_TENSOR_TYPE_APP_READ.
See QNN section in <a class="reference internal" href="#add-nodes-softmax">Add Nodes - SoftMax</a> for example.</p>
</div>
</div>
</div>
<div class="section" id="finalize-graph">
<h2>Finalize Graph<a class="headerlink" href="#finalize-graph" title="Permalink to this heading">¶</a></h2>
<p>Once the Hexagon-nn graph is constructed (above steps) it needs to be prepared (finalized) for
execution.</p>
<div class="literal-block-wrapper docutils container" id="id22">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Finalize</span><a class="headerlink" href="#id22" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="linenos">1</span><span class="n">res</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_prepare</span><span class="p">(</span><span class="n">nng_id</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p>For QNN the graph’s input and output tensors need to be created and registered before finalizing the graph.
These tensors were registered when the QNN nodes were added to the graph.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The QNN input is an activation tensor defined to be of type QNN_TENSOR_TYPE_APP_WRITE.
The QNN output is an activation tensor defined to be of type QNN_TENSOR_TYPE_APP_READ.</p>
</div>
<div class="literal-block-wrapper docutils container" id="id23">
<div class="code-block-caption"><span class="caption-text">QNN Finalize</span><a class="headerlink" href="#id23" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="w"> </span><span class="c1">// don&#39;t forget to do all your error checking (ret == QNN_SUCCESS)</span>
<span class="linenos">2</span><span class="w"> </span><span class="n">Qnn_ProfileHandle_t</span><span class="w"> </span><span class="n">profile</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="linenos">3</span><span class="w"> </span><span class="n">Qnn_SignalHandle_t</span><span class="w"> </span><span class="n">signal</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="hll"><span class="linenos">4</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnGraph_finalize</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="n">profile</span><span class="p">,</span><span class="w"> </span><span class="n">signal</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
</div>
<div class="section" id="execute-graph">
<h2>Execute Graph<a class="headerlink" href="#execute-graph" title="Permalink to this heading">¶</a></h2>
<p><strong>Hexagon-nn</strong></p>
<p>The input and output tensor definitions need to be initialized before graph execution.</p>
<p>Hexagon-nn uses <strong>hexagon_nn_tensordef</strong> structures to describe the tensor attributes for the
inputs and outputs.</p>
<div class="literal-block-wrapper docutils container" id="id24">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Execute</span><a class="headerlink" href="#id24" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">inputData</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mf">15.0</span><span class="p">,</span><span class="w"> </span><span class="mf">82.0</span><span class="p">,</span><span class="w"> </span><span class="mf">85.0</span><span class="p">,</span><span class="w"> </span><span class="mf">71.0</span><span class="p">,</span><span class="w"> </span><span class="mf">20.0</span><span class="p">,</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">inputDataMin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mf">-0.003076</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 3</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">inputDataMax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="mf">0.003076</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 4</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">inputDataNeedsQuantize</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">};</span>
<span class="linenos"> 5</span>
<span class="hll"><span class="linenos"> 6</span><span class="w"> </span><span class="n">hexagon_nn_tensordef</span><span class="w"> </span><span class="n">in_tensor_defs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span>
</span><span class="linenos"> 7</span><span class="w">   </span><span class="p">{</span>
<span class="linenos"> 8</span><span class="w">      </span><span class="p">{</span>
<span class="linenos"> 9</span><span class="w">         </span><span class="p">.</span><span class="n">batches</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">10</span><span class="w">         </span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="linenos">11</span><span class="w">         </span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="linenos">12</span><span class="w">         </span><span class="p">.</span><span class="n">depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="linenos">13</span><span class="w">         </span><span class="p">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">inputData</span><span class="p">,</span>
<span class="linenos">14</span><span class="w">         </span><span class="p">.</span><span class="n">dataLen</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">12288</span><span class="p">,</span>
<span class="linenos">15</span><span class="w">         </span><span class="p">.</span><span class="n">data_valid_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">12288</span><span class="p">,</span>
<span class="linenos">16</span><span class="w">         </span><span class="p">.</span><span class="n">unused</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">17</span><span class="w">      </span><span class="p">},</span>
<span class="linenos">18</span><span class="w">      </span><span class="p">{</span>
<span class="linenos">19</span><span class="w">         </span><span class="p">.</span><span class="n">batches</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">20</span><span class="w">         </span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">21</span><span class="w">         </span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">22</span><span class="w">         </span><span class="p">.</span><span class="n">depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">23</span><span class="w">         </span><span class="p">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">inputDataMin</span><span class="p">,</span>
<span class="linenos">24</span><span class="w">         </span><span class="p">.</span><span class="n">dataLen</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">25</span><span class="w">         </span><span class="p">.</span><span class="n">data_valid_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">26</span><span class="w">         </span><span class="n">unused</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">27</span><span class="w">      </span><span class="p">},</span>
<span class="linenos">28</span><span class="w">      </span><span class="p">{</span>
<span class="linenos">29</span><span class="w">         </span><span class="p">.</span><span class="n">batches</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">30</span><span class="w">         </span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">31</span><span class="w">         </span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">32</span><span class="w">         </span><span class="p">.</span><span class="n">depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">33</span><span class="w">         </span><span class="p">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">inputDataMax</span><span class="p">,</span>
<span class="linenos">34</span><span class="w">         </span><span class="p">.</span><span class="n">dataLen</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">35</span><span class="w">         </span><span class="p">.</span><span class="n">data_valid_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">36</span><span class="w">         </span><span class="p">.</span><span class="n">unused</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">37</span><span class="w">      </span><span class="p">},</span>
<span class="linenos">38</span><span class="w">      </span><span class="p">{</span>
<span class="linenos">39</span><span class="w">         </span><span class="p">.</span><span class="n">batches</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">40</span><span class="w">         </span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">41</span><span class="w">         </span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">42</span><span class="w">         </span><span class="p">.</span><span class="n">depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="linenos">43</span><span class="w">         </span><span class="p">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">inputDataNeedsQuantize</span><span class="p">,</span>
<span class="linenos">44</span><span class="w">         </span><span class="p">.</span><span class="n">dataLen</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">45</span><span class="w">         </span><span class="p">.</span><span class="n">data_valid_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="linenos">46</span><span class="w">         </span><span class="p">.</span><span class="n">unused</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">47</span><span class="w">      </span><span class="p">}</span>
<span class="linenos">48</span><span class="w">   </span><span class="p">};</span>
<span class="linenos">49</span>
<span class="linenos">50</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">outData</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">};</span>
<span class="linenos">51</span>
<span class="hll"><span class="linenos">52</span><span class="w"> </span><span class="n">hexagon_nn_tensordef</span><span class="w"> </span><span class="n">out_tensor_defs</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
</span><span class="linenos">53</span><span class="w">     </span><span class="p">{</span>
<span class="linenos">54</span><span class="w">         </span><span class="p">.</span><span class="n">batches</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos">55</span><span class="w">         </span><span class="p">.</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos">56</span><span class="w">         </span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="linenos">57</span><span class="w">         </span><span class="p">.</span><span class="n">depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="linenos">58</span><span class="w">         </span><span class="p">.</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">outData</span><span class="p">,</span>
<span class="linenos">59</span><span class="w">         </span><span class="p">.</span><span class="n">dataLen</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">40</span><span class="p">),</span>
<span class="linenos">60</span><span class="w">         </span><span class="p">.</span><span class="n">data_valid_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">40</span><span class="p">),</span>
<span class="linenos">61</span><span class="w">         </span><span class="p">.</span><span class="n">unused</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">62</span><span class="w">     </span><span class="p">}};</span>
<span class="linenos">63</span>
<span class="hll"><span class="linenos">64</span><span class="w">  </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_execute_new</span><span class="p">(</span><span class="n">nng_id</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensor_defs</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensor_defs</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p><strong>QNN</strong></p>
<p>QNN uses the same <strong>Qnn_Tensor_t</strong> structures to describe the tensor attributes as well as
supply input activation data, and collect output activation data. Note that the tensors are
in quantized format to keep consistent with the input and output tensor types of the graph
created above.</p>
<div class="literal-block-wrapper docutils container" id="id25">
<div class="code-block-caption"><span class="caption-text">QNN Execute</span><a class="headerlink" href="#id25" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// Setup input buffer</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">inputDataSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">uint8_t</span><span class="p">);</span>
<span class="linenos"> 3</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="n">inputData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">inputDataSize</span><span class="p">);</span>
<span class="linenos"> 4</span><span class="w"> </span><span class="n">memset</span><span class="p">(</span><span class="n">inputData</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">inputDataSize</span><span class="p">);</span>
<span class="linenos"> 5</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="c1">// Fill in the quantized input tensor data</span>
<span class="linenos"> 7</span><span class="w"> </span><span class="p">...</span>
<span class="linenos"> 8</span>
<span class="linenos"> 9</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">graphInDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">};</span>
<span class="hll"><span class="linenos">10</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">graphInTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">11</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">12</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="p">;</span>
<span class="linenos">13</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;graphIn&quot;</span><span class="p">;</span>
<span class="hll"><span class="linenos">14</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_APP_WRITE</span><span class="p">;</span>
</span><span class="linenos">15</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">16</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">17</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">18</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">19</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0256975870579481</span><span class="p">;</span>
<span class="linenos">20</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-132</span><span class="p">;</span>
<span class="linenos">21</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="linenos">22</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">graphInDimensions</span><span class="p">;</span>
<span class="linenos">23</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">24</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">inputData</span><span class="p">;</span>
<span class="linenos">25</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="n">inputDataSize</span><span class="p">;</span>
<span class="linenos">26</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">27</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">28</span><span class="w"> </span><span class="n">graphInTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">29</span>
<span class="linenos">30</span><span class="w"> </span><span class="c1">// Setup output buffer</span>
<span class="linenos">31</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">outputDataSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">uint8_t</span><span class="p">);</span>
<span class="linenos">32</span><span class="w"> </span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="n">outputData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">outputDataSize</span><span class="p">);</span>
<span class="linenos">33</span><span class="w"> </span><span class="n">memset</span><span class="p">(</span><span class="n">outputData</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">outputDataSize</span><span class="p">);</span>
<span class="linenos">34</span>
<span class="linenos">35</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">graphOutDimensions</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">};</span>
<span class="hll"><span class="linenos">36</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="w">                                 </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_INIT</span><span class="p">;</span>
</span><span class="linenos">37</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">version</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_VERSION_2</span><span class="p">;</span>
<span class="linenos">38</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="w">                                        </span><span class="o">=</span><span class="w"> </span><span class="n">softMaxOutputTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">id</span><span class="p">;</span>
<span class="linenos">39</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">name</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;graphOut&quot;</span><span class="p">;</span>
<span class="hll"><span class="linenos">40</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">type</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_TYPE_APP_READ</span><span class="p">;</span>
</span><span class="linenos">41</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataFormat</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSOR_DATA_FORMAT_FLAT_BUFFER</span><span class="p">;</span>
<span class="linenos">42</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dataType</span><span class="w">                                  </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DATATYPE_UFIXED_POINT_8</span><span class="p">;</span>
<span class="linenos">43</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">encodingDefinition</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_DEFINITION_DEFINED</span><span class="p">;</span>
<span class="linenos">44</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">quantizationEncoding</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_QUANTIZATION_ENCODING_SCALE_OFFSET</span><span class="p">;</span>
<span class="linenos">45</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">scale</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="mf">0.00390625</span><span class="p">;</span>
<span class="linenos">46</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">quantizeParams</span><span class="p">.</span><span class="n">scaleOffsetEncoding</span><span class="p">.</span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">47</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">rank</span><span class="w">                                      </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="linenos">48</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">dimensions</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="n">graphOutDimensions</span><span class="p">;</span>
<span class="linenos">49</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">memType</span><span class="w">                                   </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_RAW</span><span class="p">;</span>
<span class="linenos">50</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">data</span><span class="w">                            </span><span class="o">=</span><span class="w"> </span><span class="n">outputData</span><span class="p">;</span>
<span class="linenos">51</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">clientBuf</span><span class="p">.</span><span class="n">dataSize</span><span class="w">                        </span><span class="o">=</span><span class="w"> </span><span class="n">outputDataSize</span><span class="p">;</span>
<span class="linenos">52</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isDynamicDimensions</span><span class="w">                       </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="linenos">53</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">sparseParams</span><span class="w">                              </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_SPARSE_PARAMS_INIT</span><span class="p">;</span>
<span class="linenos">54</span><span class="w"> </span><span class="n">graphOutTensor</span><span class="p">.</span><span class="n">v2</span><span class="p">.</span><span class="n">isProduced</span><span class="w">                                </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="linenos">55</span>
<span class="hll"><span class="linenos">56</span><span class="w"> </span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnGraph_execute</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graphInTensor</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graphOutTensor</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">profile</span><span class="p">,</span><span class="w"> </span><span class="n">signal</span><span class="p">);</span>
</span><span class="linenos">57</span>
<span class="linenos">58</span><span class="w"> </span><span class="c1">// Read the quantized output tensor data and dequantize the data if necessary</span>
<span class="linenos">59</span><span class="w"> </span><span class="p">...</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="destroy-graph">
<h2>Destroy Graph<a class="headerlink" href="#destroy-graph" title="Permalink to this heading">¶</a></h2>
<p>The final step is to release all the resources associated with the graph.</p>
<div class="literal-block-wrapper docutils container" id="id26">
<div class="code-block-caption"><span class="caption-text">Hexagon-nn Destroy Graph</span><a class="headerlink" href="#id26" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="linenos">1</span><span class="n">ret</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hexagon_nn_teardown</span><span class="p">(</span><span class="n">nng_id</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
<p>For QNN the graph resources are associated with the context so freeing the context will free all
resources owned by the graph. Afterwards, device resources need to be released. Finally if the backend accelerator is not longer required, then it’s
resources can also be freed.</p>
<div class="literal-block-wrapper docutils container" id="id27">
<div class="code-block-caption"><span class="caption-text">QNN Destroy Graph</span><a class="headerlink" href="#id27" title="Permalink to this code">¶</a></div>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="linenos">1</span><span class="n">QnnContext_free</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="n">profile</span><span class="p">);</span>
</span><span class="linenos">2</span>
<span class="hll"><span class="linenos">3</span><span class="n">QnnDevice_free</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
</span><span class="linenos">4</span>
<span class="hll"><span class="linenos">5</span><span class="n">QnnBackend_free</span><span class="p">(</span><span class="n">backend</span><span class="p">);</span>
</span><span class="linenos">6</span>
<span class="hll"><span class="linenos">7</span><span class="n">QnnLog_free</span><span class="p">(</span><span class="n">logger</span><span class="p">);</span>
</span></pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2024, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>