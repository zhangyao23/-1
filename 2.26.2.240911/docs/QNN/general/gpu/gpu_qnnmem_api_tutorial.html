

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>QNN GPU QnnMem API Tutorial &mdash; Qualcomm® AI Engine Direct</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom_css.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/collapsible-lists/css/tree_view.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
        <script src="../../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Saver" href="../saver/saver_backend.html" />
    <link rel="prev" title="GPU" href="gpu_backend.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Qualcomm® AI Engine Direct
          

          
          </a>

          
            
            
              <div class="version">
                v2.26.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../setup.html">Setup</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../backend.html">Backend</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../backend.html#backend-specific-pages">Backend Specific Pages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../dsp/dsp_backend.html">DSP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../htp/htp_backend.html">HTP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../hta/hta_backend.html">HTA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lpai/lpai_backend.html">LPAI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cpu/cpu_backend.html">CPU</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="gpu_backend.html">GPU</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#api-specializations">API Specializations</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#operation-limitations">Operation Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#kernel-persistence">Kernel Persistence</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#precision-mode">Precision Mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#performance-hints">Performance Hints</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#context-configs">Context Configs</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#disabling-optimizations">Disabling Optimizations</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#qnn-gpu-backend-extensions">QNN GPU Backend Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#custom-profile-reader">Custom Profile Reader</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#op-package-writing-guidelines">Op Package Writing Guidelines</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="gpu_backend.html#qnn-mem-api-tutorial-for-gpu">QNN Mem API Tutorial for GPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="gpu_backend.html#other-notes">Other Notes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../saver/saver_backend.html">Saver</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../op_packages.html">Op Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converters.html">Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../operations.html">Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Qualcomm® AI Engine Direct</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../backend.html">Backend</a> &raquo;</li>
        
          <li><a href="gpu_backend.html">GPU</a> &raquo;</li>
        
      <li>QNN GPU QnnMem API Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="qnn-gpu-qnnmem-api-tutorial">
<h1>QNN GPU QnnMem API Tutorial<a class="headerlink" href="#qnn-gpu-qnnmem-api-tutorial" title="Permalink to this heading">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>This tutorial demonstrates the usage of the QnnMem API for the QNN GPU backend.
This feature allows for data sharing between processing domains in the QNN GPU
backend.</p>
<p>The supported types of shared memory of the QnnMem API for the QNN GPU backend are as follows:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Qnn_MemDescriptor_t Type</p></th>
<th class="head"><p>QnnGpu_MemType_t Type</p></th>
<th class="head"><p>Descriptor</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="../../api-rst/enum_QnnMem_8h_1ab5f34c4a6c8b1f544072bb49739d2a89.html#exhale-enum-qnnmem-8h-1ab5f34c4a6c8b1f544072bb49739d2a89"><span class="std std-ref">QNN_MEM_TYPE_CUSTOM</span></a></p></td>
<td><p><a class="reference internal" href="../../api-rst/enum_QnnGpuMem_8h_1a9b518ad35bee90f8f407a09b1b44b5fa.html#exhale-enum-qnngpumem-8h-1a9b518ad35bee90f8f407a09b1b44b5fa"><span class="std std-ref">QNN_GPU_MEM_OPENCL</span></a></p></td>
<td><ul class="simple">
<li><p>Each tensor shall be mapped to their own OpenCL buffer</p></li>
<li><p>One-to-one relationship between OpenCL buffer and memory handle</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial is only focused on the QNN GPU Mem OpenCL buffer usage. There are some prerequisites in the
SDK example code not discussed in detail here. Users can refer to the corresponding part in the
QNN documentation, or refer to the SampleApp.</p>
<p>SampleApp documentation: <a class="reference internal" href="../sample_app.html#sample-app-tutorial"><span class="std std-ref">Sample App Tutorial</span></a></p>
<p>SampleApp code: ${QNN_SDK_ROOT}/examples/QNN/SampleApp</p>
</div>
</div>
<div class="section" id="using-qnn-mem-type-custom-with-the-qnn-api">
<h2>Using QNN_MEM_TYPE_CUSTOM with the QNN API<a class="headerlink" href="#using-qnn-mem-type-custom-with-the-qnn-api" title="Permalink to this heading">¶</a></h2>
<p>The following documentation demonstrates the custom memory type feature of the QnnMem API for the QNN
GPU backend which allows a user to allocate their own OpenCL buffers to manage and register for input
and output tensors. Doing so will achieve zero-copy in which the need to read to and write from the GPU
memory to host and vice-versa is mitigated. This will yield inference time metric improvements.</p>
<p>The following is a representation of utilizing OpenCL buffers, where each tensor has its own OpenCL
buffer and memory handle.</p>
<div class="figure align-default">
<img alt="../../_static/resources/qnn_gpu_opencl_buffers.png" src="../../_static/resources/qnn_gpu_opencl_buffers.png" />
</div>
<p>Below is an example of an implementation of this API. It implies that the user has prior background
with OpenCL and its APIs.</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">GPU OpenCL Buffer Example</span><a class="headerlink" href="#id1" title="Permalink to this code">¶</a></div>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="w"> </span><span class="c1">// QnnInterface_t is defined in ${QNN_SDK_ROOT}/include/QNN/QnnInterface.h</span>
<span class="linenos"> 2</span><span class="w"> </span><span class="n">QnnInterface_t</span><span class="w"> </span><span class="n">qnnInterface</span><span class="p">;</span>
<span class="linenos"> 3</span><span class="w"> </span><span class="c1">// Init qnn interface ......</span>
<span class="linenos"> 4</span><span class="w"> </span><span class="c1">// See ${QNN_SDK_ROOT}/examples/QNN/SampleApp code</span>
<span class="linenos"> 5</span>
<span class="linenos"> 6</span><span class="w"> </span><span class="c1">// Qnn_Tensor_t is defined in ${QNN_SDK_ROOT}/include/QNN/QnnTypes.h</span>
<span class="linenos"> 7</span><span class="w"> </span><span class="n">Qnn_Tensor_t</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">;</span>
<span class="linenos"> 8</span><span class="w"> </span><span class="c1">// Set up common setting for inputTensor ......</span>
<span class="linenos"> 9</span><span class="w"> </span><span class="cm">/* There are 2 specific settings for custom QnnMem buffer:</span>
<span class="linenos">10</span><span class="cm"> *  1. memType should be QNN_TENSORMEMTYPE_MEMHANDLE; (line 41)</span>
<span class="linenos">11</span><span class="cm"> *  2. union member memHandle should be used instead of clientBuf, and it</span>
<span class="linenos">12</span><span class="cm"> *     should be set to nullptr. (line 42)</span>
<span class="linenos">13</span><span class="cm"> */</span>
<span class="linenos">14</span>
<span class="linenos">15</span>
<span class="linenos">16</span><span class="w"> </span><span class="c1">// Allocate some buffer, for example two tensors for the gpu runtime with dimensions {64, 128}</span>
<span class="linenos">17</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">bufferSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">128</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
<span class="linenos">18</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">outputTensorBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">bufferSize</span><span class="p">);</span>
<span class="linenos">19</span>
<span class="linenos">20</span><span class="w"> </span><span class="c1">// Generate OpenCL context</span>
<span class="linenos">21</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">clContext</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span>
<span class="linenos">22</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">cl_mem_flags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CL_MEM_READ_WRITE</span><span class="p">;</span>
<span class="linenos">23</span><span class="w"> </span><span class="n">cl_int</span><span class="w"> </span><span class="n">clStatus</span><span class="p">;</span>
<span class="linenos">24</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">outputTensorCLBuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">cl</span><span class="o">::</span><span class="n">buffer</span><span class="p">(</span><span class="o">*</span><span class="n">clContext</span><span class="p">,</span><span class="w"> </span><span class="n">memFlags</span><span class="p">,</span><span class="w"> </span><span class="n">bufferSize</span><span class="p">,</span><span class="w"> </span><span class="n">outputTensorBuffer</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">clStatus</span><span class="p">);</span>
<span class="linenos">25</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">clStatus</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">CL_SUCCESS</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">26</span><span class="w">    </span><span class="c1">// Handle error</span>
<span class="linenos">27</span><span class="w"> </span><span class="p">}</span>
<span class="linenos">28</span>
<span class="linenos">29</span><span class="w"> </span><span class="c1">// Fill the info of Qnn_MemDescriptor_t and register the buffer to QNN</span>
<span class="linenos">30</span><span class="w"> </span><span class="c1">// Qnn_MemDescriptor_t is defined in ${QNN_SDK_ROOT}/include/QNN/QnnMem.h</span>
<span class="linenos">31</span><span class="w"> </span><span class="n">Qnn_MemDescriptor_t</span><span class="w"> </span><span class="n">memDescriptor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MEM_DESCRIPTOR_INIT</span><span class="p">;</span>
<span class="linenos">32</span><span class="w"> </span><span class="n">memDescriptor</span><span class="p">.</span><span class="n">memShape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">inputTensor</span><span class="p">.</span><span class="n">rank</span><span class="p">,</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">dimensions</span><span class="p">,</span><span class="w"> </span><span class="n">nullptr</span><span class="p">};</span>
<span class="linenos">33</span><span class="w"> </span><span class="n">memDescriptor</span><span class="p">.</span><span class="n">dataType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputTensor</span><span class="p">.</span><span class="n">dataType</span><span class="p">;</span>
<span class="linenos">34</span><span class="w"> </span><span class="n">memDescriptor</span><span class="p">.</span><span class="n">memType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_MEM_TYPE_CUSTOM</span><span class="p">;</span>
<span class="linenos">35</span>
<span class="linenos">36</span><span class="w"> </span><span class="c1">// Fill the info of QnnGpu_MemInfoCustom_t to apply to the Qnn_MemDescriptor_t.</span>
<span class="linenos">37</span><span class="w"> </span><span class="n">QnnGpu_MemInfoCustom_t</span><span class="w"> </span><span class="n">customInfo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_GPU_MEM_INFO_CUSTOM_INIT</span><span class="p">;</span>
<span class="linenos">38</span><span class="w"> </span><span class="n">customInfo</span><span class="p">.</span><span class="n">memType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_GPU_MEM_OPENCL</span><span class="p">;</span>
<span class="linenos">39</span><span class="w"> </span><span class="n">customInfo</span><span class="p">.</span><span class="n">buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="n">QnnGpuMem_Buffer_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">outputTensorBuffer</span><span class="p">);</span>
<span class="linenos">40</span><span class="w"> </span><span class="n">memDescriptor</span><span class="p">.</span><span class="n">customInfo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">customInfo</span><span class="p">;</span>
<span class="linenos">41</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">memType</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QNN_TENSORMEMTYPE_MEMHANDLE</span><span class="p">;</span>
<span class="linenos">42</span><span class="w"> </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">memHandle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nullptr</span><span class="p">;</span>
<span class="linenos">43</span>
<span class="linenos">44</span><span class="w"> </span><span class="n">Qnn_ContextHandle_t</span><span class="w"> </span><span class="n">context</span><span class="p">;</span><span class="w"> </span><span class="c1">// Must obtain a QNN context handle before memRegister()</span>
<span class="linenos">45</span><span class="w"> </span><span class="c1">// To obtain QNN context handle:</span>
<span class="linenos">46</span><span class="w"> </span><span class="c1">// For online prepare, refer to ${QNN_SDK_ROOT}/docs/general/sample_app.html#create-context</span>
<span class="linenos">47</span><span class="w"> </span><span class="c1">// For offline prepare, refer to ${QNN_SDK_ROOT}/docs/general/sample_app.html#load-context-from-a-cached-binary</span>
<span class="linenos">48</span><span class="w"> </span><span class="n">Qnn_MemHandle_t</span><span class="w"> </span><span class="n">memHandles</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
<span class="linenos">49</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnMem_register</span><span class="p">(</span><span class="n">context</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">memDescriptor</span><span class="p">,</span><span class="w"> </span><span class="mi">1u</span><span class="p">,</span><span class="w"> </span><span class="n">memHandles</span><span class="p">);</span>
<span class="linenos">50</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">QNN_SUCCESS</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">result</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">51</span><span class="w">     </span><span class="c1">// handle errors</span>
<span class="linenos">52</span><span class="w"> </span><span class="p">}</span>
<span class="linenos">53</span>
<span class="linenos">54</span><span class="w"> </span><span class="cm">/**</span>
<span class="linenos">55</span><span class="cm"> * At this place, the allocation and registration of the OpenCL buffer has been complete.</span>
<span class="linenos">56</span><span class="cm"> * On user side, this buffer can be manipulated through outputTensorBuffer;</span>
<span class="linenos">57</span><span class="cm"> */</span>
<span class="linenos">58</span>
<span class="linenos">59</span><span class="w"> </span><span class="c1">// Load the input data to outputTensorBuffer ......</span>
<span class="linenos">60</span>
<span class="linenos">61</span><span class="w"> </span><span class="c1">// Execute QNN graph with input tensor and output tensor ......</span>
<span class="linenos">62</span>
<span class="linenos">63</span><span class="w"> </span><span class="c1">// Get output data for example</span>
<span class="linenos">64</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">openCLCommandQueue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...;</span><span class="w"> </span><span class="c1">// Get cl::CommandQueue instance</span>
<span class="linenos">65</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">mappedPtr</span><span class="w"> </span><span class="o">=</span>
<span class="linenos">66</span><span class="w">     </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">openCLCommandQueue</span><span class="o">-&gt;</span><span class="n">enqueueMapBuffer</span><span class="p">(</span><span class="o">*</span><span class="n">outputTensorBuffer</span><span class="p">,</span>
<span class="linenos">67</span><span class="w">                                                                   </span><span class="n">CL_TRUE</span><span class="p">,</span>
<span class="linenos">68</span><span class="w">                                                                   </span><span class="n">CL_MAP_READ</span><span class="p">,</span>
<span class="linenos">69</span><span class="w">                                                                   </span><span class="mi">0</span><span class="p">,</span>
<span class="linenos">70</span><span class="w">                                                                   </span><span class="k">sizeof</span><span class="p">(</span><span class="n">bufferSize</span><span class="p">),</span>
<span class="linenos">71</span><span class="w">                                                                   </span><span class="n">nullptr</span><span class="p">,</span>
<span class="linenos">72</span><span class="w">                                                                   </span><span class="n">nullptr</span><span class="p">,</span>
<span class="linenos">73</span><span class="w">                                                                   </span><span class="o">&amp;</span><span class="n">clStatus</span><span class="p">);</span>
<span class="linenos">74</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">clStatus</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">CL_SUCCESS</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">75</span><span class="w">     </span><span class="c1">// handle error</span>
<span class="linenos">76</span><span class="w"> </span><span class="p">}</span>
<span class="linenos">77</span>
<span class="linenos">78</span><span class="w"> </span><span class="c1">// Access contents of mappedPtr e.g.</span>
<span class="linenos">79</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">contents</span><span class="p">(</span><span class="n">mappedPtr</span><span class="p">,</span><span class="w"> </span><span class="n">mappedPtr</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">bufferSize</span><span class="p">);</span>
<span class="linenos">80</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0u</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">contents</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">81</span><span class="w">     </span><span class="c1">// Read data</span>
<span class="linenos">82</span><span class="w"> </span><span class="p">}</span>
<span class="linenos">83</span>
<span class="linenos">84</span><span class="w"> </span><span class="c1">// On completion, unmap the mappedPtr</span>
<span class="linenos">85</span><span class="w"> </span><span class="n">clStatus</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">openCLCommandQueue</span><span class="o">-&gt;</span><span class="n">enqueueUnmapBuffer</span><span class="p">(</span><span class="o">*</span><span class="n">outputTensorBuffer</span><span class="p">,</span><span class="w"> </span><span class="n">mappedPtr</span><span class="p">,</span><span class="w"> </span><span class="n">nullptr</span><span class="p">,</span><span class="w"> </span><span class="n">nullptr</span><span class="p">);</span>
<span class="linenos">86</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">clStatus</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">CL_SUCCESS</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">87</span><span class="w">     </span><span class="c1">// handle error</span>
<span class="linenos">88</span><span class="w"> </span><span class="p">}</span>
<span class="linenos">89</span>
<span class="linenos">90</span><span class="w"> </span><span class="c1">// Deregister and free all buffers if it&#39;s not being used</span>
<span class="linenos">91</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">QnnMem_deregister</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tensors</span><span class="p">.</span><span class="n">memHandle</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="linenos">92</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">QNN_SUCCESS</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">registRet</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">93</span><span class="w">     </span><span class="c1">// handle errors</span>
<span class="linenos">94</span><span class="w"> </span><span class="p">}</span>
<span class="linenos">95</span>
<span class="linenos">96</span><span class="w"> </span><span class="c1">// deallocate memory</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../saver/saver_backend.html" class="btn btn-neutral float-right" title="Saver" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="gpu_backend.html" class="btn btn-neutral float-left" title="GPU" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020-2024, Qualcomm Technologies, Inc..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>