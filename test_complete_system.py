#!/usr/bin/env python3
"""å®Œæ•´ç³»ç»Ÿæµ‹è¯•è„šæœ¬"""

import sys
import os
import numpy as np
import pandas as pd

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from feature_processor.feature_extractor import FeatureExtractor
from ai_models.autoencoder_model import AutoencoderModel
from ai_models.error_classifier import ErrorClassifier

print("ğŸ”§ å®Œæ•´ç³»ç»Ÿæµ‹è¯•")
print("=" * 80)

# 1. åˆå§‹åŒ–ç»„ä»¶
print("ğŸ“¦ åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
try:
    # ç®€åŒ–çš„é…ç½®
    metrics_config = {
        'signal_strength': {'weight': 1.0},
        'data_rate': {'weight': 1.0},
        'latency': {'weight': 1.0},
        'packet_loss': {'weight': 1.0},
        'system_load': {'weight': 1.0},
        'network_stability': {'weight': 1.0}
    }
    
    # ç®€åŒ–çš„æ—¥å¿—è®°å½•å™¨
    class SimpleLogger:
        def info(self, msg): pass
        def debug(self, msg): pass
        def error(self, msg): pass
    
    logger = SimpleLogger()
    
    # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
    feature_extractor = FeatureExtractor(metrics_config, logger)
    print("âœ… ç‰¹å¾æå–å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # åˆå§‹åŒ–è‡ªç¼–ç å™¨
    autoencoder_config = {}
    autoencoder = AutoencoderModel(autoencoder_config, logger)
    print("âœ… è‡ªç¼–ç å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    classifier_config = {}
    classifier = ErrorClassifier(classifier_config, logger)
    print("âœ… åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ")
    
except Exception as e:
    print(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
    exit(1)

# 2. å‡†å¤‡æµ‹è¯•æ•°æ®
print("\nğŸ¯ å‡†å¤‡æµ‹è¯•æ•°æ®...")
try:
    # æ¨¡æ‹Ÿæ­£å¸¸ç½‘ç»œæ•°æ®
    normal_raw_data = np.array([
        [80.0, 2.0, 10.0, 0.001, 8.0, 30.0, 0.95, 5.0, 1.0, 0.5, 2.0]
    ])
    
    # æ¨¡æ‹Ÿå¼‚å¸¸ç½‘ç»œæ•°æ®ï¼ˆé«˜å»¶è¿Ÿã€é«˜ä¸¢åŒ…ç‡ï¼‰
    anomaly_raw_data = np.array([
        [60.0, 1.0, 25.0, 0.15, 15.0, 20.0, 0.60, 8.0, 3.0, 2.0, 5.0]
    ])
    
    print(f"æ­£å¸¸æ•°æ®: {normal_raw_data[0]}")
    print(f"å¼‚å¸¸æ•°æ®: {anomaly_raw_data[0]}")
    
except Exception as e:
    print(f"âŒ æµ‹è¯•æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
    exit(1)

# 3. æµ‹è¯•å®Œæ•´æµç¨‹
print("\nğŸ”„ æµ‹è¯•å®Œæ•´æ£€æµ‹æµç¨‹...")

def test_detection_pipeline(raw_data, data_type):
    """æµ‹è¯•å®Œæ•´çš„æ£€æµ‹æµç¨‹"""
    print(f"\n--- æµ‹è¯•{data_type}æ•°æ® ---")
    
    try:
        # æ­¥éª¤1ï¼šç‰¹å¾æå–
        print("ğŸ” æ­¥éª¤1ï¼šç‰¹å¾æå–...")
        features = feature_extractor.extract_features(raw_data)
        print(f"  è¾“å…¥ç»´åº¦: {raw_data.shape}")
        print(f"  ç‰¹å¾ç»´åº¦: {features.shape}")
        print(f"  æå–çš„ç‰¹å¾: {features[0]}")
        
        # æ­¥éª¤2ï¼šå¼‚å¸¸æ£€æµ‹
        print("ğŸ¤– æ­¥éª¤2ï¼šå¼‚å¸¸æ£€æµ‹...")
        detection_result = autoencoder.predict(features)
        print(f"  é‡æ„è¯¯å·®: {detection_result['reconstruction_error']:.6f}")
        print(f"  å¼‚å¸¸é˜ˆå€¼: {detection_result['threshold']:.6f}")
        print(f"  æ˜¯å¦å¼‚å¸¸: {detection_result['is_anomaly']}")
        
        # æ­¥éª¤3ï¼šå¼‚å¸¸åˆ†ç±»ï¼ˆå¦‚æœæ£€æµ‹åˆ°å¼‚å¸¸ï¼‰
        if detection_result['is_anomaly']:
            print("ğŸ·ï¸  æ­¥éª¤3ï¼šå¼‚å¸¸åˆ†ç±»...")
            classification_result = classifier.classify_error(features)
            print(f"  é¢„æµ‹ç±»åˆ«: {classification_result['predicted_class']}")
            print(f"  ç½®ä¿¡åº¦: {classification_result['confidence']:.4f}")
            print(f"  æ‰€æœ‰æ¦‚ç‡: {classification_result['probabilities']}")
        else:
            print("âœ… æ­¥éª¤3ï¼šæ— éœ€åˆ†ç±»ï¼ˆæ£€æµ‹ä¸ºæ­£å¸¸ï¼‰")
        
        print(f"âœ… {data_type}æ•°æ®æ£€æµ‹å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ {data_type}æ•°æ®æ£€æµ‹å¤±è´¥: {e}")
        return False

# 4. è¿è¡Œæµ‹è¯•
print("\nğŸ§ª è¿è¡Œç³»ç»Ÿæµ‹è¯•...")
success_count = 0
total_tests = 2

# æµ‹è¯•æ­£å¸¸æ•°æ®
if test_detection_pipeline(normal_raw_data, "æ­£å¸¸"):
    success_count += 1

# æµ‹è¯•å¼‚å¸¸æ•°æ®
if test_detection_pipeline(anomaly_raw_data, "å¼‚å¸¸"):
    success_count += 1

# 5. æ‰¹é‡æµ‹è¯•
print(f"\nğŸ“Š æ‰¹é‡æµ‹è¯•å¤šç§åœºæ™¯...")
test_cases = [
    {
        'name': 'æ­£å¸¸åœºæ™¯',
        'data': np.array([[85.0, 2.5, 8.0, 0.001, 6.0, 35.0, 0.98, 4.0, 0.5, 0.2, 1.0]])
    },
    {
        'name': 'ä¿¡å·å¼±åŒ–',
        'data': np.array([[45.0, 1.2, 12.0, 0.02, 10.0, 15.0, 0.75, 6.0, 1.5, 1.0, 3.0]])
    },
    {
        'name': 'ç½‘ç»œæ‹¥å µ',
        'data': np.array([[70.0, 1.8, 30.0, 0.08, 18.0, 25.0, 0.65, 12.0, 2.5, 1.8, 6.0]])
    },
    {
        'name': 'ç³»ç»Ÿè¿‡è½½',
        'data': np.array([[75.0, 2.0, 15.0, 0.05, 22.0, 40.0, 0.80, 15.0, 3.0, 2.5, 8.0]])
    }
]

batch_results = []
for i, test_case in enumerate(test_cases):
    print(f"\n--- æ‰¹é‡æµ‹è¯• {i+1}/{len(test_cases)}: {test_case['name']} ---")
    
    try:
        # å®Œæ•´æµç¨‹
        features = feature_extractor.extract_features(test_case['data'])
        detection_result = autoencoder.predict(features)
        
        result = {
            'name': test_case['name'],
            'features': features[0],
            'reconstruction_error': detection_result['reconstruction_error'],
            'is_anomaly': detection_result['is_anomaly'],
            'anomaly_type': None,
            'confidence': None
        }
        
        if detection_result['is_anomaly']:
            classification_result = classifier.classify_error(features)
            result['anomaly_type'] = classification_result['predicted_class']
            result['confidence'] = classification_result['confidence']
        
        batch_results.append(result)
        
        print(f"  é‡æ„è¯¯å·®: {detection_result['reconstruction_error']:.6f}")
        print(f"  æ˜¯å¦å¼‚å¸¸: {detection_result['is_anomaly']}")
        if detection_result['is_anomaly']:
            print(f"  å¼‚å¸¸ç±»å‹: {classification_result['predicted_class']}")
            print(f"  ç½®ä¿¡åº¦: {classification_result['confidence']:.4f}")
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡æµ‹è¯•å¤±è´¥: {e}")
        batch_results.append({
            'name': test_case['name'],
            'error': str(e)
        })

# 6. æ€»ç»“æŠ¥å‘Š
print("\n" + "=" * 80)
print("ğŸ“‹ ç³»ç»Ÿæµ‹è¯•æ€»ç»“æŠ¥å‘Š")
print("=" * 80)

print(f"\nâœ… åŸºæœ¬åŠŸèƒ½æµ‹è¯•: {success_count}/{total_tests} é€šè¿‡")

print(f"\nğŸ“Š æ‰¹é‡æµ‹è¯•ç»“æœ:")
for result in batch_results:
    if 'error' in result:
        print(f"  âŒ {result['name']}: {result['error']}")
    else:
        status = "å¼‚å¸¸" if result['is_anomaly'] else "æ­£å¸¸"
        if result['is_anomaly']:
            print(f"  ğŸ”´ {result['name']}: {status} -> {result['anomaly_type']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})")
        else:
            print(f"  ğŸŸ¢ {result['name']}: {status}")

print(f"\nğŸ¯ ç³»ç»ŸçŠ¶æ€è¯„ä¼°:")
if success_count == total_tests and len([r for r in batch_results if 'error' not in r]) == len(batch_results):
    print("âœ… ç³»ç»Ÿå®Œå…¨æ­£å¸¸å·¥ä½œ")
    print("âœ… è‡ªç¼–ç å™¨å¼‚å¸¸æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
    print("âœ… åˆ†ç±»å™¨å¼‚å¸¸åˆ†ç±»åŠŸèƒ½æ­£å¸¸")
    print("âœ… ç‰¹å¾æå–å™¨å·¥ä½œæ­£å¸¸")
    print("âœ… ç«¯åˆ°ç«¯æµç¨‹è¿è¡Œæ­£å¸¸")
else:
    print("âŒ ç³»ç»Ÿå­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")

print("\n" + "=" * 80)
print("ğŸ ç³»ç»Ÿæµ‹è¯•å®Œæˆ") 