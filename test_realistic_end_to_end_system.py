import torch
import torch.nn as nn
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# çœŸå®ç«¯åˆ°ç«¯å¼‚å¸¸æ£€æµ‹ç½‘ç»œ (11ç»´è¾“å…¥)
class RealisticEndToEndAnomalyDetector(nn.Module):
    def __init__(self):
        super(RealisticEndToEndAnomalyDetector, self).__init__()
        
        # å¢åŠ ç½‘ç»œå¤æ‚åº¦å’Œæ­£åˆ™åŒ–æ¥å¤„ç†çœŸå®æ•°æ®
        self.network = nn.Sequential(
            nn.Linear(11, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(32, 16),
            nn.BatchNorm1d(16),
            nn.ReLU(),
            nn.Dropout(0.1),
            
            nn.Linear(16, 2)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        return self.network(x)

# çœŸå®ç«¯åˆ°ç«¯å¼‚å¸¸åˆ†ç±»ç½‘ç»œ (11ç»´è¾“å…¥)
class RealisticEndToEndAnomalyClassifier(nn.Module):
    def __init__(self, n_classes=6):
        super(RealisticEndToEndAnomalyClassifier, self).__init__()
        
        # å¢åŠ ç½‘ç»œå¤æ‚åº¦æ¥å¤„ç†ç›¸ä¼¼çš„å¼‚å¸¸ç±»å‹
        self.network = nn.Sequential(
            nn.Linear(11, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(64, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(32, n_classes)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        return self.network(x)

def generate_extreme_challenging_test_data(n_samples=2000):
    """ç”Ÿæˆæå…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•æ•°æ®ï¼ŒåŒ…å«æ›´å¤šè¾¹ç•Œæƒ…å†µ"""
    print(f"ç”Ÿæˆ {n_samples} ä¸ªæå…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•æ ·æœ¬...")
    
    np.random.seed(456)  # ä½¿ç”¨ä¸åŒçš„éšæœºç§å­
    
    test_data = []
    test_labels_binary = []
    test_labels_multiclass = []
    
    # æ›´å¤æ‚çš„æµ‹è¯•æ ·æœ¬ç±»å‹
    sample_types = [
        'normal', 'borderline_normal', 'marginal_anomaly', 
        'noisy_normal', 'noisy_anomaly', 'mixed_signals',
        'extreme_borderline', 'conflicting_indicators', 'ambiguous_case'
    ]
    
    for i in range(n_samples):
        sample_type = np.random.choice(sample_types)
        
        if sample_type == 'normal':
            # æ­£å¸¸æ ·æœ¬ï¼ˆ30%ï¼‰
            sample = [
                np.random.normal(75, 15),     # quality
                np.random.normal(-50, 10),    # signal
                np.random.normal(-90, 5),     # noise
                np.random.normal(15000, 5000), # rx_packets
                np.random.normal(12000, 4000), # tx_packets
                np.random.normal(3000000, 1000000), # rx_bytes
                np.random.normal(2500000, 800000),  # tx_bytes
                np.random.normal(20, 8),      # ping
                np.random.normal(30, 10),     # dns
                np.random.normal(40, 15),     # memory
                np.random.normal(25, 10)      # cpu
            ]
            binary_label = 0
            multiclass_label = 0
            
        elif sample_type == 'borderline_normal':
            # è¾¹ç•Œæ­£å¸¸æ ·æœ¬ï¼ˆ20%ï¼‰ - æ¥è¿‘å¼‚å¸¸é˜ˆå€¼
            sample = [
                np.random.normal(60, 10),     # qualityåä½
                np.random.normal(-65, 8),     # signalåå¼±
                np.random.normal(-80, 6),     # noiseåé«˜
                np.random.normal(8000, 2000), # packetsåå°‘
                np.random.normal(6000, 1500), # packetsåå°‘
                np.random.normal(1800000, 400000), # bytesåå°‘
                np.random.normal(1500000, 300000), # bytesåå°‘
                np.random.normal(40, 12),     # pingåé«˜
                np.random.normal(55, 15),     # dnsåé«˜
                np.random.normal(65, 10),     # memoryåé«˜
                np.random.normal(45, 8)       # cpuåé«˜
            ]
            binary_label = 0  # ä»ç„¶æ˜¯æ­£å¸¸ï¼Œä½†å¾ˆæ¥è¿‘è¾¹ç•Œ
            multiclass_label = 0
            
        elif sample_type == 'marginal_anomaly':
            # è¾¹é™…å¼‚å¸¸æ ·æœ¬ï¼ˆ15%ï¼‰ - åˆšè¶…è¿‡æ­£å¸¸èŒƒå›´
            base_patterns = ['wifi_degradation', 'network_latency', 'connection_instability']
            pattern = np.random.choice(base_patterns)
            
            if pattern == 'wifi_degradation':
                sample = [
                    np.random.normal(45, 15),     # qualityå·®
                    np.random.normal(-70, 8),     # signalå·®
                    np.random.normal(-75, 8),     # noiseé«˜
                    np.random.normal(6000, 2000), # packetså°‘
                    np.random.normal(4500, 1500), # packetså°‘
                    np.random.normal(1200000, 400000), # byteså°‘
                    np.random.normal(1000000, 300000), # byteså°‘
                    np.random.normal(45, 15),     # pingç¨é«˜
                    np.random.normal(60, 20),     # dnsç¨é«˜
                    np.random.normal(45, 12),     # memoryæ­£å¸¸
                    np.random.normal(30, 8)       # cpuæ­£å¸¸
                ]
                multiclass_label = 1  # wifi_degradation
            elif pattern == 'network_latency':
                sample = [
                    np.random.normal(70, 12),     # qualityæ­£å¸¸
                    np.random.normal(-55, 8),     # signalæ­£å¸¸
                    np.random.normal(-85, 5),     # noiseæ­£å¸¸
                    np.random.normal(12000, 3000), # packetsæ­£å¸¸
                    np.random.normal(9000, 2000), # packetsæ­£å¸¸
                    np.random.normal(2200000, 600000), # bytesæ­£å¸¸
                    np.random.normal(1800000, 500000), # bytesæ­£å¸¸
                    np.random.normal(65, 20),     # pingé«˜
                    np.random.normal(90, 30),     # dnsé«˜
                    np.random.normal(40, 12),     # memoryæ­£å¸¸
                    np.random.normal(25, 8)       # cpuæ­£å¸¸
                ]
                multiclass_label = 2  # network_latency
            else:  # connection_instability
                sample = [
                    np.random.normal(55, 20),     # qualityä¸ç¨³å®š
                    np.random.normal(-62, 12),    # signalä¸ç¨³å®š
                    np.random.normal(-78, 10),    # noiseè¾ƒé«˜
                    np.random.normal(7000, 3000), # packetså‡å°‘
                    np.random.normal(5500, 2000), # packetså‡å°‘
                    np.random.normal(1400000, 500000), # byteså‡å°‘
                    np.random.normal(1100000, 400000), # byteså‡å°‘
                    np.random.normal(50, 15),     # pingä¸­ç­‰
                    np.random.normal(65, 20),     # dnsä¸­ç­‰
                    np.random.normal(38, 10),     # memoryæ­£å¸¸
                    np.random.normal(22, 6)       # cpuæ­£å¸¸
                ]
                multiclass_label = 3  # connection_instability
            
            binary_label = 1
            
        elif sample_type in ['noisy_normal', 'noisy_anomaly']:
            # å¸¦å™ªå£°çš„æ ·æœ¬ï¼ˆ15%ï¼‰
            if sample_type == 'noisy_normal':
                base_sample = [75, -50, -90, 15000, 12000, 3000000, 2500000, 20, 30, 40, 25]
                binary_label = 0
                multiclass_label = 0
            else:
                base_sample = [45, -70, -75, 6000, 4500, 1200000, 1000000, 45, 60, 45, 30]
                binary_label = 1
                multiclass_label = 1
            
            sample = []
            for val in base_sample:
                # æ·»åŠ 20-40%çš„éšæœºå™ªå£°
                noise = np.random.uniform(-0.4, 0.4) * abs(val) if val != 0 else np.random.uniform(-10, 10)
                sample.append(val + noise)
            
        elif sample_type == 'mixed_signals':
            # æ··åˆä¿¡å·æ ·æœ¬ï¼ˆ10%ï¼‰ - éƒ¨åˆ†æŒ‡æ ‡æ­£å¸¸ï¼Œéƒ¨åˆ†å¼‚å¸¸
            sample = [
                np.random.normal(75, 10),     # qualityæ­£å¸¸
                np.random.normal(-50, 8),     # signalæ­£å¸¸
                np.random.normal(-90, 5),     # noiseæ­£å¸¸
                np.random.normal(3000, 1500), # packetså¼‚å¸¸ä½
                np.random.normal(2500, 1000), # packetså¼‚å¸¸ä½
                np.random.normal(600000, 300000), # byteså¼‚å¸¸ä½
                np.random.normal(500000, 200000), # byteså¼‚å¸¸ä½
                np.random.normal(25, 8),      # pingæ­£å¸¸
                np.random.normal(35, 10),     # dnsæ­£å¸¸
                np.random.normal(40, 12),     # memoryæ­£å¸¸
                np.random.normal(25, 8)       # cpuæ­£å¸¸
            ]
            binary_label = 1  # åº”è¯¥è¢«è¯†åˆ«ä¸ºå¼‚å¸¸
            multiclass_label = 3  # connection_instability
            
        elif sample_type == 'extreme_borderline':
            # æç«¯è¾¹ç•Œæƒ…å†µï¼ˆ5%ï¼‰ - éå¸¸éš¾ä»¥åˆ¤æ–­
            # åœ¨æ­£å¸¸å’Œå¼‚å¸¸ä¹‹é—´50:50æ··åˆ
            normal_base = [75, -50, -90, 15000, 12000, 3000000, 2500000, 20, 30, 40, 25]
            anomaly_base = [50, -65, -80, 8000, 6000, 1500000, 1200000, 35, 50, 45, 30]
            
            sample = []
            for i, (normal_val, anomaly_val) in enumerate(zip(normal_base, anomaly_base)):
                # 50-50æ··åˆï¼Œç„¶åæ·»åŠ å™ªå£°
                mix_factor = np.random.uniform(0.3, 0.7)
                mixed_val = normal_val * mix_factor + anomaly_val * (1 - mix_factor)
                noise = np.random.normal(0, 0.1 * abs(mixed_val))
                sample.append(mixed_val + noise)
            
            # éšæœºåˆ†é…æ ‡ç­¾ï¼ˆè¾¹ç•Œæƒ…å†µå¾ˆéš¾ç¡®å®šï¼‰
            binary_label = np.random.choice([0, 1])
            multiclass_label = np.random.choice([0, 1, 2, 3]) if binary_label == 1 else 0
            
        elif sample_type == 'conflicting_indicators':
            # å†²çªæŒ‡æ ‡æ ·æœ¬ï¼ˆ3%ï¼‰ - ä¸åŒæŒ‡æ ‡æŒ‡å‘ä¸åŒç»“è®º
            sample = [
                np.random.normal(80, 8),      # qualityå¾ˆå¥½
                np.random.normal(-45, 5),     # signalå¾ˆå¥½
                np.random.normal(-92, 3),     # noiseå¾ˆä½
                np.random.normal(500, 200),   # packetsæå°‘ï¼ˆå¼‚å¸¸ï¼‰
                np.random.normal(400, 150),   # packetsæå°‘ï¼ˆå¼‚å¸¸ï¼‰
                np.random.normal(100000, 50000), # bytesæå°‘ï¼ˆå¼‚å¸¸ï¼‰
                np.random.normal(80000, 30000),  # bytesæå°‘ï¼ˆå¼‚å¸¸ï¼‰
                np.random.normal(15, 5),      # pingå¾ˆå¥½
                np.random.normal(25, 5),      # dnså¾ˆå¥½
                np.random.normal(35, 8),      # memoryæ­£å¸¸
                np.random.normal(20, 5)       # cpuæ­£å¸¸
            ]
            binary_label = 1  # åº”è¯¥è¢«è¯†åˆ«ä¸ºå¼‚å¸¸ï¼ˆæµé‡å¼‚å¸¸ï¼‰
            multiclass_label = 3  # connection_instability
            
        else:  # ambiguous_case
            # æ¨¡ç³Šæ¡ˆä¾‹ï¼ˆ2%ï¼‰ - çœŸæ­£éš¾ä»¥åˆ†ç±»çš„æƒ…å†µ
            # æ‰€æœ‰å€¼éƒ½åœ¨è¾¹ç•Œé™„è¿‘æ³¢åŠ¨
            boundary_values = [62, -58, -82, 10000, 8000, 2000000, 1700000, 35, 45, 52, 38]
            sample = []
            for val in boundary_values:
                # åœ¨è¾¹ç•Œå€¼é™„è¿‘éšæœºæ³¢åŠ¨
                variation = np.random.normal(0, 0.15 * abs(val))
                sample.append(val + variation)
            
            # çœŸæ­£éšæœºçš„æ ‡ç­¾ï¼ˆæ¨¡æ‹Ÿç°å®ä¸­çš„æ¨¡ç³Šæƒ…å†µï¼‰
            binary_label = np.random.choice([0, 1])
            multiclass_label = np.random.choice([0, 1, 2, 3]) if binary_label == 1 else 0
        
        # åº”ç”¨è¾¹ç•Œçº¦æŸ
        sample[0] = np.clip(sample[0], 0, 100)    # quality
        sample[1] = np.clip(sample[1], -100, -10) # signal
        sample[2] = np.clip(sample[2], -100, -30) # noise
        for i in range(3, 7):  # packets and bytes
            sample[i] = max(0, sample[i])
        for i in range(7, 9):  # times
            sample[i] = max(1, sample[i])
        for i in range(9, 11): # percentages
            sample[i] = np.clip(sample[i], 0, 100)
        
        test_data.append(sample)
        test_labels_binary.append(binary_label)
        test_labels_multiclass.append(multiclass_label)
    
    return np.array(test_data), np.array(test_labels_binary), np.array(test_labels_multiclass)

def test_realistic_model_robustness():
    """æµ‹è¯•çœŸå®æ•°æ®æ¨¡å‹çš„é²æ£’æ€§"""
    print("=== çœŸå®æ•°æ®æ¨¡å‹é²æ£’æ€§æµ‹è¯• ===")
    print()
    
    # åŠ è½½çœŸå®æ•°æ®æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
    scaler = joblib.load('realistic_raw_data_scaler.pkl')
    
    detector_model = RealisticEndToEndAnomalyDetector()
    detector_model.load_state_dict(torch.load('realistic_end_to_end_anomaly_detector.pth', map_location='cpu'))
    detector_model.eval()
    
    classifier_model = RealisticEndToEndAnomalyClassifier(n_classes=6)
    classifier_model.load_state_dict(torch.load('realistic_end_to_end_anomaly_classifier.pth', map_location='cpu'))
    classifier_model.eval()
    
    # ç”Ÿæˆæå…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•æ•°æ®
    test_data, test_labels_binary, test_labels_multiclass = generate_extreme_challenging_test_data(2000)
    
    # æ ‡å‡†åŒ–æµ‹è¯•æ•°æ®
    test_data_scaled = scaler.transform(test_data)
    test_tensor = torch.FloatTensor(test_data_scaled)
    
    # æµ‹è¯•å¼‚å¸¸æ£€æµ‹
    print("ğŸ” **å¼‚å¸¸æ£€æµ‹æ€§èƒ½æµ‹è¯•ï¼ˆæç«¯æŒ‘æˆ˜ï¼‰**")
    with torch.no_grad():
        detection_output = detector_model(test_tensor)
        detection_probs = torch.softmax(detection_output, dim=1)
        predicted_binary = torch.argmax(detection_output, dim=1).numpy()
    
    # è®¡ç®—å¼‚å¸¸æ£€æµ‹å‡†ç¡®ç‡
    detection_accuracy = accuracy_score(test_labels_binary, predicted_binary)
    print(f"   å¼‚å¸¸æ£€æµ‹å‡†ç¡®ç‡: {detection_accuracy:.3f} ({detection_accuracy*100:.1f}%)")
    
    # è¯¦ç»†åˆ†æ
    cm_binary = confusion_matrix(test_labels_binary, predicted_binary)
    print(f"   æ··æ·†çŸ©é˜µ:")
    print(f"   å®é™…\\é¢„æµ‹  æ­£å¸¸   å¼‚å¸¸")
    print(f"   æ­£å¸¸      {cm_binary[0,0]:4d}   {cm_binary[0,1]:4d}")
    print(f"   å¼‚å¸¸      {cm_binary[1,0]:4d}   {cm_binary[1,1]:4d}")
    
    # è®¡ç®—å…³é”®æŒ‡æ ‡
    precision = cm_binary[1,1] / (cm_binary[1,1] + cm_binary[0,1]) if (cm_binary[1,1] + cm_binary[0,1]) > 0 else 0
    recall = cm_binary[1,1] / (cm_binary[1,1] + cm_binary[1,0]) if (cm_binary[1,1] + cm_binary[1,0]) > 0 else 0
    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    print(f"   ç²¾ç¡®ç‡: {precision:.3f}")
    print(f"   å¬å›ç‡: {recall:.3f}")
    print(f"   F1åˆ†æ•°: {f1_score:.3f}")
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒ
    confidence_normal = detection_probs[test_labels_binary == 0, 0].numpy()
    confidence_anomaly = detection_probs[test_labels_binary == 1, 1].numpy()
    
    print(f"   æ­£å¸¸æ ·æœ¬ç½®ä¿¡åº¦: å‡å€¼={confidence_normal.mean():.3f}, æœ€å°={confidence_normal.min():.3f}, æ ‡å‡†å·®={confidence_normal.std():.3f}")
    print(f"   å¼‚å¸¸æ ·æœ¬ç½®ä¿¡åº¦: å‡å€¼={confidence_anomaly.mean():.3f}, æœ€å°={confidence_anomaly.min():.3f}, æ ‡å‡†å·®={confidence_anomaly.std():.3f}")
    
    # æµ‹è¯•å¼‚å¸¸åˆ†ç±»ï¼ˆä»…å¯¹æ£€æµ‹ä¸ºå¼‚å¸¸çš„æ ·æœ¬ï¼‰
    anomaly_mask = predicted_binary == 1
    if np.sum(anomaly_mask) > 0:
        print()
        print("ğŸ¯ **å¼‚å¸¸åˆ†ç±»æ€§èƒ½æµ‹è¯•**")
        
        with torch.no_grad():
            classification_output = classifier_model(test_tensor[anomaly_mask])
            predicted_multiclass = torch.argmax(classification_output, dim=1).numpy()
        
        # è½¬æ¢çœŸå®æ ‡ç­¾
        true_multiclass = test_labels_multiclass[anomaly_mask]
        
        # åªå¯¹çœŸæ­£çš„å¼‚å¸¸æ ·æœ¬è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡
        true_anomaly_mask = test_labels_binary[anomaly_mask] == 1
        if np.sum(true_anomaly_mask) > 0:
            true_multiclass_filtered = true_multiclass[true_anomaly_mask] - 1
            predicted_multiclass_filtered = predicted_multiclass[true_anomaly_mask]
            
            # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
            valid_mask = (true_multiclass_filtered >= 0) & (true_multiclass_filtered < 6)
            if np.sum(valid_mask) > 0:
                classification_accuracy = accuracy_score(
                    true_multiclass_filtered[valid_mask], 
                    predicted_multiclass_filtered[valid_mask]
                )
                print(f"   å¼‚å¸¸åˆ†ç±»å‡†ç¡®ç‡: {classification_accuracy:.3f} ({classification_accuracy*100:.1f}%)")
                print(f"   æœ‰æ•ˆåˆ†ç±»æ ·æœ¬æ•°: {np.sum(valid_mask)}")
            else:
                print("   æ²¡æœ‰æœ‰æ•ˆçš„å¼‚å¸¸åˆ†ç±»æ ·æœ¬")
        else:
            print("   æ²¡æœ‰çœŸæ­£çš„å¼‚å¸¸æ ·æœ¬è¢«æ£€æµ‹åˆ°")
    
    # åˆ†æä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„æ€§èƒ½
    print()
    print("ğŸ” **ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„æ€§èƒ½**")
    thresholds = [0.6, 0.7, 0.8, 0.9, 0.95]
    
    for threshold in thresholds:
        # é‡æ–°é¢„æµ‹ï¼ˆä½¿ç”¨ç½®ä¿¡åº¦é˜ˆå€¼ï¼‰
        high_conf_mask = np.max(detection_probs.numpy(), axis=1) >= threshold
        
        if np.sum(high_conf_mask) > 0:
            high_conf_accuracy = accuracy_score(
                test_labels_binary[high_conf_mask], 
                predicted_binary[high_conf_mask]
            )
            coverage = np.sum(high_conf_mask) / len(test_data)
            print(f"   ç½®ä¿¡åº¦>={threshold}: å‡†ç¡®ç‡={high_conf_accuracy:.3f}, è¦†ç›–ç‡={coverage:.3f}")
        else:
            print(f"   ç½®ä¿¡åº¦>={threshold}: æ— ç¬¦åˆæ¡ä»¶çš„æ ·æœ¬")

def main():
    print("=== çœŸå®æ•°æ®æ¨¡å‹æç«¯é²æ£’æ€§æµ‹è¯• ===")
    print()
    
    print("ğŸ¯ **æµ‹è¯•ç›®æ ‡**:")
    print("   - éªŒè¯çœŸå®æ•°æ®æ¨¡å‹åœ¨æç«¯æƒ…å†µä¸‹çš„è¡¨ç°")
    print("   - æµ‹è¯•è¾¹ç•Œæƒ…å†µå’Œæ¨¡ç³Šæ ·æœ¬çš„å¤„ç†")
    print("   - åˆ†æç½®ä¿¡åº¦åˆ†å¸ƒå’Œå¯é æ€§")
    print("   - è¯„ä¼°ç›¸æ¯”ç†æƒ³æ•°æ®æ¨¡å‹çš„æ”¹è¿›")
    print()
    
    test_realistic_model_robustness()
    
    print()
    print("=== æµ‹è¯•åˆ†æç»“è®º ===")
    print("é¢„æœŸè¡¨ç°: ç›¸æ¯”ç†æƒ³æ•°æ®æ¨¡å‹ï¼Œåº”è¯¥æœ‰:")
    print("1. é€‚åº¦é™ä½çš„å‡†ç¡®ç‡ï¼ˆæ›´çœŸå®ï¼‰")
    print("2. æ›´å¥½çš„ç½®ä¿¡åº¦åˆ†å¸ƒï¼ˆä¸å†å…¨æ˜¯1.0ï¼‰") 
    print("3. æ›´åˆç†çš„é”™è¯¯æ¨¡å¼")
    print("4. æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›")

if __name__ == "__main__":
    main() 