#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIç½‘ç»œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ - å…¨é¢æ€§èƒ½æµ‹è¯•è„šæœ¬
åŒ…å«è‡ªç¼–ç å™¨ã€åˆ†ç±»å™¨å’Œç³»ç»Ÿé›†æˆçš„å®Œæ•´æ€§èƒ½è¯„ä¼°
"""

import numpy as np
import pandas as pd
import time
import json
from pathlib import Path
import sys
import os

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.append('src')

from ai_models.autoencoder_model import AutoencoderModel
from ai_models.error_classifier import ErrorClassifier
from feature_processor.feature_extractor import FeatureExtractor
from logger.logger import Logger


class ComprehensivePerformanceTest:
    """ç»¼åˆæ€§èƒ½æµ‹è¯•ç±»"""
    
    def __init__(self):
        print("ğŸš€ AIç½‘ç»œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ - å…¨é¢æ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = Logger()
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        self.load_test_data()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.init_models()
        
        # æµ‹è¯•ç»“æœ
        self.results = {
            'autoencoder_performance': {},
            'classifier_performance': {},
            'system_integration': {},
            'performance_benchmark': {}
        }
    
    def load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        print("ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
        
        try:
            # åŠ è½½è®­ç»ƒæ•°æ®ç”¨äºæ€§èƒ½æµ‹è¯•
            data_path = "data/improved_training_data_6d.csv"
            if os.path.exists(data_path):
                df = pd.read_csv(data_path)
                print(f"âœ… åŠ è½½è®­ç»ƒæ•°æ®: {len(df)} æ¡è®°å½•")
                
                # åˆ†ç¦»æ­£å¸¸å’Œå¼‚å¸¸æ•°æ®
                normal_data = df[df['label'] == 0].drop(['label', 'anomaly_type'], axis=1)
                anomaly_data = df[df['label'] == 1].drop(['label', 'anomaly_type'], axis=1)
                
                # éšæœºé‡‡æ ·ç”¨äºæµ‹è¯•
                self.normal_samples = normal_data.sample(n=min(100, len(normal_data))).values
                self.anomaly_samples = anomaly_data.sample(n=min(100, len(anomaly_data))).values
                
                print(f"ğŸ“¦ æ­£å¸¸æ ·æœ¬: {len(self.normal_samples)} æ¡")
                print(f"ğŸ“¦ å¼‚å¸¸æ ·æœ¬: {len(self.anomaly_samples)} æ¡")
                
                # è·å–å¼‚å¸¸ç±»å‹åˆ†å¸ƒ
                anomaly_types = df[df['label'] == 1]['anomaly_type'].value_counts()
                print("ğŸ“Š å¼‚å¸¸ç±»å‹åˆ†å¸ƒ:")
                for atype, count in anomaly_types.items():
                    print(f"  {atype}: {count}")
                
            else:
                print("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")
                self.create_mock_data()
                
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            self.create_mock_data()
    
    def create_mock_data(self):
        """åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®"""
        print("ğŸ”§ åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®...")
        
        # æ­£å¸¸æ•°æ® (6ç»´ç‰¹å¾)
        np.random.seed(42)
        self.normal_samples = np.random.normal(
            loc=[8.0, 2.5, 10.0, 0.001, 0.8, 0.95],
            scale=[1.0, 0.5, 2.0, 0.005, 0.2, 0.1],
            size=(100, 6)
        )
        
        # å¼‚å¸¸æ•°æ® 
        self.anomaly_samples = np.random.normal(
            loc=[2.0, 1.0, 80.0, 0.15, 0.9, 0.6],
            scale=[1.0, 0.5, 20.0, 0.05, 0.1, 0.2],
            size=(100, 6)
        )
        
        print(f"âœ… ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: æ­£å¸¸{len(self.normal_samples)}æ¡, å¼‚å¸¸{len(self.anomaly_samples)}æ¡")
    
    def init_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print("ğŸ¤– åˆå§‹åŒ–AIæ¨¡å‹...")
        
        try:
            # åˆå§‹åŒ–è‡ªç¼–ç å™¨
            self.autoencoder = AutoencoderModel(
                input_dim=6,
                logger=self.logger,
                model_path='models/autoencoder_model_retrained'
            )
            print("âœ… è‡ªç¼–ç å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–åˆ†ç±»å™¨
            self.classifier = ErrorClassifier(
                logger=self.logger,
                model_path='models/rf_classifier_improved.pkl'
            )
            print("âœ… åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def test_autoencoder_performance(self):
        """æµ‹è¯•è‡ªç¼–ç å™¨æ€§èƒ½"""
        print("\nğŸ¯ æµ‹è¯•è‡ªç¼–ç å™¨æ€§èƒ½...")
        print("-" * 40)
        
        # æµ‹è¯•æ­£å¸¸æ•°æ®
        print("ğŸ“ˆ æµ‹è¯•æ­£å¸¸æ•°æ®...")
        normal_errors = []
        normal_predictions = []
        
        for i, sample in enumerate(self.normal_samples):
            try:
                is_anomaly, error, score = self.autoencoder.predict(sample)
                normal_errors.append(error)
                normal_predictions.append(is_anomaly)
                
                if i < 5:  # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
                    print(f"  æ ·æœ¬ {i+1}: é‡æ„è¯¯å·®={error:.6f}, å¼‚å¸¸={is_anomaly}")
                    
            except Exception as e:
                print(f"  æ ·æœ¬ {i+1} æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•å¼‚å¸¸æ•°æ®
        print("ğŸ“‰ æµ‹è¯•å¼‚å¸¸æ•°æ®...")
        anomaly_errors = []
        anomaly_predictions = []
        
        for i, sample in enumerate(self.anomaly_samples):
            try:
                is_anomaly, error, score = self.autoencoder.predict(sample)
                anomaly_errors.append(error)
                anomaly_predictions.append(is_anomaly)
                
                if i < 5:  # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
                    print(f"  æ ·æœ¬ {i+1}: é‡æ„è¯¯å·®={error:.6f}, å¼‚å¸¸={is_anomaly}")
                    
            except Exception as e:
                print(f"  æ ·æœ¬ {i+1} æµ‹è¯•å¤±è´¥: {e}")
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        if normal_errors and anomaly_errors:
            normal_accuracy = sum(not pred for pred in normal_predictions) / len(normal_predictions)
            anomaly_accuracy = sum(anomaly_predictions) / len(anomaly_predictions)
            overall_accuracy = (normal_accuracy * len(normal_predictions) + 
                              anomaly_accuracy * len(anomaly_predictions)) / (len(normal_predictions) + len(anomaly_predictions))
            
            results = {
                'threshold': self.autoencoder.threshold,
                'normal_samples': len(normal_errors),
                'anomaly_samples': len(anomaly_errors),
                'normal_accuracy': normal_accuracy,
                'anomaly_accuracy': anomaly_accuracy,
                'overall_accuracy': overall_accuracy,
                'normal_error_mean': np.mean(normal_errors),
                'normal_error_std': np.std(normal_errors),
                'anomaly_error_mean': np.mean(anomaly_errors),
                'anomaly_error_std': np.std(anomaly_errors)
            }
            
            print(f"\nğŸ“Š è‡ªç¼–ç å™¨æ€§èƒ½æŒ‡æ ‡:")
            print(f"  å¼‚å¸¸æ£€æµ‹é˜ˆå€¼: {results['threshold']:.6f}")
            print(f"  æ­£å¸¸æ•°æ®å‡†ç¡®ç‡: {results['normal_accuracy']:.3f}")
            print(f"  å¼‚å¸¸æ•°æ®å‡†ç¡®ç‡: {results['anomaly_accuracy']:.3f}")
            print(f"  æ€»ä½“å‡†ç¡®ç‡: {results['overall_accuracy']:.3f}")
            print(f"  æ­£å¸¸æ•°æ®é‡æ„è¯¯å·®: {results['normal_error_mean']:.6f} Â± {results['normal_error_std']:.6f}")
            print(f"  å¼‚å¸¸æ•°æ®é‡æ„è¯¯å·®: {results['anomaly_error_mean']:.6f} Â± {results['anomaly_error_std']:.6f}")
            
            self.results['autoencoder_performance'] = results
            
        else:
            print("âŒ æ— æ³•è®¡ç®—è‡ªç¼–ç å™¨æ€§èƒ½æŒ‡æ ‡")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        try:
            self.test_autoencoder_performance()
            print("\nâœ… å…¨é¢æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œå…¨é¢æ€§èƒ½æµ‹è¯•
    test = ComprehensivePerformanceTest()
    test.run_all_tests()
